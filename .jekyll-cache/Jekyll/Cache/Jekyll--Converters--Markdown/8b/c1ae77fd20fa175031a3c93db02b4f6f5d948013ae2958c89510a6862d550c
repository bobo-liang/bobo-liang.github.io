I"ä<h1 id="attention">Attention</h1>

<ol>
  <li><strong>Attentional ShapeContextNet for Point Cloud Recognition(CVPR2018)</strong> <a href="http://openaccess.thecvf.com/content_cvpr_2018/html/Xie_Attentional_ShapeContextNet_for_CVPR_2018_paper.html">è®ºæ–‡é“¾æ¥</a> :  <em>å°†Shapecontextçš„æ€æƒ³å¼•å…¥æ·±åº¦å­¦ä¹ ã€‚ä¸ºäº†è¿›ä¸€æ­¥ç®€åŒ–ï¼Œåˆ©ç”¨æ·±åº¦å­¦ä¹ çš„èƒ½åŠ›ï¼Œå°†æ³¨æ„åŠ›ï¼ˆtransformerï¼‰å¼•å…¥ï¼Œå®Œæˆselection and aggregationçš„åŠŸèƒ½ã€‚</em></li>
  <li><strong>PCAN: 3D Attention Map Learning Using Contextual Information for Point
Cloud Based Retrieval(CVPR2019)</strong> <a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_PCAN_3D_Attention_Map_Learning_Using_Contextual_Information_for_Point_CVPR_2019_paper.html">è®ºæ–‡é“¾æ¥</a> : <em>ç›¸å½“ç”¨ç±»ä¼¼PointNet++ä¸­SAG+FPçš„æ–¹æ³•ï¼Œæå–æ¯ä¸ªç‚¹çš„å±€éƒ¨ç‰¹å¾ï¼Œå†è½¬æ¢ä¸ºattentionï¼Œç”¨äºPointNetçš„ç‚¹ç‰¹å¾â†’å…¨å±€ç‰¹å¾çš„åŠ æƒ</em></li>
</ol>

<h1 id="detection">Detection</h1>

<ol>
  <li><strong>What You See is What You Get: Exploiting Visibility for 3D Object Detection(CVPR2020)</strong> <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Hu_What_You_See_is_What_You_Get_Exploiting_Visibility_for_CVPR_2020_paper.html">è®ºæ–‡é“¾æ¥</a>: <em>å¼•å…¥visualbilityçš„æ¦‚å¿µï¼Œè€ƒè™‘åˆ°æ˜¾ç¤ºä¸­è§†çº¿çš„é®æŒ¡åŒæ ·ä¼šå¯¹ç‚¹äº‘æ•°æ®äº§ç”Ÿç›¸åŒçš„é®æŒ¡æ•ˆæœï¼Œè¿›è€Œå¯¹pasteæ•°æ®å¢å¼ºè¿›è¡Œä¸€å®šçš„é™åˆ¶ï¼Œå¹¶åŒæ—¶ä½œä¸ºä¸€ç§é¢å¤–çš„ç‰¹å¾åŠ å…¥pointpillarç‰¹å¾ä¸­ï¼Œä¸°å¯Œç‰¹å¾çš„ä¿¡æ¯ã€‚</em></li>
  <li><strong>Joint 3D Instance Segmentation and Object Detection for Autonomous Driving(CVPR2020)</strong><a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Zhou_Joint_3D_Instance_Segmentation_and_Object_Detection_for_Autonomous_Driving_CVPR_2020_paper.pdf">è®ºæ–‡é“¾æ¥</a>
<em>ä½¿ç”¨ä½¿ç”¨ç±»ä¼¼voteçš„æ–¹æ³•ï¼Œåœ¨ç»™å‡ºå‰æ™¯ç‚¹åˆ†ç±»çš„åŒæ—¶ï¼Œè®¡ç®—æ¯ä¸ªå‰æ™¯ç‚¹çš„åç§»ï¼Œé€šè¿‡èšç±»å¾—åˆ°proposalï¼ŒåŒæ—¶ç»“åˆäº†bboxå’Œsegmentationã€‚ä¸¤éƒ¨åˆ†å†…å®¹å¯ä»¥ç›¸äº’boostï¼Œç›¸å½“äºå¼•å…¥äº†æ›´å¤šçš„ç›‘ç£ã€‚ç”±äºé€šè¿‡èšç±»å¾—åˆ°proposal,å› æ­¤æ— éœ€nmsï¼Œæ¯ä¸ªèšç±»ï¼ˆç›®æ ‡ï¼‰åªæœ‰ä¸€ä¸ªproposalï¼Œæ•ˆç‡æ›´é«˜ã€‚</em></li>
</ol>

<h1 id="review">Review</h1>

<ol>
  <li><strong>Point-cloud based 3D object detection and classification methods for self-driving applications: A survey and taxonomy</strong><a href="https://www.sciencedirect.com/science/article/pii/S1566253520304097">è®ºæ–‡é“¾æ¥</a>: <em>ç»¼è¿°ï¼ŒåŸºäºç‚¹äº‘çš„è‡ªåŠ¨é©¾é©¶3Dç›®æ ‡æ£€æµ‹å’Œåˆ†ç±»æ–¹æ³•ã€‚</em></li>
</ol>

<h1 id="dataset">Dataset</h1>

<ol>
  <li>
    <p><strong>nuScenes: A multimodal dataset for autonomous driving</strong><a href="http://openaccess.thecvf.com/content_CVPR_2020/html/Sun_Scalability_in_Perception_for_Autonomous_Driving_Waymo_Open_Dataset_CVPR_2020_paper.html">è®ºæ–‡é“¾æ¥</a>: <em>nuScenesæ•°æ®é›†å‘è¡¨çš„è®ºæ–‡ï¼Œè¯¦ç»†ä»‹ç»äº†æ•°æ®é›†çš„æƒ…å†µã€‚</em></p>
  </li>
  <li>
    <p><strong>Scalability in Perception for Autonomous Driving: Waymo Open Dataset</strong><a href="http://openaccess.thecvf.com/content_CVPR_2020/html/Sun_Scalability_in_Perception_for_Autonomous_Driving_Waymo_Open_Dataset_CVPR_2020_paper.html">è®ºæ–‡é“¾æ¥</a>: <em>Waymoæ•°æ®é›†å‘è¡¨çš„è®ºæ–‡ï¼Œè¯¦ç»†ä»‹ç»äº†æ•°æ®é›†çš„æƒ…å†µã€‚</em></p>
  </li>
</ol>
:ET