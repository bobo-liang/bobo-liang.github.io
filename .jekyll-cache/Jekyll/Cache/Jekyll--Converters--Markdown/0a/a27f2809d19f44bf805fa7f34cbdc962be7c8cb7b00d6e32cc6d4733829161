I""<blockquote>
  <p>è®ºæ–‡é“¾æ¥ï¼š https://openaccess.thecvf.com/content_cvpr_2018/papers/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper.pdf
å‚è€ƒåšå®¢ ï¼š https://blog.csdn.net/qq_16936725/article/details/51147767</p>
</blockquote>

<h1 id="introduction">Introduction</h1>

<p>æœ¬æ–‡æå‡ºçš„æ— ç›‘ç£å­¦ä¹ çš„æ–°æ–¹æ³•æ¥è‡ªäºç‰©ä½“è¯†åˆ«é¢†åŸŸçš„å‡ ä¸ªå‘ç°ã€‚åœ¨ImageNetä¸Šï¼Œtop-5é”™è¯¯ç‡è¿œä½äºtop-1é”™è¯¯ç‡ï¼Œå¹¶ä¸”ç½®ä¿¡åº¦ç¬¬äºŒé«˜çš„ç±»åˆ«å¾€å¾€å’Œå›¾åƒæœ¬èº«å…·æœ‰è¾ƒé«˜çš„è§†è§‰å…³è”ã€‚å¦‚ä¸‹å›¾æ‰€ç¤º</p>

<p><img src="/assets/img/20210601/UFLNPIDF1.png" alt="" /></p>

<p>è¿™æ ·çš„å‘ç°è¯´æ˜discriminative learning methodå¯ä»¥è‡ªåŠ¨çš„å‘ç°è¯­ä¹‰ç±»åˆ«ä¸­æ˜¾è‘—çš„ç›¸ä¼¼æ€§ï¼Œè€Œä¸éœ€è¦ç‰¹åˆ«çš„æŒ‡å¼•ã€‚<strong>ä¹Ÿå°±æ˜¯è¯´ï¼Œè¿™ç§æ˜¾è‘—çš„ç›¸ä¼¼æ€§ä¸æ˜¯ä»è¯­ä¹‰æ ‡æ³¨ä¸­å­¦åˆ°çš„ï¼Œè€Œæ˜¯æ¥è‡ªäºè§†è§‰æ•°æ®æœ¬èº«</strong>ã€‚</p>

<p>å› æ­¤ä½œè€…æŠŠclass-wiseçš„ç›‘ç£ç”¨åˆ°instance-wiseçš„ç›‘ç£ä¸Šï¼Œæ˜¯å¦å¯ä»¥é€šè¿‡discriminative learningå­¦ä¹ åˆ°ä¸€ç§Metricï¼Œæ¥ååº”instanceä¹‹é—´æ˜¾è‘—çš„ç›¸ä¼¼æ€§ï¼Ÿæ¯ä¸ªimageéƒ½ä»¥ä»–ä»¬è‡ªå·±çš„å½¢å¼è¢«distinctï¼Œæ¯ä¸ªéƒ½æ˜¾è‘—çš„å’ŒåŒè¯­ä¹‰ç±»åˆ«çš„å…¶ä»–imagesä¸ä¸€æ ·ã€‚å¦‚æœæˆ‘ä»¬å­¦ä¼šå¦‚ä½•åŒºåˆ†ä¸¤ä¸ªç‹¬ç«‹çš„instanceï¼Œè€Œä¸ç”¨ä»»ä½•è¯­ä¹‰ç±»åˆ«ï¼Œ<strong>å¯èƒ½å°±å¯ä»¥å¾—åˆ°ä¸€ç§æ•æ‰instanceé—´æ˜¾è‘—ç›¸ä¼¼æ€§çš„è¡¨è¾¾ï¼Œå°±åƒclass-wiseæ•æ‰ç±»é—´ç›¸ä¼¼æ€§ä¸€æ ·ã€‚</strong>ã€‚ç”±äºè¿™ä¸ªæœ¬èº«ä¹Ÿæ˜¯ä¸€ä¸ªinstance-level discrimination çš„ä»»åŠ¡ï¼Œæ‰€ä»¥ä¹Ÿå¯ä»¥ä»æœ€æ–°çš„discriminative supervised learningä¸­è·å¾—å¥½å¤„ï¼Œæ¯”å¦‚æ–°çš„ç½‘ç»œç»“æ„ã€‚</p>

<p>ä½†æ˜¯ï¼Œæˆ‘ä»¬ä¹Ÿé‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œæ¯”å¦‚<strong>classesæ•°é‡</strong>æ•°é‡çš„æ¿€å¢ã€‚å¦‚æœä¸€ä¸ªå®ä¾‹æ˜¯ä¸€ä¸ªç±»åˆ«ï¼Œé‚£ä¹ˆImageNetå¯èƒ½æœ‰1.2Mä¸ªç±»åˆ«è€Œä¸æ˜¯100ç±»ï¼Œå› æ­¤softmaxæ˜¾å¾—ä¸å†å¯è¡Œã€‚å› æ­¤ä½¿ç”¨ä¸€ç§æ–¹æ³•æ¥æ¨¡æ‹Ÿsoftmaxçš„åˆ†å¸ƒï¼Œé€šè¿‡<strong>noise-contrastive estimation(NCE)</strong>,å¹¶åˆ©ç”¨ä¸€ä¸ª<strong>proximal regularization</strong>æ¥ç¨³å®šå­¦ä¹ è¿‡ç¨‹ã€‚</p>

<p>åœ¨è®­ç»ƒå’Œæµ‹è¯•è¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨äº†<strong>non-parametric approach</strong>ï¼Œå°†<strong>instance-level discrimination</strong>é—®é¢˜å˜ä¸ºä¸€ä¸ª<strong>metirc learning problem</strong>ã€‚ä¸¤ä¸ªå®ä¾‹ä¹‹é—´çš„è·ç¦»ç›´æ¥ä½¿ç”¨non-parameteic wayæ¥å®ç°ã€‚</p>

<h1 id="related-works">Related works</h1>
<p>ç•¥</p>

<h1 id="approach">Approach</h1>
<p><img src="/assets/img/20210601/UFLNPIDF2.png" alt="" /></p>

<p>ç›®çš„æ˜¯å­¦ä¹ ä¸€ä¸ªembedding functionï¼Œè€Œä¸ç”¨ç›‘ç£ã€‚å…¶è·ç¦»è¡¡é‡å¦‚ä¸‹
\(\begin{equation}
d_{\boldsymbol{\theta}}(x, y)=\left\|f_{\boldsymbol{\theta}}(x)-f_{\boldsymbol{\theta}}(y)\right\|
\end{equation}\)</p>

<h2 id="non-parametric-softmax-classifier">Non-Parametric Softmax Classifier</h2>

<h3 id="parametric-classifier">Parametric Classifier</h3>

<p>\(\begin{equation}
P(i \mid \mathbf{v})=\frac{\exp \left(\mathbf{w}_{i}^{T} \mathbf{v}\right)}{\sum_{j=1}^{n} \exp \left(\mathbf{w}_{j}^{T} \mathbf{v}\right)}
\end{equation}\)
å…¶ä¸­$v$æ˜¯ç½‘ç»œè¾“å‡ºçš„ç‰¹å¾ï¼Œ$w$æ˜¯ç±»åˆ«çš„æƒé‡å‘é‡ã€‚å¦‚æœç‰¹å¾ç»´åº¦æ˜¯128ï¼Œä¸€å…±120Mä¸ªå®ä¾‹ï¼ˆç±»åˆ«ï¼‰ï¼Œåˆ™è¿™ä¸€å±‚çš„å‚æ•°è¶…è¿‡15äº¿ï¼Œè¿™æ˜¯ä¸å¯æ¥å—çš„ã€‚</p>

<h3 id="non-parametric-classifier">Non-Parametric Classifier</h3>

\[\begin{equation}
P(i \mid \mathbf{v})=\frac{\exp \left(\mathbf{v}_{i}^{T} \mathbf{v} / \tau\right)}{\sum_{j=1}^{n} \exp \left(\mathbf{v}_{j}^{T} \mathbf{v} / \tau\right)}
\end{equation}\]

<p><strong>å…¶ä¸­$\tau$æ˜¯æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶äº†åˆ†å¸ƒçš„concentration(é›†ä¸­åº¦?)</strong>ï¼Œå®ƒå¯¹äºç›‘ç£å­¦ä¹ å¾ˆé‡è¦ï¼Œåœ¨è¿™é‡Œï¼ŒåŒæ ·å¯¹<strong>tuning the concentration of v on our unit sphere</strong>å¾ˆå¿…è¦ã€‚</p>

<p>å­¦ä¹ ç›®æ ‡æ˜¯æœ€å¤§åŒ–è”åˆæ¦‚ç‡å¯†åº¦ï¼Œä¹Ÿå°±æ˜¯æœ€å°åŒ–è´Ÿå¯¹æ•°ä¼¼ç„¶
\(\begin{equation}
J(\boldsymbol{\theta})=-\sum_{i=1}^{n} \log P\left(i \mid f_{\boldsymbol{\theta}}\left(x_{i}\right)\right)
\end{equation}\)</p>

<h3 id="learning-with-a-memory-bank">Learning with A Memory Bank</h3>

<p>ä¸ºäº†è®¡ç®—ä¸Šè¿°çš„æ¡ä»¶æ¦‚ç‡ï¼Œéœ€è¦${v_i}$ for all the imagesã€‚ä¸ºäº†é¿å…æ¯æ¬¡éƒ½è®¡ç®—äº§ç”Ÿçš„å·¨å¤§è®¡ç®—é‡ï¼Œæ‰€ä»¥éœ€è¦ç»´æŠ¤ä¸€ä¸ªfeature memory bank V æ¥å­˜å‚¨æ‰€æœ‰å›¾ç‰‡çš„ç‰¹å¾ã€‚å­—å…¸Vé‡Œçš„æ‰€æœ‰è¡¨è¾¾ç”¨éšæœºçš„å‘é‡æ¥åˆå§‹åŒ–ã€‚å½“ä¸€ä¸ªæ–°çš„ç‰¹å¾è¿›å…¥äº†å­—å…¸å³å®Œæˆäº†æ›´æ–°ã€‚</p>

<h2 id="noise-contrastive-estimation">Noise-Contrastive Estimation</h2>

<p>ä½¿ç”¨NCEæ¥æ¨¡æ‹Ÿfull=softmaxã€‚ä½†æ˜¯é¿å…è®¡ç®—å…¨éƒ¨instanceçš„ç›¸ä¼¼åº¦ï¼Œå°†è¿™ä¸ªé—®é¢˜è½¬æ¢ä¸ºä¸€ä¸ªäºŒåˆ†ç±»é—®é¢˜ã€‚å…¶åŸºæœ¬æ€æƒ³æ˜¯å°†å¤šåˆ†ç±»ä»»åŠ¡è½¬åŒ–ä¸ºä¸€ç³»åˆ—äºŒåˆ†ç±»ä»»åŠ¡ï¼ŒäºŒåˆ†ç±»ä»»åŠ¡æ˜¯åˆ¤æ–­æ ·æœ¬æ˜¯æ¥è‡ªä¸çœŸå®æ•°æ®è¿˜æ˜¯å™ªå£°æ•°æ®ã€‚ç‰¹åˆ«çš„ï¼Œæˆ‘ä»¬å°†æ¦‚ç‡æ”¹å†™ä¸º
\(\begin{equation}
P(i \mid \mathbf{v})=\frac{\exp \left(\mathbf{v}^{T} \mathbf{f}_{i} / \tau\right)}{Z_{i}} 
\end{equation}\)
\(\begin{equation}
Z_{i}=\sum_{j=1}^{n} \exp \left(\mathbf{v}_{j}^{T} \mathbf{f}_{i} / \tau\right)
\end{equation}\)</p>

<p>åŒæ—¶åˆ’å®šå™ªå£°æœä»å‡åŒ€åˆ†å¸ƒ\(P_{n}=1 / n\)</p>

<p>å‡è®¾å™ªå£°må€å¤šä½™data samplesï¼Œåˆ™sample $i$å’Œfeature$\bold{v}$æ¥è‡ªäºdata distributionçš„åå»¶æ¦‚ç‡ä¸º</p>

\[\begin{equation}
h(i, \mathbf{v}):=P(D=1 \mid i, \mathbf{v})=\frac{P(i \mid \mathbf{v})}{P(i \mid \mathbf{v})+m P_{n}(i)}
\end{equation}\]

<p>å¯¹è¿™ä¸ªåéªŒæ¦‚ç‡è¿›è¡Œä¼˜åŒ–å¾—åˆ°
\(\begin{equation}
\begin{aligned}
J_{N C E}(\boldsymbol{\theta}) &amp;=-E_{P_{d}}[\log h(i, \mathbf{v})] \\
&amp;-m \cdot E_{P_{n}}\left[\log \left(1-h\left(i, \mathbf{v}^{\prime}\right)\right)\right] .
\end{aligned}
\end{equation}\)</p>

<p>ç”±äºä¸Šè¿°çš„åˆ†æ¯è®¡ç®—é‡å¾ˆå¤§ï¼Œæ‰€ä»¥å°†å…¶è§†ä¸ºä¸€ä¸ªå¸¸æ•°ï¼Œä½¿ç”¨Monte Carlo approximationã€‚
\(\begin{equation}
Z \simeq Z_{i} \simeq n E_{j}\left[\exp \left(\mathbf{v}_{j}^{T} \mathbf{f}_{i} / \tau\right)\right]=\frac{n}{m} \sum_{k=1}^{m} \exp \left(\mathbf{v}_{j_{k}}^{T} \mathbf{f}_{i} / \tau\right)
\end{equation}\)</p>

<h2 id="proximal-regularization">Proximal Regularization</h2>
<p><img src="/assets/img/20210601/UFLNPIDF3.png" alt="" /></p>

<p>ç”±äºæ‰€æœ‰çš„ç±»åˆ«ï¼ˆä¸€ä¸ªinstanceå°±æ˜¯ä¸€ä¸ªç±»åˆ«ï¼‰åœ¨æ¯ä¸ªepochåªéå†ä¸€æ¬¡ï¼Œæ‰€ä»¥å­¦ä¹ è¿‡ç¨‹å¯èƒ½ä¼šç”±äºé‡‡æ ·æ³¢åŠ¨è€Œäº§ç”Ÿéœ‡è¡ï¼Œæ‰€ä»¥åŠ å…¥ä¸€ä¸ªæ­£åˆ™é¡¹ï¼Œæ¥é¼“åŠ±å…‰æ»‘çš„å­¦ä¹ æ›²çº¿ï¼Œå¦‚ä¸‹ã€‚
\(\begin{equation}
-\log h\left(i, \mathbf{v}_{i}^{(t-1)}\right)+\lambda\left\|\mathbf{v}_{i}^{(t)}-\mathbf{v}_{i}^{(t-1)}\right\|_{2}^{2}
\end{equation}\)</p>

<p>è¿™æ ·æœ€ç»ˆçš„æŸå¤±å˜ä¸º</p>

\[\begin{equation}
\begin{aligned}
J_{N C E}(\boldsymbol{\theta}) &amp;=-E_{P_{d}}\left[\log h\left(i, \mathbf{v}_{i}^{(t-1)}\right)-\lambda\left\|\mathbf{v}_{i}^{(t)}-\mathbf{v}_{i}^{(t-1)}\right\|_{2}^{2}\right] \\
&amp;-m \cdot E_{P_{n}}\left[\log \left(1-h\left(i, \mathbf{v}^{\prime(t-1)}\right)\right)\right]
\end{aligned}
\end{equation}\]

<h2 id="weighted-k-nearest-neighbor-classifier">Weighted k-Nearest Neighbor Classifier</h2>

<p>ä½¿ç”¨KNNä½œä¸ºæœ€ååˆ†ç±»çš„ä¾æ®ï¼Œè€Œä¸æ˜¯SVMï¼Œå®éªŒè¡¨æ˜KNNå…·æœ‰æ›´å¥½çš„æ€§èƒ½ã€‚</p>
:ET