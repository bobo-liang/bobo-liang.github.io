I"M><blockquote>
  <p>论文链接 ：https://proceedings.neurips.cc/paper/2020/file/821fa74b50ba3f7cba1e6c53e8fa6845-Paper.pdf
参考博客 ：https://zhuanlan.zhihu.com/p/269112325
本文基本复制了原作者的博客，放在这里方便自己查阅而已。</p>
</blockquote>

<h1 id="背景简介">背景简介</h1>
<p>近年来，在无监督学习的浪潮下，无监督及领域自适应的目标重识别任务也逐渐受到大家的关注，在刚刚过去的ECCV2020中这个方向所发表的论文就有十余篇。</p>

<p><strong>目标重识别（Object Re-ID</strong>，包括行人重识别、车辆重识别等，旨在跨摄像机检索和追踪目标人物或车辆。重识别任务的关键之一是学习具有辨识性的特征，并在多样的条件变化下保持鲁棒性。在如今深度学习盛行的时代，大规模数据集推动了目标重识别任务的快速发展，然而，领域差异及标注数据的高消耗等都成为了部署重识别算法中无法忽视的问题。</p>

<p><strong>领域自适应的目标重识别（Domain Adaptive Object Re-ID</strong>旨在通过源域有标注的数据和目标域无标注的数据进行训练，从而在目标域上取得较好的性能。这里区分一下一般分类任务上的领域自适应，分类任务上的两个领域的类别往往有部分或者全部的重叠，而重识别任务上的两个领域，我们一般认为类别完全没有重复。这是由于领域自适应的重识别任务一般应用在：将城市A训练的重识别模型应用于城市B、将虚拟合成数据训练的重识别模型应用于真实世界的场景等。在这些场景中，两个领域间的类别一般很难存在重复。</p>

<p><strong>无监督的目标重识别（Unsupervised Object Re-ID</strong>与上述领域自适应重识别非常相似，问题设置上的唯一区别在于没有有标签的源域数据。这里着重区分一下目前很受关注的无监督预训练（Unsupervised Pre-training）任务，存在两点主要区别：1）无监督预训练任务从网络随机初始化开始，无监督重识别任务从预训练好的网络开始；2）无监督预训练的网络需要经过fine-tune才可以应用在下游任务上，而无监督重识别任务本身可以看作一个无监督的下游任务，经过训练的网络可直接部署。</p>

<p>领域自适应重识别任务的研究历史较无监督重识别任务而言较长一些，但本质上这两项任务是非常相似的。正如上文所述，领域自适应重识别任务相较于无监督重识别任务而言，只是在问题设置上多出了有标签的源域数据。所以，大部分的算法也都可以通用，因为很多领域自适应重识别算法只需要去除源域预训练的步骤，即可应用于无监督重识别任务上。该论文所介绍的方法在这两项任务上也都取得了很不错的结果。</p>

<p>下面，将先以领域自适应重识别任务为例介绍方法，再讲解如何应用于无监督重识别任务。</p>

<h1 id="问题与动机">问题与动机</h1>

<p>解决领域自适应重识别任务的算法可以分为两类，伪标签类和域转换类，目前伪标签类可以获得更好的性能，而伪标签类中的基于聚类的伪标签法较为有效，所以本文所基于的baseline是<strong>基于聚类的伪标签算法</strong>。</p>

<p>目前大部分基于聚类的伪标签算法（如SSG、MMT等）在训练上分为<strong>两步</strong>：第一步，在源域上利用有标签的源域数据进行有监督的预训练；第二步，在预训练的模型基础上，利用目标域无标签的数据及其聚类产生的伪标签进行fine-tune。</p>

<p>这样的算法流程目前已经可以获得相对令人满意的结果，但他们仍然存在两点<strong>缺陷</strong>：</p>

<p>1）在第二步的目标域训练中忽略了源域数据（仅用于预训练），但我们认为源域的数据由于<strong>具有真实准确的标签</strong>，所以应当被充分利用；</p>

<p>2）在基于聚类的伪标签法中，往往没有用到全部的目标域无标签数据，因为基于密度的聚类（如DBSCAN等）本身会产生聚类离群值（outlier），这些聚类离群值由于无法分配伪标签，所以被丢弃，不用于训练。但我们认为，这样的聚类离群值往往正是那些<strong>值得挖掘的困难训练样本</strong>。尤其在训练的早期，往往存在大量的聚类离群值，若简单丢弃它们，训练样本将大幅减少。</p>

<p><img src="/assets/img/20210531/SCLF1.png" alt="" /></p>

<p>所以如何<strong>合理地挖掘所有可用的信息</strong>是提升性能的关键。如上图所示，我们提出在训练中使用全部的源域数据和目标域数据，并利用一个混合记忆模型（Hybrid Memory）来提供监督：对于源域数据而言，监督是他们真实的标签；对于目标域聚类内的数据而言，监督是他们的聚类标签；对于目标域的聚类离群值而言，他们每张图本身被看作一个单独的类，所以监督是实例级的标签。<strong>我们将所有的源域类、目标域聚类、目标域每个聚类离群值实例看成平等的类别</strong>。</p>

<h1 id="自步对比学习框架">自步对比学习框架</h1>

<p>以下是我们所提出自步对比学习（Self-paced Contrastive Learning）框架，包括一个图像特征编码器（Encoder）和一个混合记忆模型（Hybrid Memory）。核心是混合记忆模型在动态变化的类别下所提供的连续有效的监督，以统一对比损失函数（Unified Contrastive Loss）的形式监督网络更新，实现起来非常容易，且即插即用。下文将具体介绍。</p>

<p><img src="/assets/img/20210531/SCLF2.png" alt="" /></p>

<h1 id="统一对比损失函数">统一对比损失函数</h1>
<p><strong>类别原型（Class Prototype）</strong>可以理解为该类别中较为有标志的特征，例如无偏分类器中的权重（Weights）。在这里，我们使用<strong>源域真实类别的类质心（Class Centroids）</strong>作为源域数据的类别原型{w}，使用<strong>目标域聚类的质心（Cluster Centroids）</strong>作为聚类内的目标域数据的类别原型{c}，使用<strong>目标域聚类离群值的实例特征（Outlier Instance Features）</strong>作为无聚类的目标域数据的类别原型{v}。我们所提出的混合记忆模型可以实时提供这三种类别原型以作训练监督，后文将具体介绍这三种类别原型的更新过程。</p>

<p>对于每一组输入的mini-batch，同时包含源域数据和目标域数据（我们在编码器中使用Domain-specific BNs来消除不同领域数据间的域差异），他们需要与上述三种类别原型进行比较。所以我们提出<strong>统一对比损失函数（Unified Contrastive Learning）</strong>：</p>

\[\begin{equation}
\mathcal{L}_{f}=-\log \frac{\exp \left(\left\langle\boldsymbol{f}, \boldsymbol{z}^{+}\right\rangle / \tau\right)}{\sum_{k=1}^{n^{s}} \exp \left(\left\langle\boldsymbol{f}, \boldsymbol{w}_{k}\right\rangle / \tau\right)+\sum_{k=1}^{n_{c}^{t}} \exp \left(\left\langle\boldsymbol{f}, \boldsymbol{c}_{k}\right\rangle / \tau\right)+\sum_{k=1}^{n_{o}^{t}} \exp \left(\left\langle\boldsymbol{f}, \boldsymbol{v}_{k}\right\rangle / \tau\right)}
\end{equation}\]

<p>该损失函数可以使得每个训练样本靠近它所属于的类别（包含源域真实类、目标域聚类、目标域无聚类实例），而远离其他类别。举例来说，对于一个来自源域的样本，其对应的<strong>正面原型（Positive Prototype）</strong>则是它真实类别所对应的质心（Class Centroids）；对于一个来自目标域的样本，若其在聚类内，则正面原型为其所对应的聚类质心（Cluster Centroids），反之，若其不在聚类内，为聚类离群值，则正面原型为该离群值所对应的实例特征（Outlier Instance Features）。<strong>个人认为相当于最大化类间距离，最小化类内距离。</strong></p>

<p>其实，我们所设计的“混合记忆模型（Hybrid Memory）+统一对比损失函数（Unified Contrastive Loss）”与大家常用的“分类器（Classifier）+交叉熵损失函数（Cross-entropy Loss）”在工作机理上非常相似，<strong>可以简单的认为混合记忆模型是非参数化（Non-parametric）的分类器</strong>。</p>

<p>那么，为什么我们不用普通分类器来完成这一任务呢？这是由于目标域的聚类及聚类离群值在训练过程中动态变化（一般每个epoch前更新），无法使用固定的聚类ID及离群值实例ID训练分类器。如若在每次更新完ID后需要重置分类器，分类器由于无法连续更新，会导致性能较差。有同学会问，以前的算法（如MMT），每个epoch重置分类器依然训练效果很好，这是为什么？这是因为这些算法不使用聚类离群值进行训练。试想，将每个聚类离群值也看做单独的类加入分类器，而每个epoch只能遍历到该类对应的样本一次（因为一个离群值是一个类），那么，在类样本数如此不平均的情况下，分类器几乎得不到有效的训练，便会被重置。</p>

<p>我们所提出的统一对比损失函数与自监督任务（如MoCo、SimCLR等）中常用的对比损失函数最主要的区别在于，我们同时考虑了<strong>三种不同的类别原型</strong>，而以前的对比损失函数只考虑实例级的类别原型。他们将所有样本看作独立的类，进行实例区分（Instance Discrimination）训练，这样的算法很大程度上忽略了类内（Intra-class）关系，也就是同一ID的不同图像间的联系，故以前的对比损失函数不适用于重识别任务。</p>

<h1 id="混合记忆模型">混合记忆模型</h1>
<p>上文中，我们提到混合记忆模型（Hybrid Memory）实时提供三种不同的类别原型，那么，这三种类别原型是如何动态地在混合记忆模型中连续更新变化的呢？我们提出使用动量更新（Momentum Update），想必这个词对大家来说并不陌生，在MoCo、Mean-teacher等模型中常有见到，简单来说，就是以“参数= (1-动量)x新参数+动量x参数”的形式更新。在这里，我们针对源域和目标域采取不同的动量更新算法，以适应其不同的特性。</p>

<p>对于源域的数据而言，由于具有真实的类别，我们提出以<strong>类为单位进行存储</strong>。这样的操作一方面节省空间，一方面在实验中也取得了较好的结果。我们将当前mini-batch内的源域特征根据类别算均值，然后以动量的方式累计到混合记忆模型中对应的类质心上去，详见下图。</p>

<p><img src="/assets/img/20210531/SCLFZ1.png" alt="" /></p>

<p>对于<strong>目标域</strong>的数据而言，我们提出<strong>全部以实例为单位进行特征存储</strong>，这是为了让目标域样本即使在聚类和非聚类离群值不断变化的情况下，仍然能够在混合记忆模型中持续更新（Continuously Update）。具体而言，我们将当前mini-batch内的目标域特征根据实例的index累计到混合记忆模型对应的实例特征上去。
<img src="/assets/img/20210531/SCLFZ2.png" alt="" /></p>

<p>那么，如何获得目标域的聚类质心及离群值实例特征呢？我们在混合记忆模型中，将同一聚类ID的特征做平均，即可获得<strong>聚类质心</strong>；而<strong>离群值的实例特征</strong>则直接从混合记忆模型中提取剩下的实例特征即可，如下图。</p>

<p><img src="/assets/img/20210531/SCLFZ3.png" alt="" /></p>

<p>#由简入难的自步学习
我们发现，由于聚类和聚类离群值都被看作平等且独立的类，所以聚类的可靠性对训练的影响至关重要。由于网络在训练的一开始对于图像的辨别性较差，聚类的噪声也较大。所以我们借鉴<strong>自步学习（Self-paced Learning）</strong>的思想，先从最可靠的聚类开始，再逐步增加聚类，由简入难。我们提出了一个<strong>聚类可靠性评价标准（Cluster Reliability Criterion）</strong>，保留可靠的聚类，而将不可靠的聚类拆解回无聚类的离群值实例。我们所提出的聚类可靠性评价标准分为聚类独立性（Cluster Independence）和聚类紧凑型（Cluster Compactness）。</p>

<p><strong>聚类独立性（Cluster Independence）</strong>体现为一个可靠的聚类应当具有良好的类间距离，通俗点来说，不能和附近的聚类“如胶似漆”。我们提出，放宽聚类的标准，例如DBSCAN中的最小类内距离，此时，如果该聚类与周围的聚类融合成了一个大聚类、或者吸收了附近的离群值，那么我们认为，该聚类的独立性不太好。</p>

<p><img src="/assets/img/20210531/SCLFZ4.png" alt="" /></p>

<p>我们使用一个IoU（Intersection over Union）公式来计算聚类的独立性。</p>

<p><strong>聚类紧凑型（Cluster Compactness</strong>）体现为一个可靠的聚类内的样本应该相互靠近，具有良好的类内距离。类似的，我们提出，缩紧聚类的标准，此时，如果该聚类被拆解成了多个小聚类、或者拆出了一些聚类离群值，那么我们认为，该聚类的紧凑型不太好。
<img src="/assets/img/20210531/SCLFZ5.png" alt="" /></p>

<p>我们使用另一个IoU公式来计算聚类的紧凑型，如上图所示。</p>

<p>直观地说，该聚类可靠性评价标准的出发点在于，<strong>一个可靠的聚类应当在多尺度的聚类环境下保持稳定</strong>。从下图训练的统计中可以看出，使用了聚类可靠性评价标准的模型（红色线）相比较于未使用的模型（蓝色线），无论是在聚类的数量还是质量上，都离真实类别更近。
<img src="/assets/img/20210531/SCLFZ6.png" alt="" /></p>

<h1 id="算法流程">算法流程</h1>
<p>以上，我们介绍了核心的模块，我们梳理一下具体训练流程：</p>

<p><strong>初始化（Initialization）</strong>：图像编码器（Encoder）的初始化一般使用ImageNet Pre-trained Weights，混合记忆模型（Hybrid Memory）的初始化使用初始的编码器对所有的样本进行一次前向计算。</p>

<p><strong>聚类和聚类离群值</strong>：在每个epoch前进行聚类，并根据聚类可靠性评价标准（Cluster Reliability Criterion）进行聚类的筛选，仅保留可靠的聚类，其余样本均视作聚类离群值。</p>

<p><strong>网络和混合记忆模型的更新</strong>：在每个iteration中，首先利用编码器对mini-batch的样本进行特征编码，然后利用统一对比损失函数（Unified Contrastive Loss）进行网络的反向传播更新，最后利用编码的特征以动量更新（Momentum Update）的方式更新混合记忆模型（Hybrid Memory）。</p>

<h1 id="无监督重识别上的应用">无监督重识别上的应用</h1>
<p>在一开始曾提到，该方法也可以被有效利用在无监督重识别任务上，只需要将<strong>混合记忆模型和统一对比损失函数中有关源域的部分去掉即可</strong>。</p>

<p>无监督重识别任务上的自步对比学习框架如下：</p>

<p><img src="/assets/img/20210531/SCLFZ7.png" alt="" /></p>

<p>对应的统一对比损失函数如下：</p>

\[\begin{equation}
\mathcal{L}_{f}=-\log \frac{\exp \left(\left\langle f, z^{+}\right\rangle / \tau\right)}{\sum_{k=1}^{n_{c}^{t}} \exp \left(\left\langle f, c_{k}\right\rangle / \tau\right)+\sum_{k=1}^{t_{o}^{t}} \exp \left(\left\langle f, v_{k}\right\rangle / \tau\right)}
\end{equation}\]

:ET