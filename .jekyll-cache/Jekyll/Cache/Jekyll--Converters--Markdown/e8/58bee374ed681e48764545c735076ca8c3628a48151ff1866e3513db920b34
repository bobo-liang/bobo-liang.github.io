I"<blockquote>
  <p>论文链接： https://openaccess.thecvf.com/content/CVPR2021/html/Xu_PAConv_Position_Adaptive_Convolution_With_Dynamic_Kernel_Assembling_on_Point_CVPR_2021_paper.html</p>
</blockquote>

<p>提出一种利用Weight Bank对点进行直接卷积的方法，通过Weight Bank中的多重权重以及自适应选择，来对于点之间的不同相对位置关系（不同的ralationship），来选择其最适合的权重。计算复杂度低，同时也可以更灵活的捕捉点之间的信息。</p>

<h1 id="introduction">Introduction</h1>

<p><img src="/assets/img/20210802/PAConvF1.png" alt="" /></p>

<p>已经有许多工作来设计类似卷积的点云操作。</p>

<p>其中一些方法直接预测kernel weights，基于相对位置信息。典型的代表是PointConv。尽管在理论上是有效的，但是其方法的计算和内存复杂度都较高，由于spatial-variant kernal prediction。其高效实现在设计灵活性上做了妥协，导致性能的下降。</p>

<p>另一种方法是KPConv这样的，使用相关或者插值函数来调整kernels的权重。但是其Kernels的combination是hand-crafted的，可能不是最优的，或者不足以对复杂的3D位置变化进行建模。</p>

<p>本文提出的方法是<strong>Position Adaptive Convolution</strong>，也就是PAConv。其动态的对Weight Bank中的 basic weight matrices 进行assembling。 其融合的系数通过MLP来学习，也就是ScoreNet。</p>

<h1 id="related-work">Related Work</h1>

<p>主流的对点云处理的方法主要有如下几种</p>

<h2 id="mapping-point-clouds-into-regular-2d-or-3d-gridsvoxels">Mapping point clouds into regular 2D or 3D grids(voxels)</h2>

<p>向2D投影会损失3D几何信息，而3D体素化则会使得精确的位置信息受到损失。总之，这永远要面对效率和量化精度的trade-off。</p>

<h2 id="point-representation-learning-with-mlps">Point representation learning with MLPs</h2>

<p>比如PointNet及其发展。但是他们都使用共享的MLP来对点云特征进行转换，这可能会限制模型来捕捉spatial-variant information的能力。</p>

<h2 id="point-representation-learning-with-point-convolutions">Point representation learning with point convolutions</h2>

<p>有些方法直接学习Kernal或者通过预定义的Kernal来进行点卷积。其缺点分别是计算成本高，和非最优。而本文提出的方法动态的结合权重，是的模型具有更强的来适应非规律化的点云的能力。</p>

<h2 id="dynamic-and-conditioned-convolutions">Dynamic and conditioned convolutions</h2>

<p>略</p>

<h1 id="method">Method</h1>

<h2 id="overview">Overview</h2>
<p>一般化的卷积可以建模如下</p>

\[\begin{equation}
g_{i}=\Lambda\left(\left\{\mathcal{K}\left(p_{i}, p_{j}\right) f_{j} \mid p_{j} \in \mathcal{N}_{i}\right\}\right)
\end{equation}\]

<p>一般2D卷积的kernal是一个一对一的权重，因为网格化的数据距离都是确定的若干个值。但是点云是连续值，所以这种一对一映射不适合3D点云数据。所以本文重新设计kernal function,使其学习一个position-adaptive mapping by dynamic kernel assembly。</p>

<p>首先，定义一个Weight Bank，由若干个权重矩阵组成，然后通过一个ScoreNet 来学习一个系数向量，来融合这些权重矩阵，根据点的位置。最后，dynamic kernels通过结合这些权重矩阵来得到。如下图所示。</p>

<p><img src="/assets/img/20210802/PAConvF2.png" alt="" /></p>

<h2 id="dynamic-kernel-assembling">Dynamic Kernel Assembling</h2>

<p>经过试验，作者发现Weight Bank中的权重矩阵的数量为8/16为最优。</p>

<p>Score就是一个简单的MLP,最后通过一个归一化函数输出，以得到概率值。这个函数可以是softmax，或者其他的。</p>

\[\begin{equation}
\mathcal{S}_{i j}=\alpha\left(\theta\left(p_{i}, p_{j}\right)\right)
\end{equation}\]

<p>最后的kernel表示如下</p>

\[\begin{equation}
\mathcal{K}\left(p_{i}, p_{j}\right)=\sum_{m=1}^{M}\left(S_{i j}^{m} B_{m}\right)
\end{equation}\]

<h2 id="weight-regularization">Weight Regularization</h2>
<p>为了防止Weight Bank中的权重彼此太相似，这里加入了一个正则项，来限制他们的相似度。</p>

\[\begin{equation}
\mathcal{L}_{\text {corr }}=\sum_{B_{i}, B_{j} \in \mathcal{B}, i \neq j} \frac{\left|\sum B_{i} B_{j}\right|}{\left\|B_{i}\right\|_{2}\left\|B_{j}\right\|_{2}} .
\end{equation}\]

<h2 id="backbone-network-architectures">Backbone Network Architectures</h2>
<p>本文提出的方法是一个plug-and-play的方法，因此可以适用于多种Backbone，实验中分别在PointNet，DGCNN和PointNet++上使用了这个方法，取得了一定的性能提升。</p>

<h1 id="experiments">Experiments</h1>

<p><img src="/assets/img/20210802/PAConvT1.png" alt="" /></p>

<h1 id="code">Code</h1>

<p>上述的aggregation实际相当于两次求和，每个点对算得到M个分数，加权得到该点对对应的动态核。之后一个点所有的近邻点特征乘以对应的动态和，sum得到最终的输出特征。这个计算量比较繁琐，作者直接使用cuda编程实现，大大提高了效率。</p>

<p>在CUDA实现上，没有按照PointNet++的方式，而是换了一个流程，如下所示。</p>

<p><img src="/assets/img/20210802/PAConvFD1.png" alt="" /></p>
:ET