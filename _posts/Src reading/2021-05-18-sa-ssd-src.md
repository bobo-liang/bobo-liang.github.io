---
layout: post
title: 'SA-SSD 源码阅读'
date: 2021-05-18
author: Poley
cover: '../assets/img/20210518/SASSD.png'
tags: 源码阅读
---

> 参考代码 https://github.com/skyhehe123/SA-SSD
> 参考文献 CVPR 2020 Structure Aware Single-stage 3D Object Detection from Point Cloud
> 论文地址 https://openaccess.thecvf.com/content_CVPR_2020/html/He_Structure_Aware_Single-Stage_3D_Object_Detection_From_Point_Cloud_CVPR_2020_paper.html

今天来阅读CVPR2020 的SA-SSD代码，代码基于mmdet框架实现。正好学习一下如何使用mmdet自定义目标检测网络。

由于mmcv的网络定义格式，网络结构都写在config文件里，因此不妨就从config文件中来一层层的观察网络的结构。

首先是model，config如下

``` python
model = dict(
    type='SingleStageDetector',
    backbone=dict(
        type='SimpleVoxel',
        num_input_features=4,
        use_norm=True,
        num_filters=[32, 64],
        with_distance=False),

    neck=dict(
        type='SpMiddleFHD',
        output_shape=[40, 1600, 1408],
        num_input_features=4,
        num_hidden_features=64 * 5,
    ),
    bbox_head=dict(
        type='SSDRotateHead',
        num_class=1, #len(['Car', 'Pedestrian', 'Cyclist']),
        num_output_filters=256,
        num_anchor_per_loc=2,
        use_sigmoid_cls=True,
        encode_rad_error_by_sin=True,
        use_direction_classifier=True,
        box_code_size=7,
    ),
    extra_head=dict(
        type='PSWarpHead',
        grid_offsets = (0., 40.),
        featmap_stride=.4,
        in_channels=256,
        num_class=1,
        num_parts=28,
    )
)
```

可以看到，backbone中使用了**SimpleVoxel**，实际上，SA-SSD中提出的Input data representation指出，将输入点放到稀疏的3Dtensor中并逐体素的提取特征非常的浪费时间。因此使用了简单的表示方法，即通过floor计算每个点归属的体素，并将这个点的4维信息作为这个体素的特征，如果有新点被划分到同一体素内，则直接替换。

在代码实现中，实际上是用了平均的方法来代替。并将Input data representation 单独作为网络的backbone，而真正的特征提取工作都在neck中。

```python
class SimpleVoxel(nn.Module):
    def __init__(self,
                 num_input_features=4,
                 use_norm=True,
                 num_filters=[32, 128],
                 with_distance=False,
                 name='VoxelFeatureExtractor'):
        super(SimpleVoxel, self).__init__()
        self.name = name
        self.num_input_features = num_input_features

    def forward(self, features, num_voxels):
        #相当于没有进行vef，直接对每个voxel做归一化处理。
        #return features
        # features: [concated_num_points, num_voxel_size, 3(4)]
        # num_voxels: [concated_num_points]
        points_mean = features[:, :, :self.num_input_features].sum(
            dim=1, keepdim=False) / num_voxels.type_as(features).view(-1, 1)
        return points_mean.contiguous()

```


在代码的neck部分中，实际上包含了backbone,rpn以及auxiliary network的全部内容（包含perdictor）。连接backbone和auxliary的模块为**tensor2points**，具体内容还没有完全理解。一会需要通过调试再看一下。


backbone的内容包括在文件**mmdet/models/necks/cmn.py**，其中**SpMiddleFHD**包含了3D稀疏卷积backbone **Vxnet**，辅助网络结构、预测以及target的生成。后续的真正的neck，也就是2D卷积部分，则由**BEVNet**来实现。

主网络的head在**mmdet/models/single_stage_heads/ssd_rotate_head.py**中，继承了[SECOND](https://www.mdpi.com/1424-8220/18/10/3337)中的编码方法，主要是角度使正弦余弦值来进行编码，以及使用一个简单的分类器来预测角度。即目标框的yaw是否大于0来决定分类器的类别。

最后加入了一个extrahead **PSWarpHead**，用来解决分类和回归中心不对齐的问题。后面这些还需要进入调试环境进一步熟悉一下。故先没有写出详细的解读。