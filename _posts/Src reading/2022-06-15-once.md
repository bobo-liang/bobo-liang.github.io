---
layout: post
title: 'ONCE Benchmark（基于OpenPCDet的半监督和无监督框架）源码原理阅读'
date: 2022-06-15
author: Poley
cover: '../assets/img/mycat3.jpg'
tags: 源码阅读
---

在数据存储格式上，Once数据集分为若干个sequences，数据的标注或无标注是以sequence为单位的。数据集中只有少量几个sequences是具有标注的。在数据集划分上，进一步的，将这部分标注数据划分为训练集train split和验证集validation spilt。剩余大量数据均为无标签数据，除了一小部分是用于线上测试的测试集test split，其余都是用于进行半监督和无监督训练的。为了便于训练，这里进一步将无标签数据分别采样出三个大小，small,medium和large，以更方便的根据计算资源对算法进行测试。

在有监督训练上，本框架与Openpcdet一致，不再赘述。本文主要关注于Once代码对于三维点云目标检测的半监督和无监督框架构建。

在半监督数据集的划分上，主要分为四个部分，分别是
+ Pretrain
+ Labeled
+ Unlabeled
+ Validation

其中，Pretrain和Labeled包含的数据相同，只是使用的位置不同。Pretrain用于teacher模型的预训练，而Labeled数据用于在半监督训练中和Unlabeled数据混合使用，组成batch。Validation用于各种训练结果的验证。

注意，尽管pretrain和labeled使用相同的数据，但是两个是单独的类。因为labled相比pretrain提供了更多的功能（即在半监督模型中，同时向teacher，student两个模型提供数据，两者分别使用不同的数据增广方法），而unlabeled类同样提供了类似的功能，只是没有标签而已。

代码中使用yaml中的USE_PRETRAIN_MODEL来读取预训练模型，使得训练跳过pretrain部分。但是这部分并不能通过命令行指定，不是很方便。

在训练时，源码中标注
```
  Notes: we found for pseudo labels, teacher_model.eval() is better; for EMA update and consistency, teacher_model.train() is better
```

注意，为了实现dist训练，作者还对student和teacher模型进行了一个warpper包装，一边其可以方便的接受来着两个dataloader的输入。


半监督训练时，每个epoch的iter数是由labeled data决定的，即每个epoch由指定数量的labeled data和unlabeled data组成。程序中，这个默认的比例是1：4。在实际程序中，由于unlabeled和labeled data的比例不可能总是和batch中设置的比例相同，因此可能会出现一个loader全部读完，另一个还没读完的情况。此时如果要继续，则对读完的loader开启一个新的Iter，直到完成epoch指定的iter数量为止。 

在前向推导上，这里主要分为三种模式，分别是origin，teacher和student。其中，origin是和普通模型相同的模式，在训练情况下给定输入，返回损失等训练信息，eval模式下返回预测结果。teacher模式中，网络对于所有输入返回未经过后处理的输出。对于student模式，网络对于包含真值的输入计算损失，对不包含真值的输入返回网络的正常输出结果（不包含后处理），对包含真值的输入返回正常输出结果和损失等信息。

对于teacher和student，得到原始输出之后，需要根据所采用的数据增强和参数。首先将teacher自己的增广还原，再使用和student相同的增广方法和参数进行变换，得到与student可匹配的增广结果。以进行后续的目标框匹配和损失计算等工作。


ONCE_BENCHMARK所实现的半监督算法均基于上述框架，下面分别对各个方法进行解读。

## SESS

其整体框架如下

首先，有监督部分的Loss和一般的网络相同，这里有监督损失只对student进行计算。

主要的不同在于一致性损失。首先通过网络得到4组预测框（Teacher有标签，Teacher无标签、Student有标签和Student无标签），在经过数据增广的变换和反变换后，四组预测已经是基于相同输入变换的结果。

这里的一致性损失是分开计算的，对于有标签部分计算一组，无标签部分计算一组。损失包括三个，中心一致性损失，分类一致性损失和尺寸一致性损失。首先，需要通过中心距离来确定目标框之间的匹配关系。这个匹配关系是双向的，并在在计算时，对于不同类别的目标框，加入了一个极大的距离作为penalty，以防止两个不同预测类别的目标框成为匹配对。在确定了匹配对之后，使用双向的中心距离和作为损失，并使用student和teacher的输出Box总数进行归一化。而size和prediction的一致性则只使用student-teacher的单向匹配（即到每个teacher预测最近的student）。这里，在实现中，作者进行了一定的简化，将kl散度简化成了mse损失，注释如下
```
kl_div is not feasible, since we use sigmoid instead of softmax for class prediction
```
并使用teacher的预测数进行归一化，即完成了全部的损失计算。

上述一致性损失和有监督部分的损失一起，对student进行反向传播。并使用EMA对teacher进行参数更新。从工程经验上来讲，EMA这部分是比较难调的，其参数直接影响到半监督训练的最终性能。

EMA更新的过程中主要分为三个阶段：
+ 停止
+ rampup
+ start

停止阶段即不进行EMA的传递，用于网络刚刚开始，student对于unlabeled data预测还不稳定的阶段；rampup阶段即热身阶段，网络逐渐从直接平均（动量0.5）逐步上升到一个使用较大动量的指数平均（比如动量0.99）；start阶段即网络已经基本进入一个稳定阶段，此时使用一个较大的常数动量进行参数更新（比如0.999）。
在本框架中，默认的参数是进行25epoch的无监督，15epoch开始rampup，20epoch开始start阶段。

## 伪标签方法

对学生网络输入labeled和unlabeled data，对teacher输入unlabeled data。并使用teacher的预测结果作为student unlabeled data的监督。两者之间存在一些数据增广上的差异，一般来说，teacher使用一些简单，低强度的增广，而student使用一些复杂，高强度的增广。两者之间采用EMA进行参数传递。

## 3D IoU Match
基本类似于伪标签方法，只是在其中加入了一套对于伪标签的筛选方法，使用更高质量的伪标签来训练student网络以取得更好的效果。这里程序中的实现相比原版论文中进行了简化。首先，原版论文中使用三个阈值对伪标签进行过滤，分别是objectness，cls score和iou prediction。首先，这里的网络实现没有Objectness，因此忽略。同时本框架也没有对cls score进行filter，而是只对iou进行了过滤。同时，也没有实现原文中的LHS。

## Noisy student

## SE-SSD

整体框架和SESS完全一致，唯一的区别是更换了Loss。SESSD使用IoU consistency loss，比较简单，就是使用student相对于teacher bounding box的IoU 阈值mask过滤的回归L1损失和分类L1损失，以teacher的结果作为伪标签。在标签的匹配上，SESS使用类别预测和中心距离实现匹配，而SESSD使用IOU进行目标框的匹配。
