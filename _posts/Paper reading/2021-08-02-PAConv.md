---
layout: post
title: 'PAConv: Position Adaptive Convolution with Dynamic Kernel Assembling on Point Clouds'
date: 2021-08-02
author: Poley
cover: '/assets/img/20210802/PAConv.png'
tags: 论文阅读
---

>论文链接： https://openaccess.thecvf.com/content/CVPR2021/html/Xu_PAConv_Position_Adaptive_Convolution_With_Dynamic_Kernel_Assembling_on_Point_CVPR_2021_paper.html

提出一种利用Weight Bank对点进行直接卷积的方法，通过Weight Bank中的多重权重以及自适应选择，来对于点之间的不同相对位置关系（不同的ralationship），来选择其最适合的权重。计算复杂度低，同时也可以更灵活的捕捉点之间的信息。

# Introduction

![](/assets/img/20210802/PAConvF1.png)

已经有许多工作来设计类似卷积的点云操作。

其中一些方法直接预测kernel weights，基于相对位置信息。典型的代表是PointConv。尽管在理论上是有效的，但是其方法的计算和内存复杂度都较高，由于spatial-variant kernal prediction。其高效实现在设计灵活性上做了妥协，导致性能的下降。

另一种方法是KPConv这样的，使用相关或者插值函数来调整kernels的权重。但是其Kernels的combination是hand-crafted的，可能不是最优的，或者不足以对复杂的3D位置变化进行建模。

本文提出的方法是**Position Adaptive Convolution**，也就是PAConv。其动态的对Weight Bank中的 basic weight matrices 进行assembling。 其融合的系数通过MLP来学习，也就是ScoreNet。

# Related Work

主流的对点云处理的方法主要有如下几种

## Mapping point clouds into regular 2D or 3D grids(voxels)

向2D投影会损失3D几何信息，而3D体素化则会使得精确的位置信息受到损失。总之，这永远要面对效率和量化精度的trade-off。

## Point representation learning with MLPs

比如PointNet及其发展。但是他们都使用共享的MLP来对点云特征进行转换，这可能会限制模型来捕捉spatial-variant information的能力。

## Point representation learning with point convolutions

有些方法直接学习Kernal或者通过预定义的Kernal来进行点卷积。其缺点分别是计算成本高，和非最优。而本文提出的方法动态的结合权重，是的模型具有更强的来适应非规律化的点云的能力。

## Dynamic and conditioned convolutions

略

# Method

## Overview
一般化的卷积可以建模如下

$$
\begin{equation}
g_{i}=\Lambda\left(\left\{\mathcal{K}\left(p_{i}, p_{j}\right) f_{j} \mid p_{j} \in \mathcal{N}_{i}\right\}\right)
\end{equation}
$$

一般2D卷积的kernal是一个一对一的权重，因为网格化的数据距离都是确定的若干个值。但是点云是连续值，所以这种一对一映射不适合3D点云数据。所以本文重新设计kernal function,使其学习一个position-adaptive mapping by dynamic kernel assembly。

首先，定义一个Weight Bank，由若干个权重矩阵组成，然后通过一个ScoreNet 来学习一个系数向量，来融合这些权重矩阵，根据点的位置。最后，dynamic kernels通过结合这些权重矩阵来得到。如下图所示。

![](/assets/img/20210802/PAConvF2.png)

## Dynamic Kernel Assembling

经过试验，作者发现Weight Bank中的权重矩阵的数量为8/16为最优。

Score就是一个简单的MLP,最后通过一个归一化函数输出，以得到概率值。这个函数可以是softmax，或者其他的。

$$
\begin{equation}
\mathcal{S}_{i j}=\alpha\left(\theta\left(p_{i}, p_{j}\right)\right)
\end{equation}
$$

最后的kernel表示如下

$$
\begin{equation}
\mathcal{K}\left(p_{i}, p_{j}\right)=\sum_{m=1}^{M}\left(S_{i j}^{m} B_{m}\right)
\end{equation}
$$

## Weight Regularization
为了防止Weight Bank中的权重彼此太相似，这里加入了一个正则项，来限制他们的相似度。

$$
\begin{equation}
\mathcal{L}_{\text {corr }}=\sum_{B_{i}, B_{j} \in \mathcal{B}, i \neq j} \frac{\left|\sum B_{i} B_{j}\right|}{\left\|B_{i}\right\|_{2}\left\|B_{j}\right\|_{2}} .
\end{equation}
$$

## Backbone Network Architectures
本文提出的方法是一个plug-and-play的方法，因此可以适用于多种Backbone，实验中分别在PointNet，DGCNN和PointNet++上使用了这个方法，取得了一定的性能提升。

# Experiments

![](/assets/img/20210802/PAConvT1.png)

# Code

上述的aggregation实际相当于两次求和，每个点对算得到M个分数，加权得到该点对对应的动态核。之后一个点所有的近邻点特征乘以对应的动态和，sum得到最终的输出特征。这个计算量比较繁琐，作者直接使用cuda编程实现，大大提高了效率。

在CUDA实现上，没有按照PointNet++的方式，而是换了一个流程，如下所示。

![](/assets/img/20210802/PAConvFD1.png)