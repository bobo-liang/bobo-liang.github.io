---
layout: post
title: 'CAT-Det: Contrastively Augmented Transformer for Multi-modal 3D Object Detection'
date: 2022-5-20
author: Poley
cover: '/assets/img/20220519/CAT.png'
tags: 论文阅读
---

本文的创新在于使用三个Transformer同时对模态内和跨模态的远距离上下文信息进行表征，分别是Pointformer(PT),Imageformer(IT)以及Cross-Modal Transformer(CMT)。并且针对多模态的数据增广问题，提出One-way Multi-modal Data Augmentation(OMDA), 通过引入对比学习的方法来解决这一问题。

本文的方法的特点如下所示，即同时利用多模态的远距离上下文信息。

![](/assets/img/20220519/CATF1.png)

尽管图像还没有被证明具有作为独立模态处理这个问题的能力（Baseline较低），但是图像和点云的结合确实可以导致准确度的提高，由于他们天然的信息互补性。但多模态方法目前仍然不如纯激光雷达的单模态方法。

作者分析其原因可能来自于多模态中各自处理方法（PointNet++,3D 2D CNN）带来的有限的感受野（Limited local receptive field），因此不能从多模态中全面的获得上下文信息，导致信息损失。
其次，融合上，通常使用直接串联、加性卷积或者简单的注意力，没有根据不同特征有限的感受野来分配权重，使得关键信息不能被heightlighted。另外，单模态的数据增强不能在多模态中使用，这样会导致语义misalignment。而作者的创新主要为了解决上述问题。

本文提出模型的整体结构及其结构分别如图所示
![](/assets/img/20220519/CATF2.png)

![](/assets/img/20220519/CATF3.png)

![](/assets/img/20220519/CATF4.png)

![](/assets/img/20220519/CATF5.png)

在点特征的transformer上，基本使用了Point transformer的形式，使用Point Transformer对局部特征进行聚合。只不过他用的radius。对于聚合完的关键特征，再使用Point Transformer过一遍，得到全局特征，类似于PointNet++。

在图像的transformer上，直接使用的现有的图像Transformer，在此不过多赘述。

重点创新在于这个跨模态主力，这里笔者个人认为有点像CrossVit,总的来说，就是将点投影到图像中，并选取图像中特定位置的特征来匹配这些点特征。其他图像特征就不用了。这样得到点和图像对其的两组特征，分别使用彼此的query来索引对方的key，得到跨模态自注意力特征。作者最后是将这四种特征cat到一起使用，如下

$$
\begin{equation}
\boldsymbol{F}_{\boldsymbol{P}}:=\boldsymbol{F}_{\boldsymbol{P}} \oplus \boldsymbol{F}_{I} \oplus \boldsymbol{F}_{\boldsymbol{P}}^{\text {cont }} \oplus \boldsymbol{F}_{I}^{\text {cont }}
\end{equation}
$$

最后，是作者提出的One-Way Melti-modal Data Augmentation。常用的数据增广只能在一个模态上进行，进而导致多模态数据之间出现数据的misalignment。虽然可以通过一些复杂的方法同时对多模态进行增强，但是这样也会引入其他的噪声。这里，作者提出只在点云上进行增强，并将增广效果拓展到其他模态上，通过对比学习的方式，来缓解增强带来的特征misalignment问题，如下图所示。

![](/assets/img/20220519/CATF6.png)

这里在两个level上进行，分别是point level和 Object level。

Point level比较简单，即对于真实的点，其可以通过投影关系和图像中的像素建立对应关系，此时他们的特征应该是匹配的，因为他们同属于一类物体。此时将他们看作正样本，而这个点和图像中其他背景像素则称为负样本。但是当点云中引入增广物体时，其图像上对应位置一定没有和他对应的物体，因此其和对应位置自然形成一对负样本，和其他背景也是负样本。这里进而选择最近的一个同类物体的像素和这个增广点构建正样本对，用于训练，如上图所示。个人理解是增强属于同一目标类别的点特征和图像特征的相似度，对于贴过来的增广GT，由于其没有对应的图像，因此使用图像中和其类别最相近的位置的特征作为其匹配特征，同样通过对比学习使两者靠近，减轻Misalignment。

在Object level上，同上使用Object的整体特征做和上述类似的正负样本对。但是和之前不同的是，Object之间，作者发现使用不同类别的Object构建负样本对，比Object和background之间构建负样本对训练效果要更好。但是由于点云中样本的不平衡数量，导致同一场景中可能没有多种物体。因此作者为了构建根据判别性的负样本对，引入了Memory Bank，来记录各类别Object的特征用于训练，并使用动量进行更新。

![](/assets/img/20220519/CATT1.png)

消融实验体现了上述模块的作用。
![](/assets/img/20220519/CATT3.png)