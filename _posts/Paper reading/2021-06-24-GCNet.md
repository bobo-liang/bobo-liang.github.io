---
layout: post
title: 'GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond'
date: 2021-06-24
author: Poley
cover: '/assets/img/20210624/GCNET.png'
tags: 论文阅读
---

# Introduction

本文的内容来自于一个发现，**Non-local得到的attention maps实际上是query-independent的，但是却为此付出了很多的计算。因此很自然的可以简化它，直接变为一个query-independent attention map，即GCNET**。

![](/assets/img/20210624/GCNETF1.png)

在改进之后，作者发现网络结构非常像 Squeeze-Excitation Network。于是总结了一个three-step general framework,来统一了NL block 和 SE block。如下
1. A context modeling module： Aggregate所有位置的特征来组成一个global context feature；
2. A feature transform module: 捕捉channel-wise interdependencies；
3. A fusion module ：融合global context feature 到 所有位置的特征中。

综上作者发现，NL和SE block均是次优的，在三个部分中两者均各有优劣。因此作者将他们结合起来，变为了新的global context block(GC block)。

## Analysis on Non-local Networks

![](/assets/img/20210624/GCNETF2.png)

从上图可以看出，**for different query positions, their attention maps are almost the same**。为了严谨，作者还进一步统计了NL输入输出的向量的距离变化，如下表所示，可以看到输入之间的差距较大，但是得到的输出却更加近似，证实了上述可视化的直观表现。

![](/assets/img/20210624/GCNETT1.png)

# Method
## Simplifuing the Non-local Block

对Non-local进行简化，得到**query-independent**的attention map如下
$$
\begin{equation}
\mathbf{z}_{i}=\mathbf{x}_{i}+\sum_{j=1}^{N_{p}} \frac{\exp \left(W_{k} \mathbf{x}_{j}\right)}{\sum_{m=1}^{N_{p}} \exp \left(W_{k} \mathbf{x}_{m}\right)}\left(W_{v} \cdot \mathbf{x}_{j}\right)
\end{equation}
$$

移项以减小计算量
$$
\begin{equation}
\mathbf{z}_{i}=\mathbf{x}_{i}+W_{v} \sum_{j=1}^{N_{p}} \frac{\exp \left(W_{k} \mathbf{x}_{j}\right)}{\sum_{m=1}^{N_{p}} \exp \left(W_{k} \mathbf{x}_{m}\right)} \mathbf{x}_{j}
\end{equation}
$$

结构对比如下
![](/assets/img/20210624/GCNETF4.png)

同时使用了bottolneck，以及减少了query，相比NL显著降低了计算量。

# Experiments 

略