---
layout: post
title: 'RTS3D: Real-time Stereo 3D Detection from 4D Feature-Consistency Embedding
Space for Autonomous Driving'
date: 2021-12-08
author: Poley
cover: '/assets/img/20211206/RTS3D.png'
tags: 论文阅读
---

>参考博客： https://zhuanlan.zhihu.com/p/342748124

论文写的有些乱，推荐看上面的博客，说得非常清晰。

本文发表在AAAI2021上，是一个使用多目图像做3D物体检测的方法，和其他类似的方法相比，其最大的优点在于速度快，并且不需要任何深度图、实例分割mask等其他Pixel-wise的label。其和其他方法的对比如下
![](/assets/img/20211206/RTS3DF1.png)

使用额外的监督具有一些缺点，比如：
+ 标注成本高，虽然一些无监督方法也可以生成Depth map，但是精度还是和人工标注的差很多；
+ 需要使用stand-alone的网络来推理这些数据，如上所示，比如深度估计和实例分割；
+ 多个独立网络之间的误差和不一致性会带来性能的瓶颈。

这些都是由于Depth Map和其对应的Pseudo-Lidar造成的。这些方法需要将像素和深度投影为伪点云，再用3D点云检测方法检测。
实际上本质是因为3D物体检测需要使用物体的3D信息，一般这种信息通过点云（伪点云）来表示。而本文从传统的深度图生成方式中获得灵感，**用一致性来表示这种结构**。
如上图所示，对于同一个点在图像上的投影，如果其在两个图上对应的像素有所差异，则说明这个点在物体内部；同理，若没有差异，则说明点在物体表面。这样就相当于通过一致性对物体的结构信息进行了编码。
虽然论文写得不太清楚，但是其网络的整体思想还是比较简单的。结构如下所示
![](/assets/img/20211206/RTS3DF2.png)

首先，通过单目3D检测生成隐空间（Latent Space），其实就是3D目标框对应的空间。之后将其体素化，为了保证速度，体素化的分辨率较低，**可以是$20\times20\times20$和$10\times10\times10$，将这些体素对应的格点(grid points)通过图像的内外参投影到图像的特征上。投影后的点是浮点值，进而使用双线性插值来解决这个问题。将投影回的各个scale对应的特征串联在一起，成为一个格点在一副图像上的特征，最终的体素特征通过一致性度量来获得，如下所示
![](/assets/img/20211206/RTS3DFO2.png)
这里的一致性度量函数通过一个惊现基函数网络RBF实现。如此便完成了对于体素特征的提取。之后作者使用PointNet+Attention的简单风阀实现了最终的目标特征提取，如下所示

![](/assets/img/20211206/RTS3DF3.png)
比较简单，不再赘述。

实验结果如下
![](/assets/img/20211206/RTS3DT1T2.png))

