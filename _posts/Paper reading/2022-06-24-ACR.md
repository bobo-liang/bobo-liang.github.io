---
layout: post
title: 'Adaptive Consistency Regularization for Semi-Supervised Transfer Learning'
date: 2022-06-24
author: Poley
cover: '/assets/img/20220622/ACR.png'
tags: 论文阅读
---

本文发表自2021CVPR，意在同时利用源域的良好的预训练模型和目标域的有标签和无标签数据。相当于结合了迁移学习+半监督学习。本文提出的方法成为adaptive consistency regularization，分为Adaptive Knowledge Consistency（AKC）和Adaptive Representation Consistency（ARC）分别用于源-目标域之间的正则和有-无标签数据之间的正则。注意到，本文提出的方法均为正则方法，可以结合其他半监督方法使用。

本文的一大创新是结合迁移学习和半监督学习，相关研究表明在半监督训练方法中，预训练模型在目标域上带来的好处可能被边缘化。本文受到迁移学习的启发，将相关的概念引入半监督学习中，实现对预训练模型知识更好的利用。

迁移学习关注于解决样本选择偏置（sample selection bias）。主要方法是重加权和表征适应，前者尝试调整决策边界；后者尝试调整特征表达，来减小两个域之间的分布差异。

半监督学习常用的一致性正则基于假设：决策边界不会跨过密集区域。因此，一个sample与其特征上的近邻倾向于具有相同的标签。

本文的方法正是结合上述两种思想。本文的方法如下所示

![](/assets/img/20220622/ACRF1.png)

本文的正则不针对特定的task，也就是说，源域和目标域可以不使用相同的task，而在迁移的时候，只使用源域的特征提取器F，加上一个task-specific的head G。因此，本方法中，源域只用于进行预训练，之后的训练中，就不会用到源域的数据了。但是这样对于stack-specific的G并不能共享，这里使用了low-shot learning来给出一个更好的G的初始化参数。

## Adaptive Knowledge Consistency

这部分正则损失如下，其概念比较简单，即要求预训练模型和目标域模型对于相同输入（有标签和无标签的）的特征具有近似的分布，衡量分布差异的metric是KL散度，呃可以是别的。
$$
\begin{equation}
R_{\mathrm{K}}=\frac{1}{B_{l}+B_{u}} \sum_{\mathbf{x}^{i} \in \mathcal{L} \cup \mathcal{U}} w_{\mathrm{K}}^{i} \mathrm{KL}\left(F_{\theta^{0}}\left(\mathbf{x}^{i}\right), F_{\theta}\left(\mathbf{x}^{i}\right)\right)
\end{equation}
$$

这里重点在于对于样本的筛选（自适应权重），即什么样本是希望基于目标域模型的特征分布监督的。这里作者引入了熵的概念：自适应的权重来自于预训练网络的输出，通过一个entropy-gate函数将其映射到一个重要性value上。理论上来说，这个权重和模型输出的confidence是正相关的。直观的说，更高的输出置信度意味着输入样本更倾向于落入源域的trust region，因此这个knowledge对于target model是更加可靠的。只不过最后没有使用正比，而是使用一个硬阈值来对样本的重要性进行过滤（类似于伪标签的过滤）？个人理解这里类似于伪标签，只不过标签的内容换成了feature而不是最终的输出。因此，最终，作者使用一个阈值来过滤高熵的特征，保留低熵的特征来监督目标域模型
$$
\begin{equation}
w_{\mathrm{K}}^{i}=\mathrm{I}\left(\mathrm{H}\left(\mathbf{p}_{s}^{i}\right) \leq \epsilon_{\mathrm{K}}\right)
\end{equation}
$$

这部分主要针对从source的预训练到target的transfer问题。


## Adaptive Representation Consistency

这里的目的同样是为了保证分布的一致，只不过是在有标注和无标注数据之间。这里使用了常用的MMD（Maximum Mean Discrepancies）损失衡量label和unlabel两个数据representation的分布距离，并通过优化拉近两者的距离。其公式如下
$$
\begin{equation}
\operatorname{MMD}\left(Q_{v}, Q_{u}\right)=\left\|\frac{1}{m} \sum_{i=1}^{m} \kappa\left(\mathbf{v}^{i}\right)-\frac{1}{n} \sum_{j=1}^{n} \kappa\left(\mathbf{u}^{j}\right)\right\|^{2}
\end{equation}
$$

但是注意到，无标签数据的分布不总是正确可靠的，尤其是对于训练刚开始的阶段，因此这里同样需要对用于监督分布的sample进行一个筛选，类似于AKC，这里也使用熵作为样本置信度的判断，并使用具有高置信度的样本来对标注数据的representation进行正则。（熵越小意味着置信度越高）

$$
\begin{equation}
\begin{aligned}
&\mathcal{F}_{l}=\left\{F_{\theta}\left(\mathbf{x}_{l}^{i}\right) \mid x_{l}^{i} \in \mathcal{L} \text { and } \mathbf{H}\left(\mathbf{p}_{l}^{i}\right) \leq \epsilon_{\mathrm{R}}\right\} \\
&\mathcal{F}_{u}=\left\{F_{\theta}\left(\mathbf{x}_{u}^{i}\right) \mid x_{u}^{i} \in \mathcal{U} \text { and } \mathbf{H}\left(\mathbf{p}_{u}^{i}\right) \leq \epsilon_{\mathrm{R}}\right\}
\end{aligned}
\end{equation}
$$

这里之所以不能使用KL散度之类的方法，是因为这里labeled和unlabeled data并不一样，因此不能像AKC那样形成严格一一对应的向量关系，因此这里只能计算两者特征的一个整体分布。自然的，为了得到更准确的整体分布，需要扩大样本量。因此这里引入一个buffer，来保存最近sample的representation。

Labeled_Buffer.update $\left(\mathcal{F}_{l}\right)$
Unlabeled_Buffer.update $\left(\mathcal{F}_{u}\right)$
$\mathcal{F}_{l}^{\star}=$ Labeled_Buffer.get_last_k ()
$\mathcal{F}_{u}^{\star}=$ Unlabeled_Buffer.get_last_k ()

$$
\begin{equation}
R_{\mathbf{R}}=\mathbf{M M D}\left(Q_{\mathcal{F}_{l}^{\star}}, Q_{\mathcal{F}_{u}^{\star}}\right) .
\end{equation}
$$

最终得到模型的总正则损失为
$$
\begin{equation}
R(\theta)=\lambda_{\mathbf{K}} R_{\mathbf{K}}+\lambda_{\mathbf{R}} R_{\mathbf{R}}
\end{equation}
$$

和有监督损失以及其他方法的半监督损失（比如伪标签）一起，构成模型的整体损失
$$
\begin{equation}
\begin{array}{r}
L(\theta, \phi)=\quad \frac{1}{n} \sum_{i=1}^{n} L_{\mathrm{CE}}\left(\theta, \phi ; \mathbf{x}_{l}^{i}\right)+\lambda_{\mathbf{S}} L_{\mathbf{S}}\left(\left\{\mathbf{x}_{u}^{i}\right\}\right)+ \\
\lambda_{\mathbf{K}} R_{\mathbf{K}}\left(\left\{\mathbf{x}_{l}^{i}\right\},\left\{\mathbf{x}_{u}^{i}\right\}\right)+\lambda_{\mathbf{R}} R_{\mathbf{R}}\left(\left\{\mathbf{x}_{l}^{i}\right\},\left\{\mathbf{x}_{u}^{i}\right\}\right)
\end{array}
\end{equation}
$$
