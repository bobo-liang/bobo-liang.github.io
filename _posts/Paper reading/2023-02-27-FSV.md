---
layout: post
title: 'Fully Sparse VoxelNet for 3D Object Detection and Tracking'
date: 2023-2-27
author: Poley
cover: '/assets/img/20230227/FSV.jpg'
tags: 论文阅读  
---

背景：3D点云的特征稀疏，但是为了套到2D的框架里，依旧将其压缩为BEV并进行dense prediction。但是这样造成很多浪费，在val上，大约只有1%的点对car类别有响应。如下图所示。同时，大量的预测也带来了复杂的Pipeline，比如需要使用NMS来消除冗余框，而不能实现end-to-end的检测。

![](/assets/img/20230227/FSVF1.jpg)

类似的工作有FSD，其参考votenet对中心进行投票，但是由于点都坐落在物体的表面，其不可避免的引入错误，因此需要额外的group来做correction。导致整个pipeline变得非常复杂。而本文提出的方法是，特点，稀疏，结构简单。无需anchor，稠密化，rpn等。

本文总体结构如下
![](/assets/img/20230227/FSVF2.jpg)

为何Centerpoint不能直接去掉SECONDFPN结构从而变成完全的稀疏卷积结构呢？首先，Centerpoint主要还是继承了2D的centernet的结构，其属于dense prediction结构，因此其需要生成dense的feature map。其次，3D稀疏卷积的表达能力对于Prediciton来说是有限的，因此一般需要dense卷积来增强特征。另外，稀疏卷积的最大问题是感受野不足，这里证明可以通过additional down-sampling解决。

本文方法的详细结构如下
![](/assets/img/20230227/FSVF3.jpg)

主要结构有三个：
## Sparse CNN Backbone Adaptation
### Additional Down-sampling
本结构最大的作用是确保稀疏卷积的感受野。首先，为了扩充感受野，在原有的卷积上又增加两层更高的下采样，并叠加他们的特征。只需要对稀疏特征的Indices做简单的变换即可。其叠加可以表示如下

$$
\begin{equation}
\begin{aligned}
& F_c=F_4 \cup\left(F_5 \cup F_6\right), \\
& P_6^{\prime}=\left\{\left(x_p \times 2^2, y_p \times 2^2, z_p \times 2^2\right) \mid p \in P_6\right\} \\
& P_5^{\prime}=\left\{\left(x_p \times 2^1, y_p \times 2^1, z_p \times 2^1\right) \mid p \in P_5\right\} \\
& P_c=P_4 \cup\left(P_5^{\prime} \cup P_6^{\prime}\right) .
\end{aligned}
\end{equation}
$$

对于这方面的消融如下,当单纯的用稀疏卷积代替centerpoint，可以看到大目标掉点非常严重。这是由于稀疏卷积对大目标感受野不足，符合预期。
![](/assets/img/20230227/FSVT2.jpg)

### Sparse Height Compression
融合三层后，采用稀疏的 height压缩，即累加同indice的特征。
$$
\begin{equation}
\begin{aligned}
& \bar{P}_c=\left\{\left(x_p, y_p\right) \mid p \in P_c\right\} \\
& \bar{F}_c=\left\{\sum_{p \in S_{\bar{p}}} f_p, \mid \bar{p} \in \bar{P}_c\right\}
\end{aligned}
\end{equation}
$$
实际上，这是可有可无的，相当于在性能和速度之间进行了一个取舍，其消融实验如下图所示
![](/assets/img/20230227/FSVT5.jpg)

使用3D feature相比2D feature在检测性能上具有显著提升。这与我在CMT上的实验结果一致。

### Spatially Voxel Pruning
由于3D场景中的背景太多，这里采取逐步剪枝的方法，移植低响应点的dilation，从而避免不必要的计算量。如下图所示
![](/assets/img/20230227/FSVF4.jpg)

其消融如下所示，实验证明，去除大量背景点之后，对物体的检测性能影响不大。
![](/assets/img/20230227/FSVT3.jpg)

上述是本文在特征提取方面的模型设计。

## Sparse Prediction Head
由于没有dense bev featuremap，因此本文也有一套特殊设计的预测head。首先，对于稀疏的voxel，这里采用类似query的方式，gt和voxel直接进行1-1匹配，而不是使用稀疏特征。这样避免了稀疏特征的中心缺失问题。为了减少计算量，去除冗余，同时避免NMS。这里在inference的时候做了局部极大值抑制，只有保留下来的voxel才进入到后续的box  regression过程中。如下图所示
![](/assets/img/20230227/FSVF5.jpg)

其消融如下所示，预测中根据feature响应强度进行的max-pool(相当于局部抑制)，基本代替了NMS，并且更快。这得益于特征足够稀疏。
![](/assets/img/20230227/FSVT10.jpg)
## 3D Tracking
最后，本文和centerpoint一样，很自然的引入了tracking的能力。但是与其不同的是，对于tracking，主要是解决两帧之间检测目标的匹配问题。相比使用目标中心center，这里使用回归目标所用的voxel作为目标的表示，并使用L2进行最近邻匹配。从而避免了center估计不准的问题（voxel是实际存在的数据，而center是估计的），如下图所示

![](/assets/img/20230227/FSVF6.jpg)

![](/assets/img/20230227/FSVF7.jpg)

在总体性能上，如下

![](/assets/img/20230227/FSVT12.jpg)

![](/assets/img/20230227/FSVT15.jpg)