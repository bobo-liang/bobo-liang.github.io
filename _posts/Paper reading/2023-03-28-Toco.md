---
layout: post
title: 'Token Contrast forWeakly-Supervised Semantic Segmentation'
date: 2023-3-28
author: Poley
cover: '/assets/img/20230328/Toco.jpg'
tags: 论文阅读  
---

问题定义： WSSS指使用一些cheap annotations来进行分割任务的学习，比如图像级别的标签，点，简介，目标框等。其中图像级别的标签是最cheap的，包含的信息最少，本文关注这个问题。

通常无监督分割使用CAM作为伪标签。但是由于CNN的局部感受野限制，CAM往往不能提供完整的物体regions，而VIT则不存在这一点，但是存在过平滑问题，即最后的patch特征倾向于均匀分布（进而导致相似度矩阵饱和）。如下图所示。
![](/assets/img/20230328/TocoF1.jpg)
本文提出两个方法：1、PTC，使用VIT中间层的token相关性伪标签来监督final patch，使其可以与语义区域对其而产生更准确的cam。其次，针对CAM中的低置信度区域，提出CTC，通过对比全局object和local regions的class token来提升repersentation的一致性。

对于Tranformer的平滑问题，之前的工作有所证明，ViT中的self-attention相当于一个低通，倾向于降低输入信号的方差。相当于不断的smoothing输入信号。 
特征的趋同（均匀分布）导致相似矩阵全部接近于1，而这一般用于分配伪标签。导致伪标签为不同的region都分配了同样的语义标签。

进一步的，作者发现，这种平滑是逐步渐进的，即中间层仍然可以保持特征的diversity。因此提出使用中间层的信息来监督最终的final patch，防止过度的smoothing。这就是PTC（Patch Token Contrast）方法。

为了进一步利用ViT中包含充分语义的class token。这里提出一种CTC方法，将图片的不确定区域和背景区域crop出来，分别最小化和最大化其representation和Global image的距离，以进一步解决WSSS只激活最显著的物体区域的问题。


名词解释： CAM（Class Activation Map）。简单的说，CAM即特征经过分类权重（线性）后的响应幅值。之后，使用一个阈值beta来区分前景和背景区域。可以表示为如下
$$
\begin{equation}
\operatorname{CAM}_c(\mathbf{F}, \mathbf{W})=\frac{\operatorname{relu}\left(\mathbf{M}_c\right)}{\max \left(\operatorname{relu}\left(\mathbf{M}_c\right)\right)}, \mathbf{M}_c=\sum_i \mathbf{W}_{c, i} \mathbf{F}_{:, i} .
\end{equation}
$$

Vision Transformer & Oversmoothing。如下图所示，由于self attention的低通特性，随着网络的加深，patch之间的特征逐步趋同，导致相似度矩阵趋于饱和
![](/assets/img/20230328/TocoF2.jpg)

具体方法上，本文结构如下所示
![](/assets/img/20230328/TocoF3.jpg)

本文的结构是引入了一个辅助的CAM网络（对应的损失是分类损失）。两个功能：1、产生pseudo label来监督最后的patchs 2、根据高质量的CAM，提供proposal来crop前景和背景区域，提供给CTC对比学习。最后一层的CAM用于产生最终的伪标签。

Patch Token Contrast。本文使用中间层的特征产生合适用于监督的CAM。但是并非所有中间层都适用，过高的层数导致过平滑，过低的则不足以补充高层语义信息。这个选择在实验中进行了讨论。如下所示。
![](/assets/img/20230328/TocoT5a.jpg)
将toekn patch做全局maxpooling后经过FC得到CMA，这个过程中只和分类全连接层的权重以及token特征有关。故CAM可以表示为
$$
\begin{equation}
\mathbf{M}^m=\operatorname{CAM}\left(\mathbf{F}^m, \theta^m\right) .
\end{equation}
$$
并使用两个阈值划分为三段：前景，背景和不确定。

有了上述CAM标签后，设定具有相同语义label的相似度为Pos,否则为neg。用于监督高层的similarity。注意到这里指选取前景类和背景类进行相互相似度的计算，而忽略中间不确定区域内标签。同时，这部分不确定输出的Loss也被忽略。为了更好的确保损失对应差异化的输出，这里使用cosine绝对值相似度。总的来说，PTC的损失如下所示。

$$
\begin{equation}
\begin{aligned}
\mathcal{L}_{\text {ptc }} & =\frac{1}{N^{+}} \sum_{\mathbf{Y}_i=\mathbf{Y}_j}\left(1-\operatorname{CosSim}\left(\mathbf{F}_i, \mathbf{F}_j\right)\right) \\
& +\frac{1}{N^{-}} \sum_{\mathbf{Y}_i \neq \mathbf{Y}_j} \operatorname{CosSim}\left(\mathbf{F}_i, \mathbf{F}_j\right),
\end{aligned}
\end{equation}
$$


Class Token Contrast。这个模块的作用是：虽然基于CAM监督的PTC可以很好的防止过平滑，从而让ViT产生更高质量的CAM。但是CAM仍然有不好分辨的区域。因此这里提出CTC，目的是增加图像整体表征的一致性，使得更多的区域在CAM中被激活。

这里通过CAM辅助网络扣出不确定区域的img，由于这些可能包含的前景信息很好，因此也扣出了一些背景区域作为对比。最大化他们之间的diff的同时，网络对前景背景的区分能力也得到了提升。具体抠图的方法如下所示

![](/assets/img/20230328/TocoF4.jpg)

crop到这些样本后，分别当作正样本和负样本，并和整个图像的global feat进行对比，使用InfoNCE Loss。如下所示

$$
\begin{equation}
\mathcal{L}_{\text {ctc }}=\frac{1}{N^{+}} \sum_{\mathbf{q}^{+}} \log \frac{e^{\left(\mathbf{p}^{\top} \mathbf{q}^{+} / \tau\right)}}{e^{\left(\mathbf{p}^{\top} \mathbf{q}^{+} / \tau\right)}+\sum_{\mathbf{q}^{-}} e^{\left(\mathbf{p}^{\top} \mathbf{q}^{-} / \tau\right)}+\epsilon},
\end{equation}
$$

这是自监督学习里非常常用的损失，其本质目的是在高维空间中拉近同类物体，拉远不同类物体。同时，其具有对困难样本的自挖掘能力。具体讲解可见 https://zhuanlan.zhihu.com/p/357071960?ivk_sa=1024320u&utm_id=0

结合上述方法，本文提出ToCO, 损失如下
$$
\begin{equation}
\mathcal{L}_{\text {toco }}=\mathcal{L}_{c l s}+\mathcal{L}_{\text {cls }}^m+\lambda_1 \mathcal{L}_{\text {ptc }}+\lambda_2 \mathcal{L}_{\text {ctc }}
\end{equation}
$$
在其生成高质量的CAM后，送入PAR进行优化，反过来对网络进行分割监督。PAR是CVPR2022的另一篇方法，其使用CAM标签作为初始输入，并进行细化。正好与本文产生的更准确的CAM标签相结合。

最终，在性能上，本文产生的pseudo labels与其他方法相比具有显著的优势。

![](/assets/img/20230328/TocoT1.jpg)

关于CAM质量的可视化对比如下
![](/assets/img/20230328/TocoF5.jpg)



![](/assets/img/20230328/TocoT2.jpg)

![](/assets/img/20230328/TocoT3.jpg)

![](/assets/img/20230328/TocoT4.jpg)

![](/assets/img/20230328/TocoT5.jpg)

对CTC作用的可视化如下所示，可以看到经过CTC训练，网络对物体边缘的判别能力更强，边缘判断准确，如下

![](/assets/img/20230328/TocoF7.jpg)