---
layout: post
title: 'Joint 3D Instance Segmentation and Object Detection for Autonomous Driving'
date: 2021-05-25
author: Poley
cover: '/assets/img/20210525/J3D.png'
tags: 论文阅读
---

> 论文链接 : https://openaccess.thecvf.com/content_CVPR_2020/html/Zhou_Joint_3D_Instance_Segmentation_and_Object_Detection_for_Autonomous_Driving_CVPR_2020_paper

> 参考博客 : https://zhuanlan.zhihu.com/p/151398153

# Introduction

许多方法都证明了简单的表示更适合深度学习的学习。3DBbox的表示框就很简单，但是这也有一些缺点，因为Bbox损失了物体的Shape信息，而在有遮挡的情况下就更加严重，BBox不能足够准确的描述object的精确位置。

因此，可以额外引入Instance mask来消除Bbox中非目标部分的一项。一种直观的实例分割方法就是先做目标检测，再做前景分割，比如MaskRCNN。

目前3D目标检测对于室内和室外的研究已经不错，但是大多数的3D实例分割还是针对室内的。

本文提出一种网络，结合了目标检测和实例分割在一个网络中，并且可以相互提升对方的性能。

## Contribution

1. 一种端到端训练的网络，同时得到3DBbox和实例分割；
2. 相比普通的feature embedding in a 2D image，提出的方法同时考虑了gloabl BBox和local point information together；
3. KITTI上验证了有效性和高效性，相比其他SOTA。

![](/assets/img/20210525/J3DF2.png)

# Proposaed Approach


![](/assets/img/20210525/J3DF3.png)

## Overview
网络总体结构如上图所示，首先通过一个PointNet++来提取特征。之后分为2个branch，分别是语义分割得分以及Spatial Embeddding(SE),用于预测前景点相对于Object 中心的偏移以及尺寸等等。 基于这两个branch的信息，通过一个SE Based Clustering and Region Proposal，实现点的聚类，并给每个聚类都得到一个proposal。（这里由于每个聚类是一个目标，给出一个proposal，所以并不用NMS。）最后，经过一个refine network（比如PointNet），得到最后的BBox。

## Instance-aware SE

2D和3D实例分割还是有一些区别。Scale,Spatial Laypout Ambiguity and Occlusion是2D图像领域的三个主要问题，都严重的影响了目标检测和实例分割的效果。但是这些问题在3D点云数据都不存在。相反的，由于点云数据在3D空间中系数的分布，所以直接聚类并得不到好的效果，所以为了更简单的聚类或者分割，一个well designed intermediate procedure是需要的，用于发现点的隐藏特征，比如segmantic class, instance label 或者 object's information。

### Point cloud feature extraction 

使用PointNet++。

### Semantic infomation

分割分类损失，使用**focal loss**解决分类不平衡的问题。

$$
\begin{equation}
\begin{aligned}
\mathbf{L}_{\mathrm{cls}} &=-\sum_{i=1}^{C}\left(y_{i} \log \left(p_{i}\right)\left(1-p_{i}\right)^{\gamma} \alpha_{i}\right.\\
&\left.+\left(1-y_{i}\right) \log \left(1-p_{i}\right)\left(p_{i}\right)^{\gamma}\left(1-\alpha_{i}\right)\right)
\end{aligned}
\end{equation}
$$

### Object information

这里最重要的information是目标中心，因为即影响分割（聚在一起方便聚类），也影响目标检测。这里每个点的回归目标就建模为其到所属于的目标中心的距离
$$
\begin{equation}
c_{\text {offset }}^{i}=\left(p_{x}^{i}-c_{x}^{k}, p_{y}^{i}-c_{y}^{k}, p_{z}^{i}-c_{z}^{k}\right)^{T} \text { , }
\end{equation}
$$

其余的BBox信息则直接按真值回归。

## Clustering-based Proposal Generation

上述前景点都被pull到一起，使用简单的聚类方法就可以得到他们的聚类。置信度前5的聚类每个产生一个mean BBox，送入下一阶段的ROI Pooling中。

## BBox Refinement
ROI Pooling 包括两件事
1. 将一个聚类内的所有点包含进来
2. 去除里面不属于该Bbox的前景点

之后经过一个PointNet++再分两个HEAD回归就得到refine 结果。

## Multi-task Loss

总体Loss
$$
\begin{equation}
\mathbf{L}=\mathbf{L}_{\mathrm{sem}-\mathrm{cls}}+\mathbf{L}_{\mathrm{SE}}+\mathbf{L}_{\mathrm{reg}}
\end{equation}
$$

SE loss使用smooth L1, BBox regression loss 用IOU loss。

# Experiments


![](/assets/img/20210525/J3DEXP.png)
