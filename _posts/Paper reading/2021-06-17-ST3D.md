---
layout: post
title: 'ST3D: Self-training for Unsupervised Domain Adaptation on 3D Object Detection'
date: 2021-06-16
author: Poley
cover: '/assets/img/20210617/ST3D.png'
tags: 论文阅读
---

>论文链接 ： https://arxiv.org/abs/2103.05346

首先在source domain上训练，使用作者提出的*random object scaling strategy*来消除source domain bias的负面影响。
之后在target domain上交替执行 updating memory bank 和 curriculum data augmentation。

# Introduction

![](/assets/img/20210617/ST3DF1.png)

由于3D数据标注的困难性，domain adaptation显得非常重要。而**unsupervised domain adaptation(UDA)**就是其中一种，UDA已经在2D图像上广泛应用，但是直接放到3D上并不好用，**因为3D任务需要target domain的目标尺寸的统计信息，而其高度依赖于数据分布。**

近来，**self-training**是一种简单有效的UDA方法，其从在source domain上训练开始，之后交替的产生伪标签以及训练无标签数据，直到收敛。对3D数据来说，伪标签就包括有向的3D BBox以及类别。由上图可见，普通的ST在3D UDA任务中表现不好。

主要贡献：提出了ST3D，一个为3D目标检测重新设计的self-traning pipleline：
+ **Random object scaling(ROS)**：一种3D目标增强方法，减少source domain的bias。
+ **Quality-aware triplet memory bank (QTMB)**：一种结合了IoU-based box scoring crierion的mermory。
+ **Curriculum data augmentation (CDA)**：逐步提升增强的强度，来保证有效的训练以及渐进的模拟hard examples来提升模型。

# Method

目标：在有标注的source domain上训练的3D目标检测器，去适应target domain的无标注数据。

![](/assets/img/20210617/ST3DF2.png)

![](/assets/img/20210617/ST3DA1.png)

## Model Pre-training with ROS

在source domain预训练过程中，除了有用的知识，预训练检测器同样学习到了source domain的Bias，**比如object size和point densities**。其中，**Object size的Bias 对于3D检测具有直接的负面影响，会造成产生具有不正确的size的pseudo-labels，在target domain中**。为了解决这个问题，提出了**random object scaling (ROS）**

ROS其实就是对目标框及其中点做一个尺度上的放缩，随机的。这样就模拟了不同大小的物体，来消除source domain的size bias，进而训练出一个对size鲁邦的检测器，可以产生更准确的pseudo boxes，在后续的self-training中。

## Pseudo label Generation with QTMB

对于没有用来训练，无标签的target samples，将其通过检测器，得到已经经过NMS的输出，其中包含类别置信度，回归box的size和centers以及heading angles。

目标检测对于伪标签的要求更高。主要问题：
+ 分类置信度并不能完全反应IOU信息，也就是不能提供可靠的位置信息
+ 在置信度不高不低的部分，是容易混淆（判断错误）的区域。

![](/assets/img/20210617/ST3DF3.png)

因此提出了**qualityaware triplet memory bank (QTMB)**。Memeroy通过集合所有的伪标签和历史的memory来得到，伪标签通过目标检测器的预测以及iou-based scoring criterion来得到。

### Proxy-pseudo Labels from the Object Detector
为了解决上述的分类置信度和IOU不一致的问题，在原始的检测器上加了一个轻量的IOU regression head,来预测IOU。IOU已经呗做过一些尝试用来提升检测的性能，但是本文是第一个证明IOU预测可以作为一个好的标准来评价UDA self-traning 的pesudo box的。

### Triplet Box Partition to Avoid Ambiguous Samples

通过上述的IOU预测，引入Triplet Box Partition来解决 Ambiguous Samples的问题。具体方法很简单，就像anchor box的前景背景 assign一样，使用IOU（预测）作为评判标准，正阈值和负阈值之间的IOU被忽略，不赋予标签。

![](/assets/img/20210617/ST3DF4.png)

### Memory Update and Pseudo Label Generation

#### Memory Ensemble

这里使用一种memory ensemble方法来更新memory而不是直接用现有的伪标签替换。对于一对匹配的伪标签和memory，这里使用的choose box方法来做替换（选择），而不是加权平均，防止两个BBox加权后产生不合理的box。
![](/assets/img/20210617/ST3DE6.png)
#### Memory Voting

上述方法可以有效的选择更好的选择匹配的伪标签，但是不能处理没有匹配的伪标签。这些标签里可能既包含FP也包含高质量的TP，因此将他们全部纳入或者丢弃出memory都是不合理的。因此引入一个投票机制。利用未匹配目标框的历史信息来鲁棒的决定他们的状态。

![](/assets/img/20210617/ST3DE7.png)

根据历史保留次数，设定阈值来决定是否保留当前memory。

![](/assets/img/20210617/ST3DE8.png)

## Model training with CDA

作者的实验发现，绝大多数positive pseudo boxes都是easy examples，因为他们都来自于high-confident objext predictions。这样导致网络容易过拟合到exsay examples。这需要通过数据增强来解决，但是过强的数据增强可能会**confuse the learner and hence be harmful to model training at the initial stage**。故提出CDA。

### Curriculum Data Augmentation

 逐步增强数据增强的强度来解决上述问题。

 # Experiments

 ![](/assets/img/20210617/ST3DT1.png)

 