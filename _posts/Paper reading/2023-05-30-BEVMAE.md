---
layout: post
title: 'BEV-MAE: Bird’s Eye View Masked Autoencoders for Outdoor Point Cloud
Pre-training'
date: 2023-5-30
author: Poley
cover: '/assets/img/20230530/BEVMAE.jpg'
tags: 论文阅读  
---

## 背景
目前户外的LiDAR检测主要基于training from scratch，带来两个问题：1、这样需要大量的标注数据，但是标注成本很高；2、大量的无监督数据在每日的self-driving中被产生，但无法被这种Pipeline使用。上述两个问题都可以使用自监督预训练来解决。

目前预训练的方法主要分为两大类，基于对比学习(contrastive learning)以及基于mask model。就3D场景来说，由于3D中的增广方法没有2D中那么丰富，因此先前的一些基于对比学习的3D自监督方法需要复杂的预处理来产生伪实例来避免模型collapse。而本文则提出基于mask model来解决这个问题。

尽管基于MAE的点云预训练方法已经有了一些，但点云存在的一个问题，即indoor和outdoor的场景Gap太大，indoor的分类任务并不能很好的适应outdoor large scale的下游任务。而上述的工作一般都是基于合成点云的分类task或者室内场景的任务，并不适用于outdoor的large-scale自动驾驶场景。因此本文提出BEV-guide的点云mask方法。其他的一些MAE方法与本文的对比如下图所示
![](/assets/img/20230530/BEVMAEF1.jpg)

## 方法
本文方法示意图如下所示
![](/assets/img/20230530/BEVMAEF2.jpg)

从image的MAE自然的过渡过来，可以想到直接mask掉voxel再进行重建，这里作者认为单独Mask voxel是不够的，因此提出了bev guided的Point mask strategy，即最终mask和重建的目标都是points。这样确保网络可以学到最丰富准确的信息。简单的说，这里的mask point的策略是，根据其所在的bev coord，按voxel进行Mask（相当于分组mask），然后通过voxel的索引到其中对应的点，作为被mask掉的点。

由于稀疏卷积和常规的区别，这里作者进一步加入了**Learnable Point Token**。由于3D中的稀疏卷积只进行在非空体素上，因此如果mask的点直接从点云中删除，相当于点云被稀疏了。这样也许本来连通的体素被分割开了，从而导致稀疏卷积的感受野减小。因此引入可学习的point token起到占位的作用，而不提供任何信息。

在对于点的重建上，重建的最大挑战，voxel中点的数量不一致。这是是使用set-to-set loss来解决，为每个grid预测相同数量的points，并使用两个点集chemfer distance来作为监督。由于point coord变动大，这里回归（重建）的target是voxel内的归一化offset坐标。

最后，作者认为点云的density是反应点云几何信息以及距离等信息的重要指标，认为网络对density的学习（预测）可以帮助网络在自监督的过程中学习到更好的特征，因此加入了density的回归。其target比较简单，即volume内的点数/volume。

## 实验

在多个模型和多个数据集上都取得了一致的增益效果
![](/assets/img/20230530/BEVMAET1.jpg)
![](/assets/img/20230530/BEVMAET2.jpg)

同时few shot能力也有所增强
![](/assets/img/20230530/BEVMAET3.jpg)