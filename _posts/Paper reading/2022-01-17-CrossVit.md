---
layout: post
title: 'CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification'
date: 2022-1-13
author: Poley
cover: '/assets/img/20220117/CrossVit.png'
tags: 论文阅读
---

本文提出一种在Transfomer中以低计算复杂度融合Mutltiscale信息的方法。使用两个独立的Transformer分支分别处理不同scale的patch，（大patch和小patch）。并通过一个单独的token作为代理（agent）来在两个branch交换信息，实现网络对于multi-scale特征的捕捉，同时实现线性复杂度。


本文提出的结构如下图所示
![](/assets/img/20220117/CrossVitF2.png)

对于标准的ViT，其Transfomer的流程如下所示
$$
\begin{equation}
\begin{aligned}
&\mathbf{x}_{0}=\left[\mathbf{x}_{c l s} \| \mathbf{x}_{\text {patch }}\right]+\mathbf{x}_{\text {pos }} \\
&\mathbf{y}_{k}=\mathbf{x}_{k-1}+\operatorname{MSA}\left(\operatorname{LN}\left(\mathbf{x}_{k-1}\right)\right) \\
&\mathbf{x}_{k}=\mathbf{y}_{k}+\operatorname{FFN}\left(\operatorname{LN}\left(\mathbf{y}_{k}\right)\right)
\end{aligned}
\end{equation}
$$

在ViT里，分类的结果是通过一个单独的class token实现的，这个class token是一个Non-patch token，同样在transformer中和其他的patch交互，相当于global信息。其是一个手动创建的变量，而非来自于输入图像，因此可以将其视为一个代表了整体信息的代理（agent）。本文采用类似的思路，使用一个agent来实现branch，即不同scale之间高效的信息交互，以捕捉multiscale信息。

为了捕捉不同scale的特征，需要使用两个不同patch大小的分支，而如何高效的融合两个分支的信息则是本文的主要创新。

两个分支分别是
+ L-Branch：使用较大的patch size，更多的transfomer encoders以及更宽的embedding channel；
+ S-Branch：上述三项都相对更小。

注意到，这里的pos embedding也是可学习的，而不是固定的。

在如何融合两个branch(两个scale)信息的问题上，作者给出了4种选择，如下所示
![](/assets/img/20220117/CrossVitF3.png)

+ All attention: 即将所有特征一起做attention，计算复杂度会很高。
$$
\begin{equation}
\begin{aligned}
&\mathbf{y}=\left[f^{l}\left(\mathbf{x}^{l}\right) \| f^{s}\left(\mathbf{x}^{s}\right)\right], \quad \mathbf{o}=\mathbf{y}+\operatorname{MSA}(\operatorname{LN}(\mathbf{y})) \\
&\mathbf{o}=\left[\mathbf{o}^{l} \| \mathbf{o}^{s}\right], \quad \mathbf{z}^{i}=g^{i}\left(\mathbf{o}^{i}\right)
\end{aligned}
\end{equation}
$$
+ Class Token Fustion: 只对class token做融合，如下，相当于简单的全局信息融合
$$
\begin{equation}
\mathbf{z}^{i}=\left[g^{i}\left(\sum_{j \in\{l, s\}} f^{j}\left(\mathbf{x}_{c l s}^{j}\right)\right) \| \mathbf{x}_{\text {patch }}^{i}\right]
\end{equation}
$$
+ Pairwise Fusion: 成对做简单融合，考虑到不同patch带来了不同的token数量，这里使用插值的方式来解决这个问题
$$
\begin{equation}
\mathbf{z}^{i}=\left[g^{i}\left(\sum_{j \in\{l, s\}} f^{j}\left(\mathbf{x}_{c l s}^{j}\right)\right) \| g^{i}\left(\sum_{j \in\{l, s\}} f^{j}\left(\mathbf{x}_{\text {patch }}^{j}\right)\right)\right]
\end{equation}
$$
+ Cross attention：交换两者的cls token,即全局信息，与另一个branch的token进行交互，作为query。这样相当于充分融合了另一个branch中patch的所有信息，并保持了线性复杂度。处理过的patch再通过投影链接回自己的branch，并在后续的block中把融合到的信息传递到自己的branch中。如下图所示

![](/assets/img/20220117/CrossVitF4.png)

这个模块同样可以使用multihead方法来处理，如下所示
$$
\begin{equation}
\begin{aligned}
\mathbf{y}_{c l s}^{l} &=f^{l}\left(\mathbf{x}_{c l s}^{l}\right)+\operatorname{MCA}\left(\operatorname{LN}\left(\left[f^{l}\left(\mathbf{x}_{c l s}^{l}\right) \| \mathbf{x}_{\text {patch }}^{s}\right]\right)\right) \\
\mathbf{z}^{l} &=\left[g^{l}\left(\mathbf{y}_{c l s}^{l}\right) \| \mathbf{x}_{\text {patch }}^{l}\right]
\end{aligned}
\end{equation}
$$

多尺度信息的融合在CNN中已经体现出非常好的效果，而本文的主要思想在于如何在Transfomer中融合多尺度信息，并且实现线性复杂度，同样也取得了很好的效果。这点是主要的创新点。