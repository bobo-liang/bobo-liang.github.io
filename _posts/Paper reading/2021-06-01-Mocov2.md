---
layout: post
title: 'Improved Baselines with Momentum Contrastive Learning'
date: 2021-06-01
author: Poley
cover: '/assets/img/20210601/MOCOv2.png'
tags: 论文阅读
---
>论文链接 ： http://export.arxiv.org/pdf/2003.04297

这是一篇很短的论文，只有3页。主要内容是加了一些trick，将来自**SimCLR**的有效的部分结合到**Moco**里，有效的提升了性能。

**SimCLR**中，从三个层面提升了instance discrimination的端到端变体。
1. 更大的batch(4k or 8k)可以提供更多的负样本
2. 替换输出的fc projection head with an MLP head
3. 更强的数据增强

在Moco的架构中，负样本的数量已经可以很多。**MLP head和数据增强与对比学习的实例化方式是正交的**。

## MLP head
将MOCO中的fc 换成了MLP，性能有显著的提升，在不同温度下都是。

![](/assets/img/20210601/MOCOv2T1.png)

## Augmentation

在原有的数据增强基础上加入了 blur augmentation（作者发现stronger color distortion在本文中增益不明显）

对MoCo baseline的消融实验如下
![](/assets/img/20210601/MOCOv2T0.png)

其中可以看到单独用aug+的效果比用MLP的还好，在detection上，而在ImageNet分类上差一些。这说明线性分类准确率并不是单调的和transfer performance in detection相关的。

## 总结

总体来说，通过以上的改进，Mocov2相比SimCLR具有更好的性能。对于硬件和计算能力的需求也大大降低。