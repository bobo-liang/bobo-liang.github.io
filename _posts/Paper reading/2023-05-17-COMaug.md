---
layout: post
title: 'Curricular Object Manipulation in LiDAR-based Object Detection'
date: 2023-5-17
author: Poley
cover: '/assets/img/20230513/COM.jpg'
tags: 论文阅读  
---
本文的创新主要针对lidar方法中的loss和aug。提出ComAug作为对GT-aug的改进，使用group difficulties代替独立的difficulties，并在训练中不断更新，并逐步将困难样本插入训练样本。

作者分析了现有的GT-AUG的问题，认为训练早期引入hard样本可能导致模型过渡训练，而在后期引入easy样本可能会减慢模型收敛速度。进而产生3个问题：1、如何选择对当前训练阶段收益最大的样本？2、如何根据当前的训练阶段调整采样策略？3、同理，注意到样本中的原始目标可能也不是最适合当前训练的，如何将原始目标和增广目标一同处理以适应模型的训练？
本文通过引入curriculum learning来解决这个问题。即从易到难的学习。提出了两个方法COMLoss用于在训练前期一直hard sample的损失并随着训练逐步loose，COMaug则控制采样策略。由于Loss的变化会影响aug,因此这里会对所有object更新分数并进行difficult-adaptive的aug。分数的更新采用基于聚类的分组策略。

本文方法在训练前期和后期插入的样本定性可视化如下
![](/assets/img/20230513/COMF1.jpg)


对于curriculum learning，这里简单的将loss valuse作为difficulty的衡量。在点云中的基本思路是，使用逐步困难的合成数据训练。在OD任务中curriculum很少见，因为cls任务中是对sample-wise进行处理，而OD中不同物体的难度并不相同。而常见的是Hard-mining策略。因此在OD中引入curriculum需要仔细平衡easy-to-hard和hard-mining。

首先，对于使用GT sampling做增广的sample，其损失可以表示为如下
$$
\mathcal{L}=\frac{1}{N}\left(\mathcal{L}_{n}+\sum_{p=1}^{P}\left(\mathcal{L}_{c}^{p}+\mathcal{L}_{r}^{p}\right)+\sum_{q=1}^{Q}\left(\mathcal{L}_{c}^{q}+\mathcal{L}_{r}^{q}\right)\right)
$$

即负样本损失 + origin正样本 + 合成正样本损失；

首先对于curriculum学习是一个easy-to-hard的学习过程，因此一个难度度量是必要的。这里作者选择使用cls的分数作为难度度量，其有两个好处：1、其可以在训练中on-the-fly的进行评估，可以更好的与模型的训练同步；2、cls是训练过程中本身就要计算的一部分，不需要额外的计算成本。

但其也存在一些问题，使用cls的问题在于其不一致性，训练前期easy样本的分数也很低，可能导致其被判断为困难样本。这里引入一个平均分来表征网络训练的程度，即原始物体的平均分（滑动平均）。即以平均难度为标准衡量样本的困难程度，如下所示
![](/assets/img/20230513/COME2.jpg)
![](/assets/img/20230513/COME3.jpg)
其中s越小代表难度越高。

之后作者提出了COMLoss，其目的主要在于使模型在不同阶段关注与不同难度的样本，类似于hard mining。

![](/assets/img/20230513/COME4.jpg)
其函数曲线如下
![](/assets/img/20230513/COMF0.jpg)
当训练前期时，ht大于0，此时简单样本权重放大，困难样本被抑制，到后期则反之。通过上述加权，损失函数变为

$$
\mathcal{L}=\frac{1}{N}\left(\mathcal{L}_{n}+\sum_{p=1}^{P}w_p\left(\mathcal{L}_{c}^{p}+\mathcal{L}_{r}^{p}\right)+\sum_{q=1}^{Q}w_q\left(\mathcal{L}_{c}^{q}+\mathcal{L}_{r}^{q}\right)\right)
$$

COMaug则是配合上述Loss，在训练前期尽量插入简单的样本，而在训练后期多插入hard的样本。有选择的采样方式一个简单的方法是给物体打分，根据打分进行难度采样。打分通过每次被sample的时候更新。但是这样有两个问题：1、插入的物体有限，总物体很多的时候，物体被采样的概率很小，使得大部分物体的分数不能及时更新；2、因为不能及时更新，因此难度打分不准确，可能干扰训练。这里提出的解决方法是：1、聚类分组；2、按组打分；3、按难度自适应采样。
这里聚类通过Box的属性进行，距离、尺寸和朝向，以及occupancy ratio。聚类的可视化结果如下所示

![](/assets/img/20230513/COMF4.jpg)

各组的分数保存在一个分数池中，每次样本被插入训练sample之后更新其分数并加入该组分数池中，每个epoch之后将分数池的平均分作为该组的困难得分。在采样策略上，首先将所有组的困难得分按顺序排好，并使用一个高斯分布决定从每个组采样的概率，高斯分布的均值随着epoch的增大而移动，从简单的group对应的score逐渐移动像困难的group对应的score。

最后在性能上，本增广方法和损失也在多个模型上实现了相比GT-AUG的涨点。
![](/assets/img/20230513/COMT1.jpg)
![](/assets/img/20230513/COMT2.jpg)

对不同难度样本的采样曲线如下，基本符合作者的设计思路

![](/assets/img/20230513/COMF8.jpg)
