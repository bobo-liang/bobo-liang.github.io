---
layout: post
title: 'Fast Point Transformer'
date: 2022-5-30
author: Poley
cover: '/assets/img/20220530/FPT.png'
tags: 论文阅读
---

提出一种轻量化的self-attention layer。对连续的3D坐标进行编码，并使用体素的 hashing-based architecture来提高计算效率。本文的结果时competitive performance和比PT快129倍的计算速度。因此主要优化在速度，而非性能。

本文提出的FPT实际上笔者认为更加接近于卷积而非self-attention，而且其也可以完全替换3D Backbone中的卷积操作，使用相同的主干结构完成分割和检测任务。

![](/assets/img/20220530/FPTF1.png)

对于大场景的处理，基于点的方法由于其较高的复杂度，往往需要将场景分割为小块进行处理。而基于体素的方法在这方面比较具有优势，因为其网络结构的效率较高。提出的self-attention用于代替卷积，形成一个U-shape的分割网络，并且不需要手动grouping 点云，而是使用体素坐标+哈希结构来实现$O(1)$的近邻搜索，大大提高了网络的运行速度。

其结构如下所示
![](/assets/img/20220530/FPTF2.png)

本文的创新主要分为三部分，分别是
+ Centroid-aware voxelization
+ Lightweight self-attention
+ Centroid-aware devoxelization
如上图所示。

首先，1、在体素化的过程引入位置嵌入，2、通过哈希表+体素坐标完成O(1)的搜索过程
3、使用位置嵌入来合理的将voxel的特征分配到连续的3D点上。

首先，这里使用体素内点的平均位置，作为体素的坐标（连续），而不是常规的grid坐标（离散），这样可以更好地保留点的位置信息。之后，使用体素内点相对于体素坐标的偏移作为位置嵌入的信息，如下
$$
\begin{equation}
\mathbf{e}_{n}=\delta_{\mathrm{enc}}\left(\mathbf{p}_{n}-\mathbf{c}_{i=\mu(n)}\right)
\end{equation}
$$

之后，使用 permutation-invariant operator ，比如平均操作，来得到整个体素的特征，如下
$$
\begin{equation}
\mathbf{f}_{i}=\Omega_{n \in \mathcal{M}(i)}\left(\mathbf{i}_{n} \oplus \mathbf{e}_{n}\right)
\end{equation}
$$

在解体素化的过程中，执行和上述类似但相反的操作，即结合体素特征和每个点的位置（嵌入），生成每个点的点特征。反体素化主要是解决体素特征到点特征的分配问题。这里将位置嵌入作为额外信息，以根据点在体素中的位置动态的产生对应的点特征。
$$
\begin{equation}
\mathbf{o}_{n}=\operatorname{MLP}\left(\mathbf{f}_{i=\mu(n)}^{\prime} \oplus \mathbf{e}_{n}\right)
\end{equation}
$$

最关键的创新是本文作者提出的Lightweight self-attention。作者的思路是使用本特征以及邻域特征和本特征的相对位置关系（嵌入）来计算邻域特征的权重，并加权得到本位置特征。笔者认为其实这更像卷积，而不是self-attention,因为其Attention矩阵的计算并未用到两个特征之间的相关性，而只是用到了位置的相关性。基于上述思想，作者提出初步的模型为
$$
\begin{equation}
\mathbf{f}_{i}^{\prime}=\sum_{j \in \mathcal{N}(i)} a\left(\mathbf{f}_{i}, \delta\left(\mathbf{c}_{i}, \mathbf{c}_{j}\right)\right) \psi\left(\mathbf{f}_{j}\right)
\end{equation}
$$

但是这里的注意到，这里需要计算任意两个体素对之间的偏移和对应的嵌入，这具有很高的计算复杂度，为$O(IKD)$,其中$I,K,D$分别为i，邻域体素和维度的数量。注意到，对于所有的体素i计算其和对应K邻域体素的相对位置关系的复杂度是$O(IK)$，由于$c$的连续性。因此本文提出，将这个相对位置分解为gird之间的位移和各体素到自己grid中心的偏移，如下
$$
\begin{equation}
\mathbf{c}_{i}-\mathbf{c}_{j}=\left(\mathbf{c}_{i}-\mathbf{v}_{i}\right)-\left(\mathbf{c}_{j}-\mathbf{v}_{j}\right)+\left(\mathbf{v}_{i}-\mathbf{v}_{j}\right)
\end{equation}
$$

这样，对于全体体素，由于邻域的大小确定，因此$v_i-v_j$的复杂度是$O(K)$，由于他们是离散化的。而$c_i-v_i$也可以对所有体素进行计算，复杂度是$O(I)$，因此这样分解之后，位置嵌入的复杂度由$O(IKD)$变为$O(ID+KD)$，得以大幅降低。

随后，作者将体素内偏移嵌入体素特征，将grid间偏移用于计算权重，即
$$
\begin{equation}
\mathbf{g}_{i}=\mathbf{f}_{i}+\delta_{\mathrm{abs}}\left(\mathbf{c}_{i}-\mathbf{v}_{i}\right)
\end{equation}
$$
$$
\begin{equation}
\mathbf{f}_{i}^{\prime}=\sum_{j \in \mathcal{N}(i)} a\left(\mathbf{g}_{i}, \delta_{\mathrm{rel}}\left(\mathbf{v}_{i}-\mathbf{v}_{j}\right)\right) \psi\left(\mathbf{g}_{j}\right)
\end{equation}
$$
并使用cos相似度作为权重（此时权重不是归一化的），因此笔者认为这其实相当类似于自适应权重的卷积。
$$
\begin{equation}
\mathbf{f}_{i}^{\prime}=\sum_{j \in \mathcal{N}(i)} \frac{\phi\left(\mathbf{g}_{i}\right) \cdot \delta_{\mathrm{rel}}\left(\mathbf{v}_{i}-\mathbf{v}_{j}\right)}{\left\|\phi\left(\mathbf{g}_{i}\right)\right\|\left\|\delta_{\mathrm{rel}}\left(\mathbf{v}_{i}-\mathbf{v}_{j}\right)\right\|} \psi\left(\mathbf{g}_{j}\right)
\end{equation}
$$

至此，完成了这套以体素为中间媒介的点特征提取，其可以完全代替体素backbone来实现点特征提取。作者则是采取了一个unet类型的网络，如下所示

![](/assets/img/20220530/FPTA1.png)
