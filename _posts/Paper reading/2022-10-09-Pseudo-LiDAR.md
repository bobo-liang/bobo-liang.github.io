---
layout: post
title: 'Pseudo-LiDAR from Visual Depth Estimation: Bridging the Gap in 3D Object Detection for Autonomous Driving'
date: 2022-10-09
author: Poley
cover: '/assets/img/20221008/Pseudo-LiDAR.jpg'
tags: 论文阅读
---

参考博客:https://blog.csdn.net/weixin_45614254/article/details/109318785

使用图像做三维目标检测，其效果差不是因为使用图像得到的深度信息不准确，而是因为使用前视图这种表示方式的问题。以往认为基于图像的3D检测精确性更低是因为深度估计的质量不行，而作者认为是前视图这种表现形式更不良，然后作者提出伪激光雷达，也就是将深度图转换为点云形式，再输入到基于点云的3D检测模型，得到了很好的实验结果。

## 贡献
从经验上证明，造成基于双目立体和基于激光的三维物体检测性能差距的主要原因不是估计深度的质量，而是其表征。
提出了伪LiDAR作为3D对象检测的估计深度的新推荐表示形式，并表明它可以带来基于立体的3D对象检测技术，有效地使现有技术增加了三倍。结果表明，有可能在自动驾驶汽车中使用立体摄像机，从而有可能大幅降低成本 和/或 提高安全性。
## 未来可进行的工作
更高的分辨率图像来提高远处物体的精度。
实时多分辨率深度估计的最新改进表明，首先计算低分辨率的深度图，然后结合高分辨率对之前的结果进行细化，是提高深度估计速度的有效方法。
从深度图到伪激光雷达的转换非常快，通过 model distillation 或 anytime prediction，应该可以大大加快检测管道的速度。
通过激光雷达和伪激光雷达的传感器融合，很有可能在未来的工作中提高三维物体检测的技术水平。
## 论文细节
这种风格的现有算法主要基于 2D 对象检测，并施加了额外的几何约束来创建 3D建议。应用基于立体的深度估计以获得每个像素的真实 3D 坐标。
基于立体的三维深度估计的误差随着物体的深度呈二次增长，而对于飞行时间(ToF)方法，如激光雷达，这关系近似是线性的。
本文“缩小差距”的方法是小心地消除两种数据模式之间的差异，并尽可能地对齐两种识别管道。为此，提出了两步方法：首先从立体图像中估计密集像素的深度，然后将像素向后投射到三维点云中。通过将这种表示视为伪激光雷达信号，这可以应用任何现有的基于激光的三维物体检测算法。
代替通常将深度 D 作为多个额外通道并入RGB图像的做法，在左侧相机的坐标中得出每个像素（u，v）的3D位置（x，y，z）。通过将所有像素反投影到3D坐标中，可以得到3D点云 。在给定参考视点和观察方向的情况下，这种点云可以转换为任何坐标系。最终将结果点云称为伪 LiDAR 信号。
为了最大限度地与现有的激光雷达探测管道兼容，本文在伪激光雷达数据上应用了一些额外的后处理步骤。由于真实的激光雷达信号只驻留在一定的高度范围内，不考虑超出该范围的伪激光雷达点。例如在 KITTI 数据集中删除了所有高于虚拟激光雷达光源 1 米（车顶）的点。除了深度，激光雷达还返回任何测量像素的反射率(在[0,1]内)。由于视觉没有这样的信息，这里简单地将每个伪激光雷达点的反射率设置为 1.0。
在图像或深度映射上操作的卷积网络在图像/深度映射上执行一个2D卷积序列。虽然卷积的滤波器是可以学习的，但中心假设有两方面：
+ 图像中的局部邻域是有意义的，网络应该关注局部patch; 
+ 所有邻域都可以以相同的方式操作。
随着 IOU 的增大，视觉与雷达的性能也拉大，这因为遥远的物体有更大的视差误差需要更高的精度，这强调了需要精确的深度估计，特别是对遥远的距离，此外图像如果图像分辨率过小会导致远处物体只占有几个像素。
伪激光雷达具有信号密度比激光雷达大得多的优点，两种数据方式具有互补性。


## 论文重要点
利用金字塔立体匹配网络进行深度估计。伪激光雷达点(蓝色)与真激光雷达点(黄色)的对齐非常好，这与一般认为低精度的基于图像的深度是较差的 3D 目标检测的主要原因形成了对比。
两种处理方法：F-POINTNET-v1 和 AVOD-FPN
1. 将 伪LiDAR 信息视为 3D 点云。在这里，使用 frustum Point-Net（F-POINTNET-v1），它将 2D 对象检测投影到 3D 视锥中，然后应用 PointNet 在每个 3D 视锥上提取点集特征。
2. 从鸟瞰图（BEV）查看伪 LiDAR 信息。特别是，从顶向下的视图将 3D 信息转换为 2D 图像：宽度和深度成为空间尺寸，高度记录在通道中。AVOD（AVOD-FPN）将视觉特征和 BEV LiDAR 特征连接到 3D 建议框，然后融合两者以执行目标框的分类和回归。
最终结果是 AVOD 方法优于 F-POINTNET 方法。
这里应用 PSMNet，DispNet 和 SPS-STEREO 估计密集视差。后一种是基于非监督的。
在评估时，直接将 RANSAC 应用于处于一定道路高度范围内的伪激光雷达点，来拟合地平面参数。
视差估计的精度与目标检测的精度不一定相关，F-PointNet + DispNet-C 甚至优于 F-PointNet+ PSMNet，可能有以下两个原因：（1）视差精度可能不能反映深度精度：根据Eq，相同的视差误差(在一个像素上)会导致依赖于像素的真实深度的深度误差大不相同。（2）不同的检测算法对三维点的处理方式不同：AVOD将点量化成体素，而 F-POINTNET 直接处理它们，可能容易受到噪声的影响。
到目前为止，最准确的检测结果是通过本文从零开始训练的 PSMNet 获得的。

## 相关附图

1. 关于深度图质量的可视化，可以看到，现有的双目深度图估计所产生的伪点云和真实点云的对齐程度非常高。说明性能的差异可能不是来自于深度估计的质量；

![](/assets/img/20221008/Pseudo-LiDARF1.jpg)
2. 网络的总体结构
![](/assets/img/20221008/Pseudo-LiDARF2.jpg)
3. 2D卷积对于深度图边缘的模糊效应，可以看到车辆的边缘由于在grouping时收到图像邻域内背景点的影响（图像邻域，但3D空间中相距很远），导致边缘的深度被严重模糊了。在这样的数据下，不可能产生准确的目标检测结果。
![](/assets/img/20221008/Pseudo-LiDARF3.jpg)
4. 实验结果，可以看到，相比之前的基于深度估计的单目/双目估计，伪点云的检测结果性能有显著的提高。
 ![](/assets/img/20221008/Pseudo-LiDART1.jpg)
