---
layout: post
title: 'PointDAN: A Multi-Scale 3D Domain Adaption Network for Point Cloud Representation'
date: 2022-5-05
author: Poley
cover: '/assets/img/20220505/PointDAN.png'
tags: 论文阅读
---

本文是点云分类域适应问题方面的一篇经典文章。与2D图像一般直接对全局特征进行align从而进行域适应不同，3D点云的local具有显著的结构和对应的语义，而global往往通过这些Local来组成。由于视角的问题，3D点云物体的局部可能会被遮挡导致全局特征的差异，因此，对于3D点云局部特征的align就显得非常重要，如下图所示。总的来说，3D点云表征的域适应格外需要全局特征的对齐以及局部特征信息。而本文在局部上使用动态感受野来描述局部结构，全局上使用对抗训练来学习并对齐跨数据域的全局特征。

![](/assets/img/20220505/PointDANF1.png)

这篇文章的Intro介绍了不少关于无监督和对抗学习的内容，笔者之后也会逐一学习一下，争取用到自己的领域中。总的来说，无监督方法通过域间对齐的特征来匹配域的边缘分布或条件分布。方法是建立一个投影函数，将图像特征投影到一个共享的特征空间，同时最大化类间距离，最小化类内距离。而对抗学习方法则通过对抗，使得判别器无法使用判别从两个域中生成的特征，同样实现让不同域的特征相近的效果。

2D中通常使用特征的全局对齐。但是3D中每个局部都是可以被详细描述的，而且不同的局部结构也具有明显的语义特征。局部特征的组合形成了整个物体的全局语义。如上图所示，两个物体全局上弱align，但是各个局部的对应关系很强。

![](/assets/img/20220505/PointDANF2.png)

本文提出的方法主要分为两个部分：
+ 局部特征的提取和alignment
+ 全局特征的生成以及对抗学习的域适应方法

### Local Feature Alignment

一般来说，对于点云局部特征的提取需要先确定关键点Keypoints。这一般通过FPS采样得到。FPS采样近似于空间中的均匀采样，因此其采样点可以有保证的对全体点云进行覆盖。但这里的问题在于，如果要提取出明显具有语义的Local部分，那么对于采样点的位置就具有要求，最好完全覆盖一个显著的结构（local），比如桌面、桌腿等。这就意味着FPS得到的随机位置的采样点不能满足Local feature alignment的需求。

#### Self-Adaptive Node Construction

这个模型是作者为了上述解决上述问题而提出的方法，类似于deformable conv去为每一个卷积核的位置计算一个偏移，这里也同样通过计算偏移来调整keypoints的位置，使其可以最终移动到较好的local位置。

只不过这里考虑到点云的特性，采用的是类似于图的edge和相对位置对偏移位置进行回归。即通过邻域内的点域关键点的关系来调整关键点位置，如下
$$
\begin{equation}
\Delta \hat{x}_{c}=\frac{1}{k} \sum_{j=1}^{k}\left(R_{T}\left(\mathbf{v}_{c j}-\hat{\mathbf{v}}_{c}\right) \cdot\left(x_{c j}-\hat{x}_{c}\right)\right)
\end{equation}
$$
之后
$$
\begin{equation}
\hat{x}_{c}=\hat{x}_{c}+\Delta \hat{x}_{c}
\end{equation}
$$
 
而节点的最终特征则通过其邻域内所有点特征进行Maxpooling得到
$$
\begin{equation}
\hat{\mathbf{v}}_{c}=\max _{j=1, \ldots, k} R_{G}\left(\mathbf{v}_{c j}\right)
\end{equation}
$$

作者考虑到每个node对于物体的贡献并不相同，这里加入一个attention来对特征进行加权，如下
$$
\begin{equation}
\mathbf{h}_{c}=\varphi\left(W_{U} \delta\left(W_{D} \mathbf{z}_{c}\right)\right) \cdot \hat{\mathbf{v}}_{c}+\hat{\mathbf{v}}_{c}
\end{equation}
$$

在Local Alignment的损失上，使用最大均值差异MMD损失，如下
$$
\begin{equation}
L_{m m d}=\frac{1}{n_{s} n_{s}} \sum_{i, j=1}^{n_{s}} \kappa\left(\mathbf{h}_{i}^{s}, \mathbf{h}_{j}^{s}\right)+\frac{1}{n_{s} n_{t}} \sum_{i, j=1}^{n_{s}, n_{t}} \kappa\left(\mathbf{h}_{i}^{s}, \mathbf{h}_{j}^{t}\right)+\frac{1}{n_{t} n_{t}} \sum_{i, j=1}^{n_{t}} \kappa\left(\mathbf{h}_{i}^{t}, \mathbf{h}_{j}^{t}\right),
\end{equation}
$$

在全局特征上，类似于PointNet++,将上述关键点的局部特征插值到原始点上，并和原始点特征串联成为最终的点特征。使用一个生成器（卷积网络）生成一个全局特征，并使用两个分类器实现判别功能。一个分类器用于源域的经验风险最小化，

$$
\begin{equation}
L_{c l s}\left(X_{s}, Y_{s}\right)=-\mathbb{E}_{\left(\mathbf{x}_{s}, y_{s}\right) \sim\left(X_{s}, Y_{s}\right)} \sum_{k=1}^{K} \mathbb{1}_{\left[k=y_{s}\right]} \log \left(p\left(\left(\mathbf{y}=y_{s}\right) \mid G\left(E\left(\mathbf{x}_{s} \mid \Theta_{E}\right) \mid \Theta_{G}\right)\right)\right)
\end{equation}
$$

另一个则用于判别源域特征和目标域特征在输出上的区别，如下
$$
\begin{equation}
L_{d i s}\left(\mathbf{x}_{t}\right)=\mathbb{E}_{\mathbf{x}_{t} \sim X_{t}}\left[\left|p_{1}\left(\mathbf{y} \mid \mathbf{x}_{t}\right)-p_{2}\left(\mathbf{y} \mid \mathbf{x}_{t}\right)\right|\right]
\end{equation}
$$

在训练上，也和对抗学习一样。先学习判别器，即两个分类器，使其可以正确的获得源于和目标域的信息，损失如下
$$
\begin{equation}
\min _{F_{1}, F_{2}} L_{c l s}-\lambda L_{d i s}
\end{equation}
$$

之后再对生成器和local部分进行训练，减小域间差异，如下
$$
\begin{equation}
\min _{G, E, \mathcal{W}, \mathcal{R}} L_{c l s}+\lambda L_{d i s}+\beta L_{m m d}
\end{equation}
$$

本文的方法从理论上接近$\mathcal{H} \Delta \mathcal{H}$ - distance theory，这里省略。