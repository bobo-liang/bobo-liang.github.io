---
layout: post
title: 'BEVDet: High-Performance Multi-Camera 3D Object Detection in Bird-Eye-View'
date: 2022-10-27
author: Poley
cover: '/assets/img/20221025/BEVDet.jpg'
tags: 论文阅读
---

LSS等工作已经很成熟的将camera特征通过view transformer转换到了BEV空间中，从而实现了更好的BEV分割效果。很自然的，作者这里想把这套pipeline使用在detection中，毕竟分割和检测本身是流程相近的任务，只是head不同。

采取模块化设计，得到的网络结构如下。基本每个模块都跟LSS差不多
![](/assets/img/20221025/BEVDetF1.jpg)
直接把基于camera的BEV分割那一套搞过来或造成严重的过拟合问题。可能是由于BEV空间太强的拟合能力造成的，这里面有两个问题：
1、过拟合可以通过数据增广来解决。但是作者发现这只有当BEV encoder被absent的时候有用，否则反而有负面效果；
2、多相机中，image的编码器的batchsize实际上后续模块的N倍，可能造成后续训练的insufficient

## The Customized Data Augmentation Strategy
作者认为，数据增广失效的原因是因为view transformer将Pixel level的特征映射到bev空间，相当于将BEV空间和数据增广decouple了。因此，这里使用额外的数据增强在BEV空间中。


常见的增广方式，包括反转，cropping和旋转可以建模为一个3*3的变换矩阵。在进行view transformer之前，为了保证图像和bev中的特征保持consistency，在变换之前需要进行一个反变换去除数据增广。因此，实际上数据增广对于BEV空间起不到任何作用。

BEV容易过拟合的原因：
1、训练样本相比image encoder更少
2、与图像数据增广是isolate的关系。

解决方案：在BEV上单独再做一次aug，比如flipping,scaling，rotating等等。
这是BEV检测的特有方法，因为decouple，不适用于其他pipeline的方法。


## Scale NMS

![](/assets/img/20221025/BEVDetF2.jpg)

由于3D物体的尺度不相同导致了不同的iou分布。一种可能是小物体之间，由于feature map分辨率的问题，预测和真值之间里的很近但可能不存在IoU，从而相当于miss了TP（实际上这里的TP是按nuscenes的判定方式来的，按中心距离算。因此比如中心距离相距0.5m，但是两个pedestrian实际上已经没有Iou了，相当于错失了TP）。

因此，实际上这个NMS方法并不是很泛用。但是对nuScenes确实有一定的作用。

## Experiments

![](/assets/img/20221025/BEVDetT2.jpg)
