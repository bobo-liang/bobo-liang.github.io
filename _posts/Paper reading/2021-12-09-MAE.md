---
layout: post
title: 'Masked Autoencoders Are Scalable Vision Learners'
date: 2021-12-08
author: Poley
cover: '/assets/img/20211206/MAE.png'
tags: 论文阅读
---

本文提出一种非对称的encoder-decoder结构，随机遮挡输入图像的patches并且重建这些被遮挡的相似。通过这种方式得到了一种自监督的学习方式，可以很好的应用在分类任务和下游任务中。

其整体结构非常简单，如下所示
![](/assets/img/20211206/MAEF1.png)

但是思路非常新颖，非常值得学习。

作者首先关注到NLP领域中自监督方放 autoregressive language modeling and maked autoencoding，都使用了共同的概念，即移除一部分数据，来训练NLP模型的泛化行。但是这样的方法在计算机视觉中并不好用，因此，作者提出，**是什么使得masked autoencoding方法在视觉和语言中存在差异？**

作者认为，主要由于以下几个原因：
1. 处理数据的网络结构差异：图像中主要依赖于卷积，卷积在regular girds上运行并且没有直接包含类似于mask tokens和positional embeddings的 indicators。但是通过ViT，这种结构差异已经不复存在；
2. 信息密度：语言是高度语义化和信息稠密的，因此去掉一句话中的几个单词就会使得任务需要引入复杂的语言理解能力来处理。而图像是刚好相反的，是高度空间冗余的：丢失的patch很容易从近邻中恢复出来而不需要对于Part,Objects和Scenes太高的理解。对于这个问题，作者提出的方法是，使用非常高比例的mask来遮掉大部分的Patch，比如75%。如下图所示；
3. The autoencoder's decoder: 图像的decoder需要重建像素，即输出低语义等级的信息，和语言模型正好相反。因此，语言模型的decoder可以很简单（隐特征也是高语义特征，输出也是高语义特征），图像则需要更复杂的decoder，来扮演更重要的角色。

![](/assets/img/20211206/MAEF2.png)
![](/assets/img/20211206/MAEF3.png)

这里作者提出使用一个非对称的encoder-decoder，在encoder上只处理没有被遮挡的patch，并在decoder中恢复其正确的序列位置，处理所有的Patch来恢复原图。具体的实现方法如下：

+ Masking:随机按均匀分布遮挡（防止潜在的偏置出现），并且在patch内做归一化;
+ MAE encoder：线性投影+位置编码得到patch的特征，再经过Transformer Blocks;
+ MAE decoder: 类似于上，只不过将被遮挡的patch用统一的学习变量来代替;
+ Reconstruction target：重建损失只在被遮挡部分上计算。