---
layout: post
title: 'Confidence-driven Bounding Box Localization for Small Object Detection'
date: 2023-4-24
author: Poley
cover: '/assets/img/20230422/CBBL.jpg'
tags: 论文阅读  
---
本文关注与提升2D小目标的检测性能。作者认为现有的方法会产生distorted gradients，对小目标。因此提出了新的方法来修正梯度：1、使用对分布的分类损失代替回归损失，并使用分布的期望作为输出结果；2、引入不确定度的预测，预测 bounding box预测值和gt分布之间的交叉熵。本方法可以嵌入到多个方法上，实现提点。关于distorterd gradients，可以见下图
![](/assets/img/20230422/CBBLF1.jpg)
![](/assets/img/20230422/CBBLF2.jpg)

上图中使用Faster RCNN作为baseline，分别以可视化和量化统计的方式统计了在epoch 0 和epoch 12图像中以及这个题数据集上不同大小Object的梯度情况。注意到，这里使用faster rcnn，12e就是标准的1x训练了。对于一般目标，在训练刚开始时具有较大的梯度，而在训练结束时梯度较小，这是一个合理的趋于收敛的形式。但是对于小目标，梯度在训练开始和结束结束时都一直保持在较大的量级，并没有趋于收敛。这说明网络对于小目标的学习的梯度是有问题的，这样不稳定的梯度导致了模型不能很好的学习检测小目标。

本文主要是从改善梯度，稳定训练的角度出发。首先，本文对几种常用的回归loss进行了分析。

对于一般基于anchor的2D检测器，其回归损失一般被编码为
$$
\begin{equation}
\begin{aligned}
& \left\{T_x, T_y, T_w, T_h\right\}=\left\{\frac{x-x_a}{w_a}, \frac{y-y_a}{h_a}, \log \frac{w}{w_a}, \log \frac{h}{h_a}\right\} \\
& \left\{\hat{T}_x, \hat{T}_y, \hat{T}_w, \hat{T}_h\right\}=\left\{\frac{\hat{x}-x_a}{w_a}, \frac{\hat{y}-y_a}{h_a}, \log \frac{\hat{w}}{w_a}, \log \frac{\hat{h}}{h_a}\right\}
\end{aligned}
\end{equation}
$$

L2是一种常用的回归损失，其表示为
$$
\begin{equation}
\mathcal{L}_2\left(T_x, \hat{T}_x\right)=\left\|T_x-\hat{T}_x\right\|_2
\end{equation}
$$
其梯度为

$\frac{\partial \mathcal{L}_2\left(T_x, \hat{T}_x\right)}{\partial T_x}=2\left(T_x-\hat{T}_x\right)=\frac{x-\hat{x}}{w_a}$, likewise for $y$ $\frac{\partial \mathcal{L}_2\left(T_w, \hat{T}_w\right)}{\partial T_w}=2\left(T_w-\hat{T}_w\right)=\log w-\log \hat{w}$, likewise for $h$.


由于回归损失是通过anchor boxes的先验大小做了归一化的，因此小目标由于anchor boxes的尺寸更小。在L2 Loss下同样的误差在小目标上会被更加显著的放大，造成gradient distortion。

之后，往往使用Smooth L1代替L2作为回归损失，如下
$$
\begin{equation}
\begin{gathered}
\text { Smooth - } \mathcal{L}_1\left(T_x, \hat{T}_x\right)=\left\{\begin{array}{cc}
\frac{\left(T_x-\hat{T}_x\right)^2}{2 \beta}, & \left|T_x-\hat{T}_x\right| \leq \beta \\
\left|T_x-\hat{T}_x\right|-\frac{\beta}{2}, & \text { otherwise }
\end{array},\right. \\
\frac{\partial \text { Smooth }-\mathcal{L}_1\left(T_x, \hat{T}_x\right)}{\partial T_x}=\left\{\begin{array}{cc}
\frac{T_x-\hat{T}_x}{\beta}, & \left|T_x-\hat{T}_x\right| \leq \beta \\
\operatorname{sign}\left(T_x-\hat{T}_x\right), & \text { otherwise, }
\end{array} .\right.
\end{gathered}
\end{equation}
$$
之后改进使用的Smooth L1也有类似的问题，在Beta外使用线性损失保持了训练的稳定性，但是这样不能很好的衡量误差的大小（梯度恒定）。对于小目标，其经常产生更大的噪声。故L1会减慢网络的收敛速度。

对IoU Loss，从公式不太好做分析，这里作者直接画了其梯度曲线。如下所示从下图可以看出，同样的误差下，其对于小目标也更加敏感，导致了小目标的梯度不稳定。
![](/assets/img/20230422/CBBLF4.jpg)

综上，作者提出自己的方法，思想：基于分类做回归。但是简单的做One-hot分类不能给出target在interval中的准确位置。因此这里使用2-hot的方式来编码mid-interval information。将其分类权重分散到周围两个位置上。

即先将空间分为若干grid
$$
\begin{equation}
y_i=-a+i * \frac{2 \alpha}{n+1}, i \in\{0,1, \ldots, n-1, n\}
\end{equation}
$$
再取two-hot gt
$$
\begin{equation}
p_i^*=\left\{\begin{array}{cc}
\frac{n+1}{2 \alpha}\left(y_i^{\text {right }}-t^*\right), & i=i_{\text {left }} \\
\frac{n+1}{2 \alpha}\left(t^*-y_i^{\text {left }}\right), & i=i_{\text {right }} \\
0 . & \text { otherwise }
\end{array}\right.
\end{equation}
$$

在基于offset的预测里，target会不断减小？（没理解）。作者认为这样会让其一直落入固定的interval不利于训练。因此使用了不均匀的grid，改为指数form。改进的grid划分方式如下

$$
\begin{equation}
\begin{aligned}
& y_i^{\prime}= \begin{cases}\frac{\alpha}{e^{\alpha \cdot \beta}-1} \times\left(e^{\beta \cdot y_i}-1\right), & y_i \geq 0, \\
\frac{\alpha}{e^{\alpha * \beta}-1} \times\left(1-e^{-\beta \cdot y_i}\right), & y_i<0\end{cases} \\
& y_i^{\prime}-y_{i-1}^{\prime}=\frac{\alpha}{e^{\alpha \cdot \beta}-1} \times\left(e^{\beta \cdot y_{i+1}}-e^{\beta \cdot y_i}\right) . \\
&
\end{aligned}
\end{equation}
$$

做完上述基于分类的回归后，还在给出最后预测结果，还需要将分类结果转换为连续的回归数值。在从分类→连续数值的恢复上。取topk加权是数值不稳定的，这里直接对整个分布取期望。并加入了两个分布的损失。整个分类使用二值交叉熵来进行监督，如下
$$
\begin{equation}
\begin{aligned}
L_{C E}\left(p, p^*\right) & =-\sum_{i=0}^n p_i^* \log \left(p_i\right) \\
& =-p_{i_{l e f t}}^* \log \left(p_{i_{l e f t}}\right)-p_{i_{\text {right }}}^* \log \left(p_{i_{\text {right }}}\right) .
\end{aligned}
\end{equation}
$$
其梯度为
$$
\begin{equation}
\begin{aligned}
\frac{\partial L_{C E}\left(p, p^*\right)}{\partial l_i} & =\frac{\partial L_{C E}\left(p, p^*\right)}{\partial l_i} \times \frac{\partial p_i}{\partial l_i} \\
& +\sum_{j \neq i} \frac{\partial L_{C E}\left(p, p^*\right)}{\partial p_j} \times \frac{\partial p_j}{\partial l_i} \\
& =\left\{\begin{array}{cc}
p_i-\frac{n+1}{2 \alpha}\left(t_{r i g h t}-t^*\right), & i=i_{\text {left }} \\
p_i-\frac{n+1}{2 \alpha}\left(t^*-t_{\text {left }}\right), & i=i_{\text {right }} \\
p_i, & \text { otherwise }
\end{array}\right. \\
& =p_i-p_i^* .
\end{aligned}
\end{equation}
$$

优势：这样设计的交叉熵可以为不同尺度的object全部产生0-1的损失，更加稳定。而不会像上述分析的若干loss一样，不利于小目标的学习和梯度稳定。

最后这里额外加入了一个由信息熵差确定的不确定度。即在宏观上让预测值的信息量尽可能下降，达到gt two-hot的结果。笔者认为这里可能有些重复，因为交叉熵本身就和自信息与互信息有关。这里直接将gt和pred的自信息量的插值作为损失，如下

$$
\begin{equation}
\begin{aligned}
& L_{\text {uncertainty }}\left(p, p^*\right)=\left|\mathcal{H}\left(p^*\right)-\mathcal{H}(p)\right| \\
& =\left|-\sum_{i=0}^n-p_i^* * \log \left(p_i^*\right)-\sum_{i=0}^n p_i * \log \left(p_i\right)\right| .
\end{aligned}
\end{equation}
$$

综上，使用本文的方法在小目标的梯度稳定性上有较大的提高，定性可视化如下图所示
![](/assets/img/20230422/CBBLF5.jpg)
消融实验如下所示
![](/assets/img/20230422/CBBLT1.jpg)
对于不同检测器的提升效果如下所示
![](/assets/img/20230422/CBBLT4.jpg)