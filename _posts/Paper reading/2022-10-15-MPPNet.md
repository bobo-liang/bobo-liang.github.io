---
layout: post
title: 'MPPNet: Multi-Frame Feature Intertwining with Proxy Points for 3D Temporal Object Detection'
date: 2022-10-15
author: Poley
cover: '/assets/img/20221008/MPPNet.jpg'
tags: 论文阅读
---

本文发表于ECCV2022，提出一个三层的框架，使用proxy point来对多帧特征进行encoding并interactions，以实现更好的检测性能。三阶段分别是，per-frame encoding， short-clip特征融合，和全序列特征聚合。通过在时间和空间上充分融合同一物体在多帧中的感知信息，本文在检测能力上体现出了较大的优势。

多帧融合可以解决每帧汇总partial view的问题，partial view导致单帧中出现关于感兴趣物体的不完整的点云分布，使得对物体属性的准确估计变得困难。（这是一个实际存在的问题，比如big truck）。

现有方法已经证明了直接串联多帧点云可以对检测性能起到帮助。但是这只对短序列有用，对长序列来说，直接串联导致移动物体出现tail，反而增加了检测的难度，导致性能下降。如下图所示

![](/assets/img/20221008/MPPNetF2.jpg)

![](/assets/img/20221008/MPPNetT1.jpg)

本方法的核心是一系列的一系列内在对齐的proxy point，用于编码对象随时间变化的一致表示，以及一个三层次范式，用于更好地融合长期特征序列。一阶段，对单帧预测，产生每个object的proposal trajectory。这些proposal trajectory和其中对应的点将作为第二阶段的输入。通过在每个proposal里设置内在对齐的proxy point，来协助网络聚合多帧的时序特征。这是因为由于物体点在不同帧中可能具有截然不同的空间分布，因此直接聚合是有难度的。三个阶段分别负责处理单帧、短序列和长序列，特征是一个逐级聚合的过程。

在对Proposal进行特征编码的过程中，将多帧的geometric和motion做decouple。通过proxy point的相对位置来对proposal的运动情况进行预测。在聚合proposal特征时，需要在不同帧之间的proxy point之间两两建立连接。这对长序列不太可行。因此，这里使用short group，先聚合短的，再把聚合结果二次聚合。三阶段通过3D MLP Mixer和cross-attention来聚合组间信息。整体结构如下所示

![](/assets/img/20221008/MPPNetF1.jpg)

本文的主要创新在于二阶段使用proposal trajectory作为Input并且有效的在时间和空间上聚合多帧的Object feature。
## Single-frame Proposal Network and 3D Proposal Trajectories
首先，将输入序列分为4帧的clip，并将single-stage检测器拓展到多帧模型上来做检测。4帧的原因是通过实验确定的，即通过简单concatenate在4frame的时候效果最好。使用一个额外的head来预测object的速度。（因为这里也简单包含了multi frame的信息，因此这种预测也不是non-sense的）。这个speed用于在关联多帧proposal的时候进行加速。
## Three-Hierarchy Feature Aggregation with Proxy Points
对于每帧的bounding box，其中的点和对应的轨迹作为下一阶段的输入。其对物体提供了Multi-views。在proposal内均匀采样grid point做为proxy Point。因为Grid point在Proposal的局部坐标内具有固定的相对位置和排列顺序，因此在multiple frame之间同一个proposal的grid point是 naturally align的。

在几何特征的表达上，内点的相对位置使用9维表示。8corner+1center。作为object points的几何表征。如下
$$
\begin{equation}
\triangle l_i^t=\operatorname{Concat}\left(\left\{l_i^t-b_j^t\right\}_{j=1}^9\right)
\end{equation}
$$

通过set abstraction对Proposal内的点进行聚合。这里只聚合了几何特征，而没有语义特征（没有额外的Point branch）。实现了对几何信息的编码。在motion的编码上，使用proxy point相对与上一阵bounding box的8corners+1center的残差作为对物体的运动编码。这里的bounding box是已经通过车辆的全局运动信息转换到了同一坐标系下的。这个相对位移+帧间时间Offset一起作为Motion 的 embedding。如下

$$
\begin{equation}
\Delta p_k^t=\text { Concat }\left(\left\{p_k^t-b_j^T\right\}_{j=1}^9\right) \text {. }
\end{equation}
$$

上述motion特征和时间offset一起embedding成final motion


$$
\begin{equation}
f_k^t=\operatorname{MLP}\left(\text { Concat }\left(\Delta p_k^t, e^t\right)\right) \text {, for } k=1, \ldots, N
\end{equation}
$$

最后，将geometric和motion feature融合得到proposal的最终特征
$$
\begin{equation}
r_k^t=g_k^t+f_k^t, \text { for } k=1, \ldots, N
\end{equation}
$$

由于序列太长，对每一帧中的proposal在时间上两两建立联系的成本太高。因此将其进行分组，分为intra-group（组内）和inter-group（组见）的两阶段进行处理。具体的融合方法相当于直接将proxy point（N个）在不同frame上的特征串联（T'*D），经过MLP压缩到D维度。在这样简单的融合之后，引入一个3D MLP Mixer，分别在group特征的x y z c维度上分别对特征进行Mix，如上图所示。得到inter-group特征。
$$
\begin{equation}
\hat{G}^i=\operatorname{MLP}^{4 d}\left(\hat{G}^i\right), \text { for } s=1, \ldots, S
\end{equation}
$$
之后进行intra-group的特征聚合。以同样的方法可以得到多个group的all-group summarization特征，并作为中间媒介，与各组的特征进行cross attention。all-group相当于简单融合了同一个点在整个time sequence上的特征。每个点的group特征在去和其他点的sequence特征进行cross attention。相当于是时间和空间上的聚合。上述这个Inter和intra的操作模块重复数次，可以有效的表征trajectory's representations。相当于在时间和空间上有效的聚合了local和global的特征。
$$
\begin{equation}
\hat{G}^i=\text { MultiHeadAttn }\left(Q\left(\hat{G}^i+\mathrm{PE}\right), K(\hat{\mathcal{H}}+\mathrm{PE}), V(\hat{\mathcal{H}})\right) \text {, for } i=1, \ldots, S,
\end{equation}
$$
最后，对于一个proposal，得到了S组group特征。这里作者使用了一个类似于Memory bank的learnable embedding来实现多个group信息的聚合，如下

$$
\begin{equation}
E^i=\text { MultiHeadAttn }\left(Q(E), K\left(\hat{G}^i+\mathrm{PE}\right), V\left(\hat{G}^i\right)\right), \text { for } i=1, \ldots, S
\end{equation}
$$

最终，在实验结果上，确实实现了显著的性能提升，尤其是对于长序列来说。

![](/assets/img/20221008/MPPNetT2.jpg)