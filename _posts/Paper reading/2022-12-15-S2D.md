---
layout: post
title: 'Sparse2Dense: Learning to Densify 3D Features for 3D Object Detection'
date: 2022-12-16
author: Poley
cover: '/assets/img/20221205/S2D.jpg'
tags: 论文阅读  
---

本文提出一种网络蒸馏和辅助loss的方法，在付出很小计算代价的情况下提升现有3D检测器的性能。其提出，由于点云的稀疏性，点云对远处物体的检测能力较差。一种方法是通过额外的模块补全点云（相当于引入先验信息），之后再进行检测。然而，这些方法需要额外训练单独的补全模块，并且对于过于稀疏的点云，补全效果并不好，且计算代价较大。本文同样从引入先验知识的角度出发，提出了通过知识蒸馏和点云重建的辅助loss，隐式的在网络中补全点云的信息，从而实现网络性能的提高。

本文的结构如下图所示
![](/assets/img/20221205/S2DF2.jpg)

在网络上，本文使用两个网络进行知识蒸馏的训练，分别是稠密点云3D检测网络（DDet）和稀疏点云3D检测（SDet）。两者主要的区别在于输入上，稠密网络使用多帧拼接得到的稠密点云，首先单独进行训练。

稠密点云的构建方法如下：
1、使用完全的198帧的点云序列构建
2、主要关注于构建dense object，即稠密的前景信息：首先对序列中所有的帧，按照其包含的前景点点数进行排序，并按从高到低的顺序依次累加，以获得最密集的前景物体。直到全部场景95%的体素都被占据。 对于拼接的点，实际上进行了一个体素下采样的过程，以确保点数不会过多的同时，保留了完整的几何信息，如下图所示。

![](/assets/img/20221205/S2DF3.jpg)

综上，可以使用密集点云训练出一个具有较高性能的DDet，接下来的目的是将其蒸馏到应用于稀疏点云输入的SDet中。

如何蒸馏？常见的方法是对齐特征，并使用MSE Loss最小化差异。但是由于输入差异很大，这样做效果并不好。而且由于SPConv只对non-empty voxel做卷积，因此其也不可能对空体素产生特征，即，不可能对齐。而这里采取了隐式的方法，由于网络需要通过先验知识补全信息，故这里引入了额外的S2D网络，结构如下所示

![](/assets/img/20221205/S2DF4.jpg)

并在DDet分支输入纯前景的稠密点云，以得到纯前景的feature map，并用于监督S2D输出的dense feature map。即S2D包含了一个隐式的分割和补全功能，从稀疏的feature map中，隐式的完成了一个区分前景并补全前景信息的功能。

这样，原有feature map的前景信息被补充，使得整个feature map也可以跟DDet中包含背景信息的feature map进行element wise的监督。

最后，本文加入了一个重建损失，如图所示
![](/assets/img/20221205/S2DF5.jpg)

这里很巧妙的地方在于，作者通过体素化，巧妙的避开了传统重建loss建立中复杂的二分匹配问题。通过将准确的重建软化为对voxel点云中心的预测，这个问题变成了一个类似于detection的head设计，并且所有的点都具有一一对应的监督关系，使得训练变得简单。


最后，网络的性能如下
![](/assets/img/20221205/S2DT1.jpg)

从消融实验上来看，实际上S2D对网络信息的补全对网络性能具有最大最显著的提升
![](/assets/img/20221205/S2DT4.jpg)