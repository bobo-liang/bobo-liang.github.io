---
layout: post
title: 'SESS: Self-Ensembling Semi-Supervised 3D Object Detection'
date: 2021-12-28
author: Poley
cover: '/assets/img/20211228/SESS.png'
tags: 论文阅读
---

这是一篇比较经典的论文，通过perturbation scheme来增强网络对于未标注数据和新的没见过的数据的泛化性。整体结构上采用Mean teacher方法，在室内3D检测上取得了不错的效果。

其整体结构如下图所示
![](/assets/img/20211228/SESSF2.png)

在Mean Teacher的框架上，作者并没有进行太大的变动，同样适用一个teacher model 和一个 student model，并使用ema来向teacher传播参数的更新。因此，本文的创新主要集中于对于Mean teacher框架各部分的设计上。

## Perturbation Scheme

Input perturbation是self-embedding方法成功的关键角色。这里主要采用了两种干扰策略：

+ Random Sub-sampling：对于输入teacher和student的点云进行相同的下采样。这样两个随机样本之间的局部信息可能完全不同，但是整体的几何结构是相似的，这强迫网络去利用随机输入之间的一致性，即隐含的集合信息来完成任务和学习。
+ Stochastic Transform: 这里包含flipping(x,y), rotation(z) 和scaling四种方法(两种翻转)，分别以独立的概率采取增强（相互可以叠加）。这里和一般的增强没有区别，不再赘述。注意的是这个增强是针对student的，在有标注数据对Student进行Supervised和teacher与student进行Consistency的时候要把对应的标签也做对应的变换，才能和student的一致。

## Consistency Loss

这里选取配对目标框的方法比较简单，选取目标框中心欧氏距离最近的目标框作为当前目标框的配对目标框。由于这种最近是相对的，因此双向的匹配并不一定对称，在计算Loss的时候要考虑到双向匹配的情况，如下所示。
$$
\begin{equation}
\mathcal{L}_{\text {center }}=\frac{\sum_{\hat{c}_{s}}\left\|\hat{c}_{s}-\hat{c}_{t}^{A}\right\|_{2}+\sum_{\hat{c}_{t}}\left\|\hat{c}_{t}-\hat{c}_{s}^{A}\right\|_{2}}{\left|\hat{C}_{s}\right|+\left|\hat{C}_{t}\right|}
\end{equation}
$$

在Size和Class信息上，则直接使用teacher的输出作为标签来计算student 的consistency loss，比较简单。
$$
\begin{equation}
\mathcal{L}_{\text {class }}=\frac{1}{\left|\hat{P}_{t}\right|} \sum D_{K L}\left(\hat{p}_{s}^{\mathcal{A}} \| \hat{p}_{t}\right)
\end{equation}
$$
$$
\begin{equation}
\mathcal{L}_{s i z e}=\frac{1}{\left|\hat{D}_{t}\right|} \sum\left(\hat{d}_{s}^{\mathcal{A}}-\hat{d}_{t}\right)^{2}
\end{equation}
$$
$$
\begin{equation}
\mathcal{L}_{\text {consistency }}=\lambda_{1} \mathcal{L}_{\text {center }}+\lambda_{2} \mathcal{L}_{\text {class }}+\lambda_{3} \mathcal{L}_{\text {size }}
\end{equation}
$$

## Experiments 
![](/assets/img/20211228/SESST1.png)