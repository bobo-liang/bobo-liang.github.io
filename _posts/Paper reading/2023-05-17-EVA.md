---
layout: post
title: 'EVA: Exploring the Limits of Masked Visual Representation Learning at Scale'
date: 2023-5-17
author: Poley
cover: '/assets/img/20230513/EVA.jpg'
tags: 论文阅读  
---
本文的结构比较简单，如下所示
![](/assets/img/20230513/EVAF1.jpg)

简单的说，本文使用scale的vit模型，以mask的图像作为输入，预测图像的高维语义特征（即Image-text对），其中语义特征来自于提前训练好的CLIP模型。如上图所示。总的来说，EVA 是一种经过预训练的普通 ViT，用于重建 以可见图像块为条件的 屏蔽掉的图像-文本对齐（image-text aligned）的视觉特征。通过这个前置任务，我们可以有效地将 EVA 扩展到 10 亿个参数。

## 背景
扩大预训练语言模型 (PLM) 在过去几年彻底改变了自然语言处理 (NLP)。这一成功的关键在于掩码信号预测的简单且可扩展的自监督学习任务，利用该任务，Transformer 模型 可以使用几乎无限的未标记数据扩展到数十亿个参数，并且只需很少的调整就可以很好地泛化到各种下游任务。随着计算、数据和模型规模的进一步扩展，PLM 不仅带来了持续的性能改进，而且令人惊讶地出现了上下文学习(in-context learning)能力 。

受 NLP 模型扩展成功的推动，我们还可以将这种成功从语言转化为视觉，即 扩大以视觉为中心的基础模型，该模型有利于视觉和多模态下游任务。最近，掩码图像建模 (MIM) [5, 40, 116] 作为一种可行的视觉模型预训练和缩放方法得到了蓬勃发展。然而，最具竞争力的数十亿级视觉预训练模型仍然 严重依赖监督或弱监督训练 以及数亿（通常是公开不可访问的）标记数据。 MIM 在某种程度上仅被用作 严格地监督预训练之前的 初始化阶段 ，或者纯 MIM 预训练模型无法在十亿规模的模型大小下实现良好的性能。我们认为这种差距源于自然图像是原始的且信息稀疏的事实。同时，理想的视觉前置任务 不仅需要 低级几何结构信息的抽象，还需要高级语义的抽象，而像素级恢复任务 很难捕获这些信息。

在这项工作中，本文为大规模视觉表示学习寻找合适的 MIM 前置任务，并探索其在十亿参数规模和数千万未标记数据下的极限。最近，有一些试验 利用 图像-图像 或 图像-文本 对比学习的语义信息进行 MIM 预训练，它们在视觉下游任务中表现相当好。然而，关于 (i) 标记化语义特征 可以为视觉中的掩码建模提供更好的监督信号以及 (ii) 良好的性能也可以通过 没有掩码预测任务的 简单后蒸馏过程 [110 ]来实现 仍然存在争论 。通过试点实证研究，本文发现简单地使用图像-文本对齐（即 CLIP）视觉特征作为 MIM 中的预测目标可以很好地扩展 并在广泛的下游基准测试中 取得令人满意的性能。该预训练任务受益于图像文本对比学习的高级语义抽象 以及 掩码图像建模中几何和结构的良好捕获，这通常涵盖了大多数视觉感知任务所需的信息。

**本文的一个两点在于其在下游任务上的出色性能。** 此外，我们观察到 扩大EVA 的量变导致迁移学习性能的质变，这在其他较小规模的模型中没有观察到，例如，EVA 在具有挑战性的大词汇量 目标级识别任务中 取得了重大突破：我们的模型在 LVISv1.0（55.0 APmask on val），一个具有超过 1,200 个类别的实例分割基准，上实现了与 COCO（55.0 APmask on val），它几乎与 LVISv1.0 共享相同的图像集但仅注释了 80 个类别，几乎相同的性能（55.0 APmask on val）。这种涌现能力很好地符合模型扩展的期望，即模型的更大能力 不仅会 导致 标准基准的可预测性能改进，而且还会产生不可预测的现象和解决更具挑战性任务的能力。


**首先，本文寻求具有令人信服的迁移性能的 MIM 视觉前置任务。**基于先前关于视觉预训练的文献，本文研究了两个有前途的候选者：（i）恢复被屏蔽的标记化语义视觉特征，以及（ii）从强大的预训练表示中特征蒸馏，如。它们都利用预训练的图像-文本对齐视觉特征（即 CLIP 视觉特征）。通过表 2 中所示的一系列试点实验，我们发现：（i）（附加的）CLIP 特征标记化（tokenization）过程 对于 实现良好的下游性能 是不必要的（ii）特征蒸馏无法提供持续的性能增益，因为预训练变得更长。相反，我们发现 简单地重建 以可见图像块为条件的 掩码的 CLIP 视觉特征是高性能的，它被选择用于扩展 EVA。详情如下表所示

![](/assets/img/20230513/EVAT2.jpg)

在这项工作中，**本文表明这个前置任务可以扩展到十亿级参数和数千万个未标记图像**，用于以视觉为中心的表示学习，无需 (i) 语义特征量化/标记化，和 (ii) 明确使用图像-文本配对的预训练数据和大型语料库，如 BEiT-3。

## 下游任务性能

本文提出的方法在下游任务上的性能非常可观。
### Classification
![](/assets/img/20230513/EVAT4.jpg)
![](/assets/img/20230513/EVAT5.jpg)
## Video action recognition
![](/assets/img/20230513/EVAT6.jpg)

## Objection detection and segmentation
![](/assets/img/20230513/EVAT7.jpg)
![](/assets/img/20230513/EVAT8.jpg)