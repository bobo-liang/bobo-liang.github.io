---
layout: post
title: 'Adaptive Class Suppression Loss for Long-Tail Object Detection'
date: 2021-10-18
author: Poley
cover: '/assets/img/20211018/ACSL.png'
tags: 论文阅读
---

本文提出一种自适应的应别类别不平衡的方法，简单有效。

目前已经有很多启发性的工作，针对长尾问题作出了解决办法。但是这些方法大多都需要通过先验知识（出现频率）来人为的对不同的类别进行分组。这是一种hard division。这可能会到来两种两种问题：

+  临近类别的训练不一致性
+  少数类别的低判别能力

## 临近类别的训练不一致性

对于两个统计特性相似，正好处于硬分界点的类别，其面临着差别巨大的训练策略。这可能会导致网络性能的退化。

## 少数类别的低判别能力

通过绝对出现频率来进行分组实际上是次优的，因为其没有考虑到实例之间的相似性。比如对于*sunglass*和*eye mask*分别处于head和tail两个类别中。为了防止*eye mask*类别的分类器被过渡压制，其会忽略来自*sunglass*类别传来的负梯度。而这两个类别本身在特征空间中就具有一定的语义相似度，使得这两个类别在测试中非常容易混淆。也就是说，对于属于不同分组但是具有近似外观的类别，**网络很难学习到discriminative feature representation**。

![](/assets/img/20211018/ACSLF1.png)

本文提出ACSL，思想很简单。**将所有的类别都视为一个分组并且自适应的根据当前的学习状态压制从其他类别传递来的梯度**。

## 分析
对于SOTA方法 BAGS，进行了测试。将所有类别分为两组，如下图所示

![](/assets/img/20211018/ACSLT1.png)

可以看到，不同的分界点对于*mAP*的影响是很大的。同时，由于这个分组的阈值是人为确定的，因此在换数据集上的时候需要很多额外工作来确定新的阈值。

![](/assets/img/20211018/ACSLF2.png)

ACSL的主要思想如下：

+ tail classifiers 应该受到保护，以免被过多的head sample来过渡压制；
+ loss function 应该最好不依赖于类别先验类别频率，这样可以更方便的在不同数据集上训练；


![](/assets/img/20211018/ACSLF3.png)

ACSL的示意图如上所示，其动态的改变不同类别计算LOSS的权重。对于预测得分很小的负样本（即已经比较正确分类的负样本），不给予其权重，防止数量过多的类别对小数量类别过度的抑制。同时，使用sigmoid激活函数而非softmax，也是一样的原因。

Sigmoid交叉熵损失的梯度如下

$$
p_{i}=\frac{1}{1+e^{-z_{i}}}
$$
$$
L_{B C E}\left(x_{s}\right)=-\sum_{i=1}^{C} \log \left(\hat{p}_{i}\right)
$$
where,
$$
\begin{gathered}
\hat{p}_{i}=\left\{\begin{array}{cc}
p_{i}, & \text { if } i=k \\
1-p_{i}, & \text { if } i \neq k
\end{array}\right. \\
\frac{\partial L_{B C E}}{\partial z_{i}}= \begin{cases}p_{i}-1, & \text { if } i=k \\
p_{i}, & \text { if } i \neq k\end{cases}
\end{gathered}
$$

这里提出使用一个预定义的阈值$\xi$来动态的判断权值，如下

$$
L_{A C S L}\left(x_{s}\right)=-\sum_{i=1}^{C} w_{i} \log \left(\hat{p}_{i}\right)
$$
where,
$$
w_{i}= \begin{cases}1, & \quad \text { if } i=k \\ 1, & \text { if } i \neq k \text { and } p_{i} \geq \xi \\ 0, & \text { if } i \neq k \text { and } p_{i}<\xi\end{cases}
$$

得到如下的梯度
$$
\frac{\partial L_{A C S L}}{\partial z_{i}}= \begin{cases}p_{i}-1, & \text { if } i=k \\ w_{i} p_{i}, & \text { if } i \neq k\end{cases}
$$

在实验结果上展现出很大的提升

![](/assets/img/20211018/ACSLT2.png)

![](/assets/img/20211018/ACSLT3.png)