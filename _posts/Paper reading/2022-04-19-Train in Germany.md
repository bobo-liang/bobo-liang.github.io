---
layout: post
title: 'Train in Germany, Test in The USA: Making 3D Object Detectors Generalize'
date: 2022-4-19
author: Poley
cover: '/assets/img/20220419/TiG.png'
tags: 论文阅读
---

本文对于自动驾驶场景的三维目标检测域适应问题进行了较多的实验分析，认为不同区域之间的几何统计差别，导致模型不能很好的定位目标，导致性能的下降。通过引入目标域的几何统计对网络进行微调，取得了显著的性能提升。

大多数自动驾驶数据集的数据都是在同一个国家的城市的一小块区域采集的。即情况有限。数据区域的差别带来网络先验知识的差别，影响泛化性。在我的论文里，这些被称为不同的背景信息。这些往往是一些隐形的先验信息，即bias，比如：天是蓝色的，路是可见的，特定品牌的汽车等等。

本文主要关注于通过实验分析了解3D检测器的Bias ，并提出方法环节这些bias（其实也是域适应方法的目的）。

首先，本文对不同数据集上训练的模型进行了跨数据集，其性能出现了剧烈的下降，如下图所示。


![](/assets/img/20220419/TiGT2.png)

作者主要对于数据集之间的统计信息差别进行了分析，首先是尺寸。根据统计，美国最流行的车是5m长的truck，比如Ford F-series。而德国则更喜欢4米长的紧凑型轿车，比如大众高尔夫。因此，在德国采集的KITTI数据集中的车辆目标相对与Waymo数据集要更小。

同时，作者也提到，其他数据集的数据向nuscenes迁移时，一般具有较差的性能。**这可能是由于nuScenes 的32线低质量点云导致的**。

同时，从上表来看，从低到高线束的迁移更容易，反之更难，因此作者推测，**传感器质量在测试时相比训练时对模型更加重要**。

作者对不同数据集中的目标和标注框进行了分析，如下

首先是场景和目标的平均点数
![](/assets/img/20220419/TiGF2.png)

然后是标注框的尺寸分布
![](/assets/img/20220419/TiGF3.png)

作者这里很关键的一个实验如下
![](/assets/img/20220419/TiGF5.png)

作者对于直接迁移的模型画出了其不同IOU下的AP曲线。发现在低IOU下，不同源域模型的差距较少，而随着IOU的提高，差距逐步变大。**这说明模型之间的基本检测能力差别较小，而准确定位能力（回归）差距较大**。进一步的作者将所有IoU>0.2的检测框，在保持底面中心和旋转角不变的前提下，将其尺寸换成了对应的真值尺寸，此时出现了巨大的性能提升，如下表所示。由此，作者得出结论，**几何统计的差别对于模型的域适应具有显著影响**。

![](/assets/img/20220419/TiGT3.png)

作者提出的方法也很简单，有两种方法：
+ **Few-shot(FS) fine-tuning**:对目标域场景进行少量标注，用这些样本对于源域预训练模型进行fine-tune，以获得学习目标域的几何统计信息。此时性能曲线如下图所示，只需要20个样本的训练就可以达到直接在目标域上使用500个样本训练的效果。

![](/assets/img/20220419/TiGF6.png)

+ **Statistical normalization（SN）**：不需要使用目标域标注数据，通过其他方式获得目标域的几何统计后，直接对源域目标进行对应的缩放，并使用缩放后的源域目标和场景对网络进行fine-tune。同样具有不错的效果。具体方式是根据源域和目标域的统计差别计算一个尺寸bias
$$
\begin{equation}
\Delta=(\Delta h, \Delta w, \Delta l)=\left(h_{\mathrm{TD}}, w_{\mathrm{TD}}, L_{\mathrm{TD}}\right)-\left(h_{\mathrm{SD}}, w_{\mathrm{SD}}, L_{\mathrm{SD}}\right)
\end{equation}
$$
之后对源域所有目标减去这个偏置即可，并对目标中的点进行对应的缩放。如下图所示

![](/assets/img/20220419/TiGF7.png)

+ **Output transformation(OT)**: 同上，只不过对输出结果进行偏置。效果不佳。

最终三种方法的结果如下所示
![](/assets/img/20220419/TiGT4.png)
