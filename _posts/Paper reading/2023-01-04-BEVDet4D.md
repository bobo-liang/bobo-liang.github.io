---
layout: post
title: 'BEVDet4D: Exploit Temporal Cues in Multi-camera 3D Object Detection'
date: 2022-12-26
author: Poley
cover: '/assets/img/20230103/BEVDet4D.jpg'
tags: 论文阅读  
---






结构上基本继承BEVDet：其大体结构: image-view encoder，view transformer, bev encoder和head。在融合方式上，只探索了最简单的融合方式，concat。
![](/assets/img/20230103/BEVDet4DF2.jpg)

同时，作者认为，由于LSS的bev太稀疏，太粗糙，会影响融合的质量。这里在融合前加入了额外的bev encoder。个人认为这里实际上是为了一定程度上弥补动态目标在自车补偿之后的位置差异（扩散一下）。

本文的大篇幅内容主要在讨论自车补偿问题，但是也没什么新东西。总的来说，自车补偿如下
$$
\begin{equation}
\mathcal{F}^{\prime}\left(T-1, \mathbf{P}^{e(T-1)}\right)=\mathcal{F}\left(T-1, \mathbf{T}_{e(T)}^{e(T-1)} \mathbf{P}^{e(T)}\right)
\end{equation}
$$
即对于当前BEV中的位置，将其做自车补偿后投影到上一帧的BEV中，可以插值得到具体的值。补偿与不补偿的对比示意图如下所示
![](/assets/img/20230103/BEVDet4DF3.jpg)
这里作者认为将BEV位置投影做插值是次优的方法，最优的方法应该是对LSS 池化前的points做补偿，然后再通过view transformer转换到BEV上。但这样做成本更高，因此作者将其舍弃。同时，对于BEV进行转换插值的方式在Pillar的分辨率提高的情况下，性能退化逐渐减小。

实际上前者的转换方式就是PETRV2的时序引入方法，只是没有view transformer而已。

![](/assets/img/20230103/BEVDet4DT1.jpg)



消融实验结论：1、不对齐的引入时序造成性能下降，translation对齐后性能显著提升；2、以offset形式预测速度更加准确（预测物体在两帧之间的位移）；3、extra bev encoder可以略微提升性能；4、提升速度损失权重可以略微提高NDS；5、引入旋转补偿略微提升性能；6、在选择邻接帧时对时间进行增广提升效果明显。


![](/assets/img/20230103/BEVDet4DT3.jpg)
