---
layout: post
title: 'Improving 3D Object Detection with Channel-wise Transformer'
date: 2021-11-22
author: Poley
cover: '/assets/img/20211122/CT3D.png'
tags: 论文阅读
---

本文使用高质量的RPN和Channel-wise Transformer结构来来构建一个二阶段3D检测器ST3D。CT3D同时进行对于proposal中的点特征的proposal-aware embedding和channel-wise context aggregation，再使用proposal中的关键点进行一个encoding-decoding结构得到更强的特征。

本文同样受到DETR的启发，使用一个类似的结构，即CNN Backbone用于提取特征，然后使用一个encoder-decoder Transformer来增强RoI region features。

## CT3D 
![](/assets/img/20211122/CT3DF1.png)

主要由三部分组成，an RPN backbone, a channel-wise Transformer for proposal feature refinement, a detect head。
这里作者得创新主要再中间部分的channel-wise Transformer上。

### RPN 
这里作者直接使用的是SECOND中的RPN，但是理论上任何高质量的RPN都可以在作者的框架中替代现有的RPN。

### Proposal-to-point Encoding Module
Encoding分为两步，分别是proposal-to-point embedding和self-attention encoding。

#### Prposal-to-point Embedding
首先根据Proposal划出一片点云来，这个范围比Proposal的大小要大一些，目的是补偿proposal和ground-truth之间的差异，尽可能把所有的object points都包含进来。范围最终是一个圆柱体型的(cylindrical）,不限高度，半径为$r=\alpha \sqrt{\left(\frac{l^{c}}{2}\right)^{2}+\left(\frac{w^{c}}{2}\right)^{2}}$，其中$\alpha$是超参数。之后在其中采样$N=256$个点。
在计算出采样点和Proposal中心的相对坐标之后，最简单的方法是把proposal的参数$\left[\Delta \boldsymbol{p}_{i}^{c}, l^{c}, w^{c}, h^{c}, \theta^{c}, f_{i}^{r}\right]$直接串联到点特征上。但是这样在Transformer直接利用几何信息的refinement效果有限。而另一种在检测中比较好的利用几何信息的方法就是key points（这里是corner points，8个）。8个corner points包含了和上述表示方式相同的信息。这里直接计算每个点和8个角点的相对坐标并串联起来，通过线性映射到高维空间中进行embedding如下
$$
\begin{equation}
\boldsymbol{f}_{i}=\mathcal{A}\left(\left[\Delta \boldsymbol{p}_{i}^{c}, \Delta \boldsymbol{p}_{i}^{1}, \ldots, \Delta \boldsymbol{p}_{i}^{8}, f_{i}^{r}\right]\right) \in \mathbb{R}^{D}
\end{equation}
$$

#### Self-attention Encoding
这里使用的就是一个标准的self-attention模块。
![](/assets/img/20211122/CT3DF2.png)

### Channel-wise Decoding Module
目的：将编码模块中输出的全部点特征，通过解码得到一个global representation，之后通过一个FNNs用于最后的检测预测。

和传统的Transformer解码使用长度为$M$的query不同，这里只是用长度为1的query，主要是因为，一般query的数量对应最后生成的预测的数量，但是这里只需要一个预测（refinement）。

标准的解码流程如下，使用一个可学习的向量，比如query embedding来作为query计算输入向量对应的权重.其中，$h$代表了不同的head。

$$
\begin{equation}
\boldsymbol{w}_{h}^{(S)}=\sigma\left(\frac{\hat{\boldsymbol{q}}_{h} \hat{\mathbf{K}}_{h}^{T}}{\sqrt{D^{\prime}}}\right), h=1, \ldots, H
\end{equation}
$$
由此得到的权重可以视为是每一个点单独的权重，并进行简单的全局aggregation。但是这样做缺少了对于local channel wise的建模。

#### Channel-wise Re-weighting
这里使用 key embedding中提取channel-wise信息。这样可以产生D个不同的channel weight，进而产生D种解码结果。之后将这些解码结果做线性变换变成一个单位的channel-wise decoding vector，即
$$
\begin{equation}
\boldsymbol{w}_{h}^{(C)}=\boldsymbol{s} \cdot \hat{\sigma}\left(\frac{\hat{\mathbf{K}}_{h}^{T}}{\sqrt{D^{\prime}}}\right), h=1, \ldots, H
\end{equation}
$$
如下图所示。

![](/assets/img/20211122/CT3DF3.png)

#### Extended Channel-wise Re-weighting
结合两者，作者使用如下作为最终的decoding weight vector for all points。
$$
\begin{equation}
\boldsymbol{w}_{h}^{(E C)}=s \cdot \hat{\sigma}\left(\frac{\rho\left(\hat{\boldsymbol{q}}_{h} \hat{\mathbf{K}}_{h}^{T}\right) \odot \hat{\mathbf{K}}_{h}^{T}}{\sqrt{D^{\prime}}}\right), h=1, \ldots, H
\end{equation}
$$
最终得到用于回归和预测的特征为
$$
\begin{equation}
\boldsymbol{y}=\left[\boldsymbol{w}_{1}^{(E C)} \cdot \hat{\mathbf{V}}_{1}, \ldots, \boldsymbol{w}_{H}^{(E C)} \cdot \hat{\mathbf{V}}_{H}\right]
\end{equation}
$$

## Experiments
![](/assets/img/20211122/CT3DT1.png)
![](/assets/img/20211122/CT3DF5.png)
笔者注：上图中可以看出，虽然最高的attention权重都在车上（这是必然），但是车附近的地面点同样具有中等的权重，这是否说明车辆附近的地面信息同样对预测起到一定的作用？直观上想是这样的，实际上是么？