---
layout: post
title: 'Object as Query: Equipping Any 2D Object Detector with 3D Detection Ability'
date: 2023-1-29
author: Poley
cover: '/assets/img/20230103/MV2D.jpg'
tags: 论文阅读  
---




目前主要分为两种方法，dense和sparse，dense的计算代价随着range的增大而平方增大，不适用于large-scale的场景。query-based的sparse避免了大量的计算，但是query的数量和位置依赖经验先验，可能导致FP或者漏检（FN），在动态的场景中。

本文提出，将成熟的2D检测的每一个结果作为query用于后续的3D检测。

本文的主要创新：
+ 一种动态稀疏object query的生成方法，基于2D图像的检测结果
+ 一种sparse aggregation方法，聚合特定相关邻域的特征

本文的总体效果如下，3D检测中若干小物体并不容易检测，但是在成熟的图像检测领域则相对容易检测。这里基于2D检测结果产生初始化query位置，显著的提高了模型的召回率。
定性可视化如下
![](/assets/img/20230129/MV2DF1.jpg)

定量统计如下
![](/assets/img/20230129/MV2DF5.jpg)

本文的整体结构如下
![](/assets/img/20230129/MV2DF2.jpg)

如上图所示，产生query位置初始化所使用的信息：2D BBOX, ROI FEATURE和相机参数。这里并不要使用全部的图像特征，而是使用ROI特征，并在此基础上进一步对ROI特征进行了筛选。

首先根据2D预测获得ROI特征，由于RoI都被缩放到了统一大小，因此损失了原始图像中的几何信息，因此从中直接预测深度并不好。这里使用的方法是结合相机参数对RoI中的Object Location进行隐式的预测。RoI有一个缩放过程，这可以直接通过对相机内参进行变换实现，对ROI的缩放等效变为相机内参的缩放，将roi坐标投影到3D

相机内参可以表示为
$$
\begin{equation}
\mathbf{K}_v=\left[\begin{array}{cccc}
f_x & 0 & o_x & 0 \\
0 & f_y & o_y & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1
\end{array}\right] .
\end{equation}
$$
经过RoI pooling后可以表示为
$$
\begin{equation}
\mathbf{K}_v^i=\left[\begin{array}{cccc}
f_x * r_x & 0 & \left(o_x-x_{\min }^i\right) * r_x & 0 \\
0 & f_y * r_y & \left(o_y-y_{\min }^i\right) * r_y & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1
\end{array}\right]
\end{equation}
$$
其中$r_x=W^{r o i} /\left(x_{\text {max }}^i-x_{\min }^i\right), r_y=H^{\text {roi }} /\left(y_{\max }^i-\right.$ $\left.y_{\min }^i\right)$

之后隐式估计一个ref point，并投影到Lidar坐标系中

$$
\begin{equation}
\mathbf{p}_v^i=\mathcal{H}\left(\operatorname{MLP}\left(\operatorname{Pool}\left(\operatorname{Conv}\left(\mathbf{o}_v^i\right)\right) ; \mathbf{K}_v^i\right)\right)
\end{equation}
$$

上述即完成了图像特征的提取，以及query ref points的初始化，总结如下图所示
![](/assets/img/20230129/MV2DF3.jpg)
为了准确的定位，query应该关注于所有相关的图像区域，并且丢弃无关的区域，避免干扰。因此这里提出了一种token的筛选策略。相关的定义：cover the object，即产生query所使用的box，以及在别的view中与上述box对应的box。其中，第一种情况非常容易检索（一对一）。后一种情况本文提出一种方法高效检索（实际上就是检索cross view information）。


检索的方法非常巧妙。如下图所示。类似于3DPE，对ROI构建一个密集深度的meshgrid，并投影到其他的view，确定一个最小的Bounding box，并选取其他view中与其roi最大的box作为相关box。这种情况下，每个query在每个view上至多获得一个box的信息。


![](/assets/img/20230129/MV2DF4.jpg)

最后，在decoder中，RoI Feature使用3DPE进行编码。和PETR一样。

损失函数上，只有2D和3D Loss，也就是说上述ref points的预测实际上是无监督的，隐式的。

性能上，有较大优势，主要来自于图像对小目标的强力的检测能力
![](/assets/img/20230129/MV2DT1.jpg)




