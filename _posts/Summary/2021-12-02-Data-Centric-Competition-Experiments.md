---
layout: post
title: 'Data-Centric AI Competition 经验分享'
date: 2021-12-01
author: Poley
cover: '/assets/img/mycat3.jpg'
tags: 总结
---

## Team: KAIST – AIPRLab

### 比赛中的主要困难和挑战
现有的方法普遍不太好用，存在理论和实践的差距。最终决定，重要的是找到一种简单而富有创意的方法，而不是指望最新的方法可以神奇的解决问题。

### 所采用的方法
希望使用一些更基础的可以泛化到不同数据域的方法。只使用了竞赛中提供的数据，方法分为三个步骤：**Data Valuation, Auto Augmentation,  Cleansing with a Contrastively Learned Model, Edge Case Augmentation and Cleansing**。

#### Data Valuation
我们从使用梯度下降优化深度学习模型的想法开始。一个常用的类比将这个过程比作徒步旅行者沿着沿途有里程碑的山谷行走。但是，如果提供的里程碑具有误导性，徒步旅行者可能会迷路。类似的问题也可能发生在深度学习中，其中模型是根据误导性示例进行训练的。因此，我们需要删除这样的列车数据点。我们使用强化学进行数据评估的初步实验结果证明对于极其嘈杂的数据集无效。

我们可以通过影响函数的方法来看看训练数据点如何影响模型对验证数据点的预测。这背后的基本思想是将特定训练点的权重少量提升，看看这如何影响推理时的模型预测。我们结合了 HyDRA，它使用验证损失的梯度（也称为超梯度）来有效地近似训练点对模型优化轨迹的局部影响。**从那里，我们删除了具有负面影响的训练数据点。**

然而，这绝不是清除数据集中所有噪声点的完美算法，因为我们的验证集太小。我们的实验表明，该算法可以去除大部分噪声数据，但该方法仍然可以去除具有语义意义的图像，或者不会去除混合到训练数据集中的绝对不相关的图像。因此，我们在进行增强之前应用了额外的清理操作。 

#### Auto Augmentation
增强是计算机视觉中其他领域的常用技术，用于创建更多训练样本并构建更稳健的模型。 然而，为增强找到一组合适的变换通常涉及体力劳动，因此非常耗时。 尽管竞争数据集小而简单，可以手动找到合适的增强策略，但我们还是采用了自动增强来减少人工干预。

这些自动增强算法在收到有关验证数据的反馈后寻找最佳增强策略。 在许多提议的方法中，我们使用了 Faster Auto Augment，它通过使算法完全可微来大大减少了搜索时间。 为了保留尽可能多的信息，我们在 64 x 64 图像上应用了增强。 此外，我们平衡了每个类中的样本数量以解决类不平衡问题。

#### Cleansing with a Contrastively Learned Model
即使经过清洗和增强，数据中仍然存在噪音。此外，增强图像有时具有错误的语义标签。例如，“iv”的图像可能会被过度向右平移而变成“i”。为了消除此类噪声并修复错误标记的数据点，我们使用了来自 Siamese 网络的特征表示，该网络已在迄今为止以对比和监督方式获得的数据集上进行训练。

我们通过 t-SNE将 Siamese 网络的学习潜在特征投影到 2D 空间，并使用可视化来检查集群。我们可以从这个可视化中识别出明显被错误标记或毫无意义的数据点。使用 k 最近邻距离和标签，如果标签明显是一个标签错误（所有邻居都具有与感兴趣点相同但不同的标签），我们修复了标签，或者如果数据点不明显属于一个集群，则删除数据点（最近的邻居远离兴趣点或其邻居仅在距数据点的某个方向上）。

#### Edge Case Augmentation
由于它们的比例很小，一些边缘情况然存在在这些程序中持续存在。 因此，我们需要识别和增加这些边缘案例样本。 我们决定使用到目前为止用数据训练的模型的表示。 正如我们在上一步所做的那样，我们通过 t-SNE 将潜在特征投影到 2D 空间。 我们可以将明显属于一个集群但远离最近的同级邻居的数据点识别为边缘情况数据点。 我们在每个集群中增加了这些孤立的数据点。

#### Cleansing
最后，在进一步的边缘情况增强之后，我们以与步骤 3 相同的方式再次清理数据集。 在这个步骤之后，我们可以在测试数据集上达到 0.84711 的准确率。 我们将继续发展和简化在外部数据或预训练模型不易获得的领域中的工作方法。

## Team: INNOTESCUS , Rank: 2

方法可以分为两部分： Data Labeling and Data Distuibutions.

### Data Labeling
这部分即数据清洗工作，比赛中提供的数据中有很多错误和不一致。具有一致性的正确标签可以减少错误。

+ Identify noisy images： 去除一些噪声样本（人为无法分辨）的样本；
+ Identify incorrect classes: 去除标注错误的样本；
+ Identify ambiguous data points: 修改一些模糊标注的样本，比如罗马数字2和罗马数字5之间的模糊。

通过上述数据清洗，大概从比赛提供的数据集中去除了22%的数据，使用这些数据直接训练，结果相比baseline得到了约9%的提升。

### Balancing Data Distributions

当我们在现实世界中收集训练数据时，我们可以说是及时捕捉到数据的快照，总是将隐藏的偏差引入我们的训练数据中。 大多数情况下，有偏差的数据会导致学习不佳。 一种解决方案是减少不明确的数据点并确保沿数据集中方差的主要维度保持平衡。

#### Rebalancing Training and Testing Datasets

真实世界的数据有很多内在的差异。 这种差异几乎总是会导致分布不平衡，尤其是在观察特定特征或度量时。 当增加时，这些偏见会被放大。 结果？ 向您的模型投放更多数据可能会使您离目标更远。我们在本次比赛中提交的两份参赛作品中观察到了这一点。 两次提交包含相同的数据，只是在训练和验证之间划分不同（分别为 80:20 和 88:12）。 我们看到，在训练集中添加 800 张图像实际上使测试集的准确率降低了约 1.5%。 在此之后，我们的方法从“更多数据”转向“更平衡的数据”。

#### Rebalancing Subclasses Using Embeddings

首先，采样使得每个类别具有平衡的数量。
之后在每个大写和小写的子集中进一步探索聚类，将每个情况进一步细分为3类，利用K-means聚类方法，聚类的特征通过对ResNet50 embedding特征做PCA降维得到。如下所示
![](/assets/img/20211202/AI0.png)
![](/assets/img/20211202/AI1.png)

#### Rebalancing Edge Cases with Hard Examples and Augmentation 

在比赛即将结束时，我们观察到验证集中的某些示例一直被错误分类。 我们的目标是帮助模型以更高的置信度对这些示例进行分类。我们认为这些错误分类是由于我们的训练集中“边缘案例”示例的代表性不足造成的。 下面是一个这样的例子； 这是一个被错误分类为 IV 的 III。

![](/assets/img/20211202/AI2.png)

从模型预测输出中，我们观察到，即使我们错误地分类了这个例子，III 类和 IV 类的值非常接近。 我们想在“决策边界”上或附近识别更多示例并将它们添加到我们的训练集中，因此我们定义了一个难度分数，如下所述：

![](/assets/img/20211202/AI3.png)

其中 Pomax 是最大预测输出，Po2nd max 是下一个最佳预测值。 这描述了第一个和第二个最可能的预测值之间的百分比差异； 对于示例中显示的输出，难度分数为 2.793 – 2.2252.793=0.203。 然后我们添加了一个约束； 如果难度分数小于 0.5，我们将其视为“困难示例”。 这个过程为我们提供了额外的 880 张图像，我们将其添加到我们的训练集中。 

![](/assets/img/20211202/AI4.png)
此外，为了避免过度拟合，我们将图像裁剪了几个像素以减少罗马数字周围的空白，并使用不同的膨胀和腐蚀迭代。 其中一些附加示例如上所示。

但是，添加这 880 个“硬”图像意味着我们必须从验证集中删除 880 个现有图像。 为此，我们研究了训练数据集中每个类别的难度分数的直方图分布，并匹配其在验证集中的分布。 匹配训练和验证难度分数是避免训练数据集过度拟合或欠拟合的最佳方法，并确保最佳模型性能。


## Team Synaptic-AnN , Rank: 3

大致步骤：
+ 手动清洗
+ 产生更多样本（请朋友帮忙手写罗马数字）
  + 在原数据集上增强来填充数据集似乎不是最好的选择，为了保持繁华性
  + 作者想尝试GAN，但是计算负担太大并且会引入一些不想要的人工样本。
  + 目标是得到a wide variety of distributions 的罗马数字
+  分布和风格复制（Distribution and Style Replication）
   +  由于每个人的写字风格都具有一定的一致性，因此对于每个样本都扩充出了和其风格一致的其他数字。
  ![](/assets/img/20211202/AI5.png)
  ![](/assets/img/20211202/AI6.png)
    这样得到一个风格数据集$L$,和原始数据集$D$以及人为扩充的数据集$H$一起作为比赛的基础数据集。
    + Five Crops： 将一个图像分别在四角和中心做corp；
    + Aspect Ratio Standardization: 所有长宽比太大的都被截断，这是为了保持图像在resize到32*32之后的质量。
  + Auto Augmentation: 直接用的原Papaer在SVHN数据集上的粗略，并删除了一些没用的，比如Solarize和Invert。
  + Filter by Vote: 使用多个模型来过滤noisy and ambiguous images。从互联网和问卷收集了70000个图像。之后使用特定的增强参数生成平衡数据集。

    $$
    \Sigma=\left(\begin{array}{llll}
    P\left(c=0 \mid m_{0}\right) & P\left(c=1 \mid m_{0}\right) & \ldots & P\left(c=9 \mid m_{0}\right) \\
    P\left(c=0 \mid m_{1}\right) & P\left(c=1 \mid m_{1}\right) & \ldots & P\left(c=9 \mid m_{1}\right) \\
    P\left(c=0 \mid m_{2}\right) & P\left(c=1 \mid m_{2}\right) & \ldots & P\left(c=9 \mid m_{2}\right) \\
    P\left(c=0 \mid m_{3}\right) & P\left(c=1 \mid m_{3}\right) & \ldots & P\left(c=9 \mid m_{3}\right) \\
    P\left(c=0 \mid m_{4}\right) & P\left(c=1 \mid m_{4}\right) & \ldots & P\left(c=9 \mid m_{4}\right)
    \end{array}\right)
    $$

    设定一个阈值,如果五个模型的预测平均值小于阈值，则认定为噪声。省去大量时间。

最终解决方案：
![](/assets/img/20211202/AI7.png)
