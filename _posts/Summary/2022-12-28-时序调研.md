# 学术界（论文）

## PETRV2
隐式建模，引入时序的3DPE，即对反投影3D点做自车补偿，效果比较显著
![](/assets/img/20221226/PETRV2F1.jpg)

**时序引入方式：将两帧特征全部送进PETR，只对PE进行一些自车补偿**

本帧的图像对应的3D点可以从2D点（with depth）中通过相机内参和外参得到。
$$
\begin{equation}
P_i^{l(t)}(t)=T_{c_i(t)}^{l(t)} K_i^{-1} P^m(t)
\end{equation}
$$

自然的，前一帧的也可以这样做
$$
\begin{equation}
P_i^{l(t)}(t-1)=T_{l(t-1)}^{l(t)} P_i^{l(t-1)}(t-1)
\end{equation}
$$

综上，分别将图像转换成在各帧中的3D点，事情就变得很简单了，通过自车运动补偿即可以对齐两者。

$$
\begin{equation}
T_{l(t-1)}^{l(t)}=T_{e(t)}^{l(t)} T_g^{e(t)} T_g^{e(t-1)^{-1}} T_{e(t-1)}^{l(t-1)^{-1}}
\end{equation}
$$

消融实验
![](/assets/img/20221226/PETRV2FT3.jpg)

额外信息：据说这里引入的时序实际上效果有限，反而是FPE可能是更泛用的提点方法。

FPE：用图像特征给对应位置的PE加权。
$$
\begin{equation}
P E_i^{3 d}(t)=\xi\left(F_i(t)\right) * \psi\left(P_i^{l(t)}(t)\right)
\end{equation}
$$

## BEVFormer：
  **时序引入方式：通过Query信息的继承引入时序**
  ![](/assets/img/20221025/BEVFormerF2.jpg)

Temporal Self-Attention
时序信息通过当前时间的Q和上一时刻的BEV特征交互来获得。
1、对齐。根据上一时刻的自车运动将BEV对齐；
2、考虑到运动目标，BEV特征不可能严格对齐。因此引入deformAttn，来自适应的预测offset。
如下所示

$$
\begin{equation}
\operatorname{TSA}\left(Q_p,\left\{Q, B_{t-1}^{\prime}\right\}\right)=\sum_{V \in\left\{Q, B_{t-1}^{\prime}\right\}} \operatorname{DeformAttn}\left(Q_p, p, V\right)
\end{equation}
$$

代码中的实际操作，query和上一阵的query concat起来，一起做self attention，再将num_bev_query维度做reduce（平均）。

**本文没有给出Camera单帧与引入时序（双帧）的性能消融实验**。


## BEVFormerv2:
**时序引入方法：Concat + 基于resblock的reduction，可以重复引入多帧BEV**

似乎相比BEVFormer，这样的时序引入更加简洁了。
![](/assets/img/20221123/BEVFormerv2F1.jpg)

消融实验
![](/assets/img/20221123/BEVFormerv2T6.jpg)


**引入时序的效果似乎并不显著**。Bi是作者在此表格加入的一个trick，指做了简单说明，即在离线感知的情况下，做双向的temporal encoder，引入未来信息。

## DETR4D：
直接通过一个MHA模块来对前后两帧的query进行融合。这类似于BEVFormer？只不过这里做的是Cross Attention。而前者做的是Self-attention。本文提出的方法如下所示

$$
\begin{equation}
\operatorname{TSA}\left(Q^{(t)}, Q^{(t-1)}\right)=\operatorname{MHA}\left(Q^{(t)},\left[Q^{(t)}, Q^{(t-1)}\right]\right)
\end{equation}
$$
这部分是query的时序融合。除此之外，DETR4D还引入了Feature的时序融合，即融合后的query分别从两帧的feature map中query特征（但是使用不同的ref points，相差一个自车补偿）

$$
\begin{equation}
\begin{gathered}
q^{(t)}=\operatorname{PCA}\left(q, c^{(t)}, F^{(t)}\right) \\
q^{(t-1)}=\operatorname{PCA}\left(q, c^{(t-1)}, F^{(t-1)}\right) \\
\operatorname{PCA}\left(q, c^{(t)}, F^{(t)}, c^{(t-1)}, F^{(t-1)}\right)=\frac{1}{2}\left(q^{(t)}+q^{(t-1)}\right)
\end{gathered}
\end{equation}
$$

实验结果如下
![](/assets/img/20221205/DETR4DT2.jpg)

从消融实验的结果看：
1、query初始化的影响很大。
2、PCA比SCA性能更优（并且这部分应该是简单的平替关系）
3、时序Feature的引入，比时序Query的引入更加重要？
4、自车补偿必不可少。
## Trackformer:
![](/assets/img/20221123/TrackformerF2.jpg)

对于前一帧的检测结果，根据query预测的置信度筛选valid object(query)并传递给下一帧；而被识别为背景的query则被抛弃。考虑到检测中还可能出现短暂的遮挡导致目标丢失的情况，因此一般情况下re-id在tracking中也是必须的。为了应对这种情况，这里提出类似于Memory，对于移除的queries，保留一定的时间（frame）。注意到，这里仍然需要使用NMS。用于处理一些Self-attention不能解决的重复框。（个人认为可能是由于不统一的初始化造成的。）memory住的query，当其的预测结果大于阈值是，就会触发re-id，继续这个物体的轨迹。由于query中包含的位置信息，长时间远距离的移动，query无法索引到。但是短时间的recovery却是query非常擅长的。因此，这样非常适合常见的short-term occlusions。

比较关键的，作者针对这套pipeline专门设计了三种数据增广方法，来对物体的位置、运动、missing和遮挡进行干扰。
+ 随机使用前某一帧（一段时间Range内）和当前帧匹配。以模拟大距离的一定和低帧数数据。
+ 在传递的时候，以一定比例传递FN（漏检）到下一帧中。保持足够的FN（漏检）比例是联合训练有效的关键。
+ 同理，在传递的过程中，加入FP，即一些背景query，这些在下一帧的训练中应当被识别为背景，对应为被遮挡的情况。相当于也保证了FP的数量。

其余是一些常见的，比如对目标框空间扰动，等等。由于query对信息的编码是隐式的，因此不能对query扰动。

**如果是继承全部query的方式的话，比如DETR4D和BEVformer，则上述后两个筛选就不需要了，但是随机时间的时序信息可能对模型的性能有所收益。**

**其实验评估基于Track而不是Detection,故这里省略**
## SOLOFusion:


![](/assets/img/20221123/SOLOF7.jpg)

目前常见的时序融合方法：
+ BEV-based的方法通过concatenate多个timesteps的volumes实现；
+ query-based方法通过将query投影到过去的图像上实现提取特征。

但是这些方法都只能从temporal fusion中获得有限的增益。

不同时序融合方式的对比。分别是基于多视图匹配、lss和query。如下表所示
![](/assets/img/20221123/SOLOT1.jpg)

作者从多视图重建的角度来看待这个问题，因为多视图立体匹配和时序3D检测的共同点在于，其都关心一个候选位置是否被占据，前者关心其是否被任何物体占据，而后者关心其是否被特定物体占据。

本文作者首先对多视图重建进行了一些分析（此处略），之后提出SOFOFusion方法。基本思路是，将长序列分为若干短序列。在短序列中使用可学习的重建方法构建cost volume生成depth map并投影为bev feauture。短序列之间通过简单的concat形成长序列特征（cost volume）。这里的长序列特征直接通过concatbev特征获得，相对简单。

具体性能上，具有显著优势

![](/assets/img/20221123/SOLOT2T3.jpg)

消融实现显示，长时序的收益明显，并且三维重建显著提高了模型对低分辨率图像的检测能力。
![](/assets/img/20221123/SOLOT6.jpg)
![](/assets/img/20221123/SOLOT7.jpg)
另外，Base组韩春瑞目前正在做基于SOLOFusion的新工作，其主要区别是将SOLOFusion的Cat换成了RNN，这样使得网络可以实现Online的特性。在性能上目前基本与SOLOfusion持平。


## CenterFormer:
TODO，还没看
## Bevdet4D: 
TODO，还没看
## BEVStereo: 
TODO，还没看
