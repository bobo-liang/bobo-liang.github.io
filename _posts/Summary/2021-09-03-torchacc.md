---
layout: post
title: 'Torch常见加速方法'
date: 2021-09-02
author: Poley
cover: '/assets/img/mycat3.jpg'
tags: 总结
---

> 参考博客 ：https://0809zheng.github.io/2020/09/16/eccv-tutorial.html


来自于 ECCV 2020 Tutorial on PyTorch Performance Tuning Guide.

# Use asynv data loading / augmentation

使用异步数据加载和增强，即**num_workers=0, pin_memory=False**。

+ **num_workers**:当加载batch的时间小于模型的训练时间时，GPU每次训练完都可以直接从CPU中取到下一个batch的数据，无需额外的等待，因此也不需要多余的worker，即使增加worker也不会影响训练速度；当加载batch的时间大于模型的训练时间时，GPU每次训练完都需要等待CPU完成数据的载入，若增加worker，即使worker_1还未就绪，GPU也可以取worker_2的数据来训练。即**异步加载**。

+ **pin_memory**:设置**锁页内存**，即放在内存中永远不会和主机虚拟内存发生交换的内存内存。在内存和显存交换的过程中会有更快的速度。GPU显存中全部都是**锁页内存**。

下表是训练MNIST图像分类实验中不同参数的对照试验（环境PyTorch 1.6 + NVIDIA Quadro RTX 8000）

![](/assets/img/20210902/TorchaccF1.png)

# enable cuDNN autotuner
+ 允许cuDNN进行调校
在训练卷积神经网络时，cuDNN支持多种不同的算法计算卷积，使用调校工具autotuner可以运行一个较小的benchmark检测这些算法，并从中选择表现最好的算法。

对于卷积神经网络，只需要设置：

```
torch.backends.cudnn.benchmark = True
```

下表是使用nn.Conv2d(64,3)处理大小为(32,64,64,64)数据的对照试验（环境PyTorch 1.6 + NVIDIA Quadro RTX 8000）

![](/assets/img/20210902/TorchaccF2.png)

# Increase batch size

+ 增加批量大小
+ 学习率衰减，warmup，权重衰减
+ 换用大batch的优化方法:LARS,LAMB,NVLAMB,NovoGrad

# Remove unnecessary computation
比如去除batchnorm之前层的bias
![](/assets/img/20210902/TorchaccF3.png)

# Use DistributedDataParallel instead of DataParallel

区别，使用的CPU进程数不同，如下
![](/assets/img/20210902/TorchaccF4.png)

# Efficiently zero-out gradinets

梯度置零一般使用如下语句
```
model.zero_grad() or optimizer.zero_grad()
```

上述对每一个参数执行memset操作（为新申请内存做初始化工作），反向传播时用'$+=$'，即读+写。为了提高效率，可以变为

```
for param in model.parameters():
    param.grad = None
```

上述不会执行memset，反向传播用'$=$'（写）

# Apply PyTorch JIT to fuse pointwise operations

+ 使用PyTorch JIT融合逐点操作
PyTorch JIT能够将逐点操作（pointwise operations）融合到单个CUDA核上，从而减小执行时间。

如下图，只需要在执行语句前加上@torch.jit.script便可以实现（环境PyTorch 1.6 + NVIDIA Quadro RTX 8000）：

![](/assets/img/20210902/TorchaccF5.png)
# Checkpoint to recompute intermediates
+ 使用checkpoint重新计算中间值
在常规的训练过程中，前向传播会存储中间运算的输出值用以反向传播，这一步需要更多的内存，从而限制了训练时batch size的大小；在反向传播更新参数时不再需要额外的运算。

torch.utils.checkpoint提供了checkpoint操作。在前向传播只存储部分中间运算的输出值，减小了对内存的占用，可以使用更大的batch size；反向传播时需要额外的运算。

checkpoint操作是一种用时间换内存的操作。通常需要选择对合适的操作进行，如较小的重复计算代价（re-computation cost）和较大的内存占用（memory footprint），包括激活函数、上下采样和较小堆积深度（accumulation depth）的矩阵向量运算。
